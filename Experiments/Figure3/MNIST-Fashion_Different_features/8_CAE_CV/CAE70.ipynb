{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#----------------------------Reproducible----------------------------------------------------------------------------------------\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "import os\n",
    "\n",
    "seed=0\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "np.random.seed(seed)\n",
    "rn.seed(seed)\n",
    "\n",
    "#----------------------------Reproducible----------------------------------------------------------------------------------------\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "import random\n",
    "import scipy.sparse as sparse\n",
    "import scipy.io\n",
    "import time\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skfeature.utility import construct_W\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from skfeature.utility.sparse_learning import feature_ranking\n",
    "import time\n",
    "from sklearn.impute import SimpleImputer \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from concrete_autoencoder import ConcreteAutoencoderFeatureSelector\n",
    "from keras.layers import Dense\n",
    "import pandas as pd\n",
    "from skimage import io\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.sparse as sparse\n",
    "from keras.datasets import fashion_mnist\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "#Import ourslef defined methods\n",
    "import sys\n",
    "sys.path.append(r\"../Defined\")\n",
    "import Functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data_used=10000\n",
    "(x_train_, y_train_), (x_test_, y_test_) = fashion_mnist.load_data()\n",
    "x_data=np.r_[x_train_,x_test_].reshape(70000, 28*28).astype('float32')/255.0\n",
    "y_data=np.r_[y_train_,y_test_]\n",
    "\n",
    "np.random.seed(seed)\n",
    "x_data_num,_=x_data.shape\n",
    "index=np.arange(x_data_num)\n",
    "np.random.shuffle(index)\n",
    "\n",
    "data_arr=x_data[index][0:num_data_used]\n",
    "label_arr_onehot=y_data[index][0:num_data_used]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_feture_number=70"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "def write_to_csv(p_data,p_path):\n",
    "    dataframe = pd.DataFrame(p_data)\n",
    "    dataframe.to_csv(p_path, mode='a',header=False,index=False,sep=',')\n",
    "    del dataframe\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------       \n",
    "def mse_check(train, test):\n",
    "    LR = LinearRegression(n_jobs = -1)\n",
    "    LR.fit(train[0], train[1])\n",
    "    MSELR = ((LR.predict(test[0]) - test[1]) ** 2).mean()\n",
    "    return MSELR\n",
    " \n",
    "#--------------------------------------------------------------------------------------------------------------------------------       \n",
    "def cal(p_data_arr,\\\n",
    "        p_label_arr_onehot,\\\n",
    "        p_key_feture_number,\\\n",
    "        p_epochs_number,\\\n",
    "        p_seed):\n",
    "    \n",
    "    C_train_x,C_test_x,C_train_y,C_test_y= train_test_split(p_data_arr,p_label_arr_onehot,test_size=0.2,random_state=p_seed)\n",
    "\n",
    "    os.environ['PYTHONHASHSEED'] = str(p_seed)\n",
    "    np.random.seed(p_seed)\n",
    "    rn.seed(p_seed)\n",
    "    tf.compat.v1.set_random_seed(p_seed)\n",
    "    \n",
    "    #--------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    def decoder(x):\n",
    "        #x = Dense(key_feture_number)(x)\n",
    "        x = Dense(data_arr.shape[1])(x)\n",
    "        return x\n",
    "\n",
    "    t_start = time.time()\n",
    "    selector = ConcreteAutoencoderFeatureSelector(K = p_key_feture_number, output_function = decoder, num_epochs = p_epochs_number)\n",
    "    selector.fit(C_train_x, C_train_x, C_test_x, C_test_x)\n",
    "    t_used=time.time() - t_start\n",
    "    \n",
    "    write_to_csv(np.array([t_used]),\"./log\"+str(key_feture_number)+\"/CAE_time.csv\")\n",
    "    \n",
    "    train_compressed_Data=p_data_arr[:, selector.get_support(indices=True)]\n",
    "    \n",
    "    # Classification on original features\n",
    "    train_feature=C_train_x\n",
    "    train_label=C_train_y\n",
    "    test_feature=C_test_x\n",
    "    test_label=C_test_y \n",
    "    orig_train_acc,orig_test_acc=F.ETree(train_feature,train_label,test_feature,test_label,0)\n",
    "        \n",
    "    # Classification on selected features\n",
    "    C_train_selected_x,C_test_selected_x,C_train_y,C_test_y= train_test_split(train_compressed_Data,p_label_arr_onehot,test_size=0.2,random_state=p_seed)\n",
    "    \n",
    "    train_feature=C_train_selected_x\n",
    "    train_label=C_train_y\n",
    "    test_feature=C_test_selected_x\n",
    "    test_label=C_test_y\n",
    "    selec_train_acc,selec_test_acc=F.ETree(train_feature,train_label,test_feature,test_label,0)\n",
    "    \n",
    "    # Linear reconstruction\n",
    "    train_feature_tuple=(C_train_selected_x,C_train_x)\n",
    "    test_feature_tuple=(C_test_selected_x,C_test_x)\n",
    "\n",
    "    reconstruction_loss=mse_check(train_feature_tuple, test_feature_tuple)\n",
    "    \n",
    "    results=np.array([orig_train_acc,orig_test_acc,selec_train_acc,selec_test_acc,reconstruction_loss])\n",
    "    \n",
    "    write_to_csv(results.reshape(1,len(results)),\"./log\"+str(key_feture_number)+\"/CAE_results.csv\")\n",
    "    \n",
    "    return orig_train_acc,orig_test_acc,selec_train_acc,selec_test_acc,reconstruction_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_number=200\n",
    "\n",
    "p_data_arr=data_arr\n",
    "p_label_arr_onehot=label_arr_onehot\n",
    "p_key_feture_number=key_feture_number\n",
    "p_epochs_number=epochs_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "concrete_select (ConcreteSel (None, 70)                54881     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 784)               55664     \n",
      "=================================================================\n",
      "Total params: 110,545\n",
      "Trainable params: 110,544\n",
      "Non-trainable params: 1\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/200\n",
      "mean max of probabilities: 0.001420195 - temperature 10.0\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.0717 - val_loss: 0.0649\n",
      "Epoch 2/200\n",
      "mean max of probabilities: 0.0014370383 - temperature 9.716152\n",
      "8000/8000 [==============================] - 8s 982us/step - loss: 0.0647 - val_loss: 0.0643\n",
      "Epoch 3/200\n",
      "mean max of probabilities: 0.0014807344 - temperature 9.440363\n",
      "8000/8000 [==============================] - 7s 832us/step - loss: 0.0641 - val_loss: 0.0638\n",
      "Epoch 4/200\n",
      "mean max of probabilities: 0.0015445617 - temperature 9.172401\n",
      "8000/8000 [==============================] - 8s 980us/step - loss: 0.0639 - val_loss: 0.0637\n",
      "Epoch 5/200\n",
      "mean max of probabilities: 0.0016322886 - temperature 8.912045\n",
      "8000/8000 [==============================] - 8s 957us/step - loss: 0.0638 - val_loss: 0.0636\n",
      "Epoch 6/200\n",
      "mean max of probabilities: 0.0017495726 - temperature 8.6590805\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.0636 - val_loss: 0.0635\n",
      "Epoch 7/200\n",
      "mean max of probabilities: 0.0019151242 - temperature 8.413296\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.0634 - val_loss: 0.0632\n",
      "Epoch 8/200\n",
      "mean max of probabilities: 0.0021565373 - temperature 8.174487\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.0627 - val_loss: 0.0621\n",
      "Epoch 9/200\n",
      "mean max of probabilities: 0.0025162862 - temperature 7.942457\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.0615 - val_loss: 0.0603\n",
      "Epoch 10/200\n",
      "mean max of probabilities: 0.0030132765 - temperature 7.7170134\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.0591 - val_loss: 0.0572\n",
      "Epoch 11/200\n",
      "mean max of probabilities: 0.0036454406 - temperature 7.4979672\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.0557 - val_loss: 0.0535\n",
      "Epoch 12/200\n",
      "mean max of probabilities: 0.004346354 - temperature 7.2851405\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.0519 - val_loss: 0.0503\n",
      "Epoch 13/200\n",
      "mean max of probabilities: 0.005014881 - temperature 7.078353\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.0491 - val_loss: 0.0476\n",
      "Epoch 14/200\n",
      "mean max of probabilities: 0.005558135 - temperature 6.8774366\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.0474 - val_loss: 0.0468\n",
      "Epoch 15/200\n",
      "mean max of probabilities: 0.0059424927 - temperature 6.6822195\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.0469 - val_loss: 0.0463\n",
      "Epoch 16/200\n",
      "mean max of probabilities: 0.0061783916 - temperature 6.4925466\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.0468 - val_loss: 0.0463\n",
      "Epoch 17/200\n",
      "mean max of probabilities: 0.0063262098 - temperature 6.3082566\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.0466 - val_loss: 0.0460\n",
      "Epoch 18/200\n",
      "mean max of probabilities: 0.006448722 - temperature 6.129198\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.0464 - val_loss: 0.0460\n",
      "Epoch 19/200\n",
      "mean max of probabilities: 0.0066100224 - temperature 5.955221\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.0461 - val_loss: 0.0453\n",
      "Epoch 20/200\n",
      "mean max of probabilities: 0.006847344 - temperature 5.786184\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.0457 - val_loss: 0.0451\n",
      "Epoch 21/200\n",
      "mean max of probabilities: 0.0072301873 - temperature 5.621946\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.0452 - val_loss: 0.0445\n",
      "Epoch 22/200\n",
      "mean max of probabilities: 0.0077785715 - temperature 5.4623694\n",
      "8000/8000 [==============================] - 12s 1ms/step - loss: 0.0445 - val_loss: 0.0437\n",
      "Epoch 23/200\n",
      "mean max of probabilities: 0.008500442 - temperature 5.307321\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.0435 - val_loss: 0.0427\n",
      "Epoch 24/200\n",
      "mean max of probabilities: 0.00941526 - temperature 5.1566744\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.0425 - val_loss: 0.0416\n",
      "Epoch 25/200\n",
      "mean max of probabilities: 0.010519624 - temperature 5.010304\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.0414 - val_loss: 0.0404\n",
      "Epoch 26/200\n",
      "mean max of probabilities: 0.011786346 - temperature 4.8680882\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.0403 - val_loss: 0.0396\n",
      "Epoch 27/200\n",
      "mean max of probabilities: 0.013204578 - temperature 4.7299085\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.0392 - val_loss: 0.0383\n",
      "Epoch 28/200\n",
      "mean max of probabilities: 0.014676215 - temperature 4.595652\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.0382 - val_loss: 0.0375\n",
      "Epoch 29/200\n",
      "mean max of probabilities: 0.016224178 - temperature 4.4652066\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.0373 - val_loss: 0.0365\n",
      "Epoch 30/200\n",
      "mean max of probabilities: 0.01785939 - temperature 4.338463\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.0363 - val_loss: 0.0356\n",
      "Epoch 31/200\n",
      "mean max of probabilities: 0.019528644 - temperature 4.2153172\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.0354 - val_loss: 0.0348\n",
      "Epoch 32/200\n",
      "mean max of probabilities: 0.021268278 - temperature 4.095666\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.0346 - val_loss: 0.0342\n",
      "Epoch 33/200\n",
      "mean max of probabilities: 0.023056637 - temperature 3.979412\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.0337 - val_loss: 0.0331\n",
      "Epoch 34/200\n",
      "mean max of probabilities: 0.024911748 - temperature 3.8664572\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.0328 - val_loss: 0.0324\n",
      "Epoch 35/200\n",
      "mean max of probabilities: 0.026886301 - temperature 3.7567089\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.0320 - val_loss: 0.0316\n",
      "Epoch 36/200\n",
      "mean max of probabilities: 0.028794518 - temperature 3.650076\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.0312 - val_loss: 0.0309\n",
      "Epoch 37/200\n",
      "mean max of probabilities: 0.03067162 - temperature 3.5464702\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.0306 - val_loss: 0.0302\n",
      "Epoch 38/200\n",
      "mean max of probabilities: 0.032670654 - temperature 3.445804\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.0300 - val_loss: 0.0298\n",
      "Epoch 39/200\n",
      "mean max of probabilities: 0.034721013 - temperature 3.3479955\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.0295 - val_loss: 0.0296\n",
      "Epoch 40/200\n",
      "mean max of probabilities: 0.036813565 - temperature 3.2529633\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.0291 - val_loss: 0.0289\n",
      "Epoch 41/200\n",
      "mean max of probabilities: 0.038665477 - temperature 3.1606295\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.0287 - val_loss: 0.0287\n",
      "Epoch 42/200\n",
      "mean max of probabilities: 0.04055288 - temperature 3.0709162\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.0283 - val_loss: 0.0282\n",
      "Epoch 43/200\n",
      "mean max of probabilities: 0.042575844 - temperature 2.9837487\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.0279 - val_loss: 0.0279\n",
      "Epoch 44/200\n",
      "mean max of probabilities: 0.04469319 - temperature 2.8990557\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.0276 - val_loss: 0.0275\n",
      "Epoch 45/200\n",
      "mean max of probabilities: 0.04697604 - temperature 2.8167667\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.0272 - val_loss: 0.0271\n",
      "Epoch 46/200\n",
      "mean max of probabilities: 0.049522415 - temperature 2.7368128\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.0269 - val_loss: 0.0268\n",
      "Epoch 47/200\n",
      "mean max of probabilities: 0.052132387 - temperature 2.659129\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.0265 - val_loss: 0.0265\n",
      "Epoch 48/200\n",
      "mean max of probabilities: 0.055080026 - temperature 2.5836504\n",
      "8000/8000 [==============================] - 8s 950us/step - loss: 0.0261 - val_loss: 0.0260\n",
      "Epoch 49/200\n",
      "mean max of probabilities: 0.058255713 - temperature 2.5103142\n",
      "8000/8000 [==============================] - 8s 970us/step - loss: 0.0257 - val_loss: 0.0256\n",
      "Epoch 50/200\n",
      "mean max of probabilities: 0.061789915 - temperature 2.43906\n",
      "8000/8000 [==============================] - 8s 1ms/step - loss: 0.0253 - val_loss: 0.0251\n",
      "Epoch 51/200\n",
      "mean max of probabilities: 0.065418825 - temperature 2.369828\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.0249 - val_loss: 0.0248\n",
      "Epoch 52/200\n",
      "mean max of probabilities: 0.06919795 - temperature 2.3025618\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.0245 - val_loss: 0.0245\n",
      "Epoch 53/200\n",
      "mean max of probabilities: 0.07264535 - temperature 2.2372043\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.0242 - val_loss: 0.0241\n",
      "Epoch 54/200\n",
      "mean max of probabilities: 0.076193646 - temperature 2.173702\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.0238 - val_loss: 0.0238\n",
      "Epoch 55/200\n",
      "mean max of probabilities: 0.0794939 - temperature 2.1120012\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.0235 - val_loss: 0.0237\n",
      "Epoch 56/200\n",
      "mean max of probabilities: 0.08212478 - temperature 2.0520527\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.0234 - val_loss: 0.0232\n",
      "Epoch 57/200\n",
      "mean max of probabilities: 0.084614284 - temperature 1.993806\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.0231 - val_loss: 0.0232\n",
      "Epoch 58/200\n",
      "mean max of probabilities: 0.08661261 - temperature 1.9372126\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.0229 - val_loss: 0.0231\n",
      "Epoch 59/200\n",
      "mean max of probabilities: 0.08806392 - temperature 1.8822256\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.0228 - val_loss: 0.0227\n",
      "Epoch 60/200\n",
      "mean max of probabilities: 0.08919926 - temperature 1.8287995\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.0227 - val_loss: 0.0227\n",
      "Epoch 61/200\n",
      "mean max of probabilities: 0.09047357 - temperature 1.7768897\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.0226 - val_loss: 0.0227\n",
      "Epoch 62/200\n",
      "mean max of probabilities: 0.091602944 - temperature 1.7264532\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.0225 - val_loss: 0.0225\n",
      "Epoch 63/200\n",
      "mean max of probabilities: 0.0934401 - temperature 1.6774484\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.0225 - val_loss: 0.0227\n",
      "Epoch 64/200\n",
      "mean max of probabilities: 0.0953244 - temperature 1.6298345\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.0225 - val_loss: 0.0225\n",
      "Epoch 65/200\n",
      "mean max of probabilities: 0.09696295 - temperature 1.583572\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.0224 - val_loss: 0.0228\n",
      "Epoch 66/200\n",
      "mean max of probabilities: 0.0987815 - temperature 1.5386227\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.0225 - val_loss: 0.0226\n",
      "Epoch 67/200\n",
      "mean max of probabilities: 0.10073085 - temperature 1.4949492\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.0225 - val_loss: 0.0225\n",
      "Epoch 68/200\n",
      "mean max of probabilities: 0.102648154 - temperature 1.4525156\n",
      "8000/8000 [==============================] - 12s 1ms/step - loss: 0.0224 - val_loss: 0.0225\n",
      "Epoch 69/200\n",
      "mean max of probabilities: 0.10516777 - temperature 1.4112862\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.0225 - val_loss: 0.0227\n",
      "Epoch 70/200\n",
      "mean max of probabilities: 0.10822058 - temperature 1.3712273\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.0226 - val_loss: 0.0225\n",
      "Epoch 71/200\n",
      "mean max of probabilities: 0.11149351 - temperature 1.3323054\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.0225 - val_loss: 0.0227\n",
      "Epoch 72/200\n",
      "mean max of probabilities: 0.11502468 - temperature 1.2944883\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.0226 - val_loss: 0.0229\n",
      "Epoch 73/200\n",
      "mean max of probabilities: 0.118676975 - temperature 1.2577448\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.0226 - val_loss: 0.0225\n",
      "Epoch 74/200\n",
      "mean max of probabilities: 0.122879684 - temperature 1.2220443\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.0227 - val_loss: 0.0229\n",
      "Epoch 75/200\n",
      "mean max of probabilities: 0.12739559 - temperature 1.1873572\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.0227 - val_loss: 0.0226\n",
      "Epoch 76/200\n",
      "mean max of probabilities: 0.13266012 - temperature 1.1536546\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.0226 - val_loss: 0.0227\n",
      "Epoch 77/200\n",
      "mean max of probabilities: 0.13812184 - temperature 1.1209084\n",
      "8000/8000 [==============================] - 12s 2ms/step - loss: 0.0226 - val_loss: 0.0229\n",
      "Epoch 78/200\n",
      "mean max of probabilities: 0.14448054 - temperature 1.089092\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.0226 - val_loss: 0.0227\n",
      "Epoch 79/200\n",
      "mean max of probabilities: 0.1511683 - temperature 1.0581783\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.0224 - val_loss: 0.0226\n",
      "Epoch 80/200\n",
      "mean max of probabilities: 0.15844645 - temperature 1.0281421\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.0224 - val_loss: 0.0225\n",
      "Epoch 81/200\n",
      "mean max of probabilities: 0.16628744 - temperature 0.9989582\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.0224 - val_loss: 0.0226\n",
      "Epoch 82/200\n",
      "mean max of probabilities: 0.17476626 - temperature 0.970603\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.0225 - val_loss: 0.0222\n",
      "Epoch 83/200\n",
      "mean max of probabilities: 0.18412785 - temperature 0.9430529\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.0222 - val_loss: 0.0222\n",
      "Epoch 84/200\n",
      "mean max of probabilities: 0.19396538 - temperature 0.91628474\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.0221 - val_loss: 0.0222\n",
      "Epoch 85/200\n",
      "mean max of probabilities: 0.20448163 - temperature 0.8902763\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.0222 - val_loss: 0.0222\n",
      "Epoch 86/200\n",
      "mean max of probabilities: 0.21585323 - temperature 0.865006\n",
      "8000/8000 [==============================] - 8s 1ms/step - loss: 0.0222 - val_loss: 0.0220\n",
      "Epoch 87/200\n",
      "mean max of probabilities: 0.22781841 - temperature 0.84045327\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.0220 - val_loss: 0.0220\n",
      "Epoch 88/200\n",
      "mean max of probabilities: 0.24000326 - temperature 0.8165973\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.0217 - val_loss: 0.0219\n",
      "Epoch 89/200\n",
      "mean max of probabilities: 0.25279602 - temperature 0.7934184\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.0219 - val_loss: 0.0216\n",
      "Epoch 90/200\n",
      "mean max of probabilities: 0.26561683 - temperature 0.7708973\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.0217 - val_loss: 0.0218\n",
      "Epoch 91/200\n",
      "mean max of probabilities: 0.2792416 - temperature 0.74901587\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.0215 - val_loss: 0.0215\n",
      "Epoch 92/200\n",
      "mean max of probabilities: 0.29265076 - temperature 0.7277553\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.0215 - val_loss: 0.0217\n",
      "Epoch 93/200\n",
      "mean max of probabilities: 0.30567285 - temperature 0.7070981\n",
      "8000/8000 [==============================] - 12s 1ms/step - loss: 0.0213 - val_loss: 0.0216\n",
      "Epoch 94/200\n",
      "mean max of probabilities: 0.3192809 - temperature 0.68702734\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.0213 - val_loss: 0.0213\n",
      "Epoch 95/200\n",
      "mean max of probabilities: 0.3334664 - temperature 0.6675263\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.0213 - val_loss: 0.0212\n",
      "Epoch 96/200\n",
      "mean max of probabilities: 0.34706217 - temperature 0.64857894\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.0211 - val_loss: 0.0212\n",
      "Epoch 97/200\n",
      "mean max of probabilities: 0.3619925 - temperature 0.6301691\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.0211 - val_loss: 0.0212\n",
      "Epoch 98/200\n",
      "mean max of probabilities: 0.37673095 - temperature 0.61228204\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.0208 - val_loss: 0.0208\n",
      "Epoch 99/200\n",
      "mean max of probabilities: 0.3911876 - temperature 0.5949025\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.0207 - val_loss: 0.0209\n",
      "Epoch 100/200\n",
      "mean max of probabilities: 0.40567997 - temperature 0.5780162\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.0207 - val_loss: 0.0210\n",
      "Epoch 101/200\n",
      "mean max of probabilities: 0.42021587 - temperature 0.56160927\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.0206 - val_loss: 0.0206\n",
      "Epoch 102/200\n",
      "mean max of probabilities: 0.43408364 - temperature 0.5456681\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.0205 - val_loss: 0.0203\n",
      "Epoch 103/200\n",
      "mean max of probabilities: 0.4482899 - temperature 0.5301795\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.0203 - val_loss: 0.0203\n",
      "Epoch 104/200\n",
      "mean max of probabilities: 0.4621574 - temperature 0.5151305\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.0202 - val_loss: 0.0202\n",
      "Epoch 105/200\n",
      "mean max of probabilities: 0.47535956 - temperature 0.5005086\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.0201 - val_loss: 0.0201\n",
      "Epoch 106/200\n",
      "mean max of probabilities: 0.48805797 - temperature 0.48630178\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.0200 - val_loss: 0.0198\n",
      "Epoch 107/200\n",
      "mean max of probabilities: 0.50143963 - temperature 0.47249824\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.0200 - val_loss: 0.0202\n",
      "Epoch 108/200\n",
      "mean max of probabilities: 0.51372135 - temperature 0.45908657\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.0198 - val_loss: 0.0198\n",
      "Epoch 109/200\n",
      "mean max of probabilities: 0.5253457 - temperature 0.44605547\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.0198 - val_loss: 0.0198\n",
      "Epoch 110/200\n",
      "mean max of probabilities: 0.5365596 - temperature 0.43339437\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.0196 - val_loss: 0.0197\n",
      "Epoch 111/200\n",
      "mean max of probabilities: 0.54781246 - temperature 0.42109263\n",
      "8000/8000 [==============================] - 12s 1ms/step - loss: 0.0195 - val_loss: 0.0194\n",
      "Epoch 112/200\n",
      "mean max of probabilities: 0.55885303 - temperature 0.40914014\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.0195 - val_loss: 0.0195\n",
      "Epoch 113/200\n",
      "mean max of probabilities: 0.569335 - temperature 0.39752677\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.0194 - val_loss: 0.0193\n",
      "Epoch 114/200\n",
      "mean max of probabilities: 0.5797504 - temperature 0.38624313\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.0192 - val_loss: 0.0192\n",
      "Epoch 115/200\n",
      "mean max of probabilities: 0.58966845 - temperature 0.37527984\n",
      "8000/8000 [==============================] - 12s 1ms/step - loss: 0.0192 - val_loss: 0.0192\n",
      "Epoch 116/200\n",
      "mean max of probabilities: 0.5994803 - temperature 0.36462763\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.0191 - val_loss: 0.0195\n",
      "Epoch 117/200\n",
      "mean max of probabilities: 0.60992205 - temperature 0.35427782\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.0190 - val_loss: 0.0191\n",
      "Epoch 118/200\n",
      "mean max of probabilities: 0.6197773 - temperature 0.34422177\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.0190 - val_loss: 0.0190\n",
      "Epoch 119/200\n",
      "mean max of probabilities: 0.63007843 - temperature 0.3344512\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.0190 - val_loss: 0.0188\n",
      "Epoch 120/200\n",
      "mean max of probabilities: 0.6398062 - temperature 0.32495785\n",
      "8000/8000 [==============================] - 12s 1ms/step - loss: 0.0188 - val_loss: 0.0186\n",
      "Epoch 121/200\n",
      "mean max of probabilities: 0.64921 - temperature 0.31573397\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.0186 - val_loss: 0.0187\n",
      "Epoch 122/200\n",
      "mean max of probabilities: 0.6579155 - temperature 0.30677187\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.0187 - val_loss: 0.0189\n",
      "Epoch 123/200\n",
      "mean max of probabilities: 0.66711193 - temperature 0.29806426\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.0186 - val_loss: 0.0187\n",
      "Epoch 124/200\n",
      "mean max of probabilities: 0.67540675 - temperature 0.28960377\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.0185 - val_loss: 0.0186\n",
      "Epoch 125/200\n",
      "mean max of probabilities: 0.683974 - temperature 0.28138345\n",
      "8000/8000 [==============================] - 12s 1ms/step - loss: 0.0184 - val_loss: 0.0184\n",
      "Epoch 126/200\n",
      "mean max of probabilities: 0.6925433 - temperature 0.27339643\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.0185 - val_loss: 0.0184\n"
     ]
    }
   ],
   "source": [
    "for p_seed in np.arange(0,5):\n",
    "    orig_train_acc,orig_test_acc,selec_train_acc,selec_test_acc,reconstruction_loss=cal(p_data_arr,\\\n",
    "                                                                                        p_label_arr_onehot,\\\n",
    "                                                                                        p_key_feture_number,\\\n",
    "                                                                                        p_epochs_number,\\\n",
    "                                                                                        p_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#----------------------------Reproducible----------------------------------------------------------------------------------------\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "import os\n",
    "\n",
    "seed=0\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "np.random.seed(seed)\n",
    "rn.seed(seed)\n",
    "\n",
    "#----------------------------Reproducible----------------------------------------------------------------------------------------\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "import random\n",
    "import scipy.sparse as sparse\n",
    "import scipy.io\n",
    "import time\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skfeature.utility import construct_W\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from skfeature.utility.sparse_learning import feature_ranking\n",
    "import time\n",
    "from sklearn.impute import SimpleImputer \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from concrete_autoencoder import ConcreteAutoencoderFeatureSelector\n",
    "from keras.layers import Dense\n",
    "import pandas as pd\n",
    "from skimage import io\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.sparse as sparse\n",
    "from keras.datasets import fashion_mnist\n",
    "import scipy.io\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "#Import ourslef defined methods\n",
    "import sys\n",
    "sys.path.append(r\"../Defined\")\n",
    "import Functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=\"../Dataset/arcene.mat\"\n",
    "Data = scipy.io.loadmat(data_path)\n",
    "\n",
    "data_arr=Data['X']\n",
    "label_arr_=Data['Y'][:, 0]\n",
    "\n",
    "label_arr=np.array([0 if label_arr_i<0 else label_arr_i for label_arr_i in label_arr_])\n",
    "data_arr=MinMaxScaler(feature_range=(0,1)).fit_transform(data_arr)\n",
    "label_arr_onehot=label_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_feture_number=55"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "def write_to_csv(p_data,p_path):\n",
    "    dataframe = pd.DataFrame(p_data)\n",
    "    dataframe.to_csv(p_path, mode='a',header=False,index=False,sep=',')\n",
    "    del dataframe\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------       \n",
    "def mse_check(train, test):\n",
    "    LR = LinearRegression(n_jobs = -1)\n",
    "    LR.fit(train[0], train[1])\n",
    "    MSELR = ((LR.predict(test[0]) - test[1]) ** 2).mean()\n",
    "    return MSELR\n",
    " \n",
    "#--------------------------------------------------------------------------------------------------------------------------------       \n",
    "def cal(p_data_arr,\\\n",
    "        p_label_arr_onehot,\\\n",
    "        p_key_feture_number,\\\n",
    "        p_epochs_number,\\\n",
    "        p_seed):\n",
    "    \n",
    "    C_train_x,C_test_x,C_train_y,C_test_y= train_test_split(p_data_arr,p_label_arr_onehot,test_size=0.2,random_state=p_seed)\n",
    "\n",
    "    os.environ['PYTHONHASHSEED'] = str(p_seed)\n",
    "    np.random.seed(p_seed)\n",
    "    rn.seed(p_seed)\n",
    "    tf.compat.v1.set_random_seed(p_seed)\n",
    "    \n",
    "    #--------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    def decoder(x):\n",
    "        #x = Dense(key_feture_number)(x)\n",
    "        x = Dense(data_arr.shape[1])(x)\n",
    "        return x\n",
    "\n",
    "    t_start = time.time()\n",
    "    selector = ConcreteAutoencoderFeatureSelector(K = p_key_feture_number, output_function = decoder, num_epochs = p_epochs_number)\n",
    "    selector.fit(C_train_x, C_train_x, C_test_x, C_test_x)\n",
    "    t_used=time.time() - t_start\n",
    "    \n",
    "    write_to_csv(np.array([t_used]),\"./log\"+str(key_feture_number)+\"/CAE_time.csv\")\n",
    "    \n",
    "    train_compressed_Data=p_data_arr[:, selector.get_support(indices=True)]\n",
    "    \n",
    "    # Classification on original features\n",
    "    train_feature=C_train_x\n",
    "    train_label=C_train_y\n",
    "    test_feature=C_test_x\n",
    "    test_label=C_test_y \n",
    "    orig_train_acc,orig_test_acc=F.ETree(train_feature,train_label,test_feature,test_label,0)\n",
    "        \n",
    "    # Classification on selected features\n",
    "    C_train_selected_x,C_test_selected_x,C_train_y,C_test_y= train_test_split(train_compressed_Data,p_label_arr_onehot,test_size=0.2,random_state=p_seed)\n",
    "    \n",
    "    train_feature=C_train_selected_x\n",
    "    train_label=C_train_y\n",
    "    test_feature=C_test_selected_x\n",
    "    test_label=C_test_y\n",
    "    selec_train_acc,selec_test_acc=F.ETree(train_feature,train_label,test_feature,test_label,0)\n",
    "    \n",
    "    # Linear reconstruction\n",
    "    train_feature_tuple=(C_train_selected_x,C_train_x)\n",
    "    test_feature_tuple=(C_test_selected_x,C_test_x)\n",
    "\n",
    "    reconstruction_loss=mse_check(train_feature_tuple, test_feature_tuple)\n",
    "    \n",
    "    results=np.array([orig_train_acc,orig_test_acc,selec_train_acc,selec_test_acc,reconstruction_loss])\n",
    "    \n",
    "    write_to_csv(results.reshape(1,len(results)),\"./log\"+str(key_feture_number)+\"/CAE_results.csv\")\n",
    "    \n",
    "    return orig_train_acc,orig_test_acc,selec_train_acc,selec_test_acc,reconstruction_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_number=200\n",
    "\n",
    "p_data_arr=data_arr\n",
    "p_label_arr_onehot=label_arr_onehot\n",
    "p_key_feture_number=key_feture_number\n",
    "p_epochs_number=epochs_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1702: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "concrete_select (ConcreteSel (None, 55)                550001    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10000)             560000    \n",
      "=================================================================\n",
      "Total params: 1,110,001\n",
      "Trainable params: 1,110,000\n",
      "Non-trainable params: 1\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/200\n",
      "mean max of probabilities: 0.0001032471 - temperature 10.0\n",
      "160/160 [==============================] - 3s 21ms/step - loss: 0.0864 - val_loss: 0.0740\n",
      "Epoch 2/200\n",
      "mean max of probabilities: 0.00010324709 - temperature 9.705095\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.0640 - val_loss: 0.0570\n",
      "Epoch 3/200\n",
      "mean max of probabilities: 0.00010324869 - temperature 9.418887\n",
      "160/160 [==============================] - 2s 11ms/step - loss: 0.0519 - val_loss: 0.0491\n",
      "Epoch 4/200\n",
      "mean max of probabilities: 0.00010325396 - temperature 9.141122\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.0466 - val_loss: 0.0458\n",
      "Epoch 5/200\n",
      "mean max of probabilities: 0.000103261096 - temperature 8.871547\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.0443 - val_loss: 0.0445\n",
      "Epoch 6/200\n",
      "mean max of probabilities: 0.00010326777 - temperature 8.609923\n",
      "160/160 [==============================] - 2s 11ms/step - loss: 0.0434 - val_loss: 0.0441\n",
      "Epoch 7/200\n",
      "mean max of probabilities: 0.000103272956 - temperature 8.356012\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0430 - val_loss: 0.0441\n",
      "Epoch 8/200\n",
      "mean max of probabilities: 0.00010327678 - temperature 8.1095915\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0428 - val_loss: 0.0438\n",
      "Epoch 9/200\n",
      "mean max of probabilities: 0.00010327978 - temperature 7.8704367\n",
      "160/160 [==============================] - 2s 11ms/step - loss: 0.0427 - val_loss: 0.0438\n",
      "Epoch 10/200\n",
      "mean max of probabilities: 0.00010328257 - temperature 7.6383343\n",
      "160/160 [==============================] - 1s 8ms/step - loss: 0.0427 - val_loss: 0.0438\n",
      "Epoch 11/200\n",
      "mean max of probabilities: 0.000103285536 - temperature 7.413077\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0427 - val_loss: 0.0437\n",
      "Epoch 12/200\n",
      "mean max of probabilities: 0.000103288425 - temperature 7.1944623\n",
      "160/160 [==============================] - 1s 8ms/step - loss: 0.0426 - val_loss: 0.0438\n",
      "Epoch 13/200\n",
      "mean max of probabilities: 0.00010329109 - temperature 6.9822946\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0426 - val_loss: 0.0439\n",
      "Epoch 14/200\n",
      "mean max of probabilities: 0.00010329393 - temperature 6.7763844\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 0.0427 - val_loss: 0.0436\n",
      "Epoch 15/200\n",
      "mean max of probabilities: 0.0001032966 - temperature 6.576546\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 0.0425 - val_loss: 0.0436\n",
      "Epoch 16/200\n",
      "mean max of probabilities: 0.00010329982 - temperature 6.3826013\n",
      "160/160 [==============================] - 1s 8ms/step - loss: 0.0425 - val_loss: 0.0436\n",
      "Epoch 17/200\n",
      "mean max of probabilities: 0.00010330262 - temperature 6.194376\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0424 - val_loss: 0.0436\n",
      "Epoch 18/200\n",
      "mean max of probabilities: 0.000103304876 - temperature 6.0117006\n",
      "160/160 [==============================] - 1s 8ms/step - loss: 0.0424 - val_loss: 0.0434\n",
      "Epoch 19/200\n",
      "mean max of probabilities: 0.00010330661 - temperature 5.8344135\n",
      "160/160 [==============================] - 1s 8ms/step - loss: 0.0423 - val_loss: 0.0435\n",
      "Epoch 20/200\n",
      "mean max of probabilities: 0.00010330882 - temperature 5.662354\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 0.0423 - val_loss: 0.0432\n",
      "Epoch 21/200\n",
      "mean max of probabilities: 0.00010331108 - temperature 5.495369\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 0.0422 - val_loss: 0.0435\n",
      "Epoch 22/200\n",
      "mean max of probabilities: 0.00010331356 - temperature 5.3333087\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 0.0422 - val_loss: 0.0437\n",
      "Epoch 23/200\n",
      "mean max of probabilities: 0.00010331418 - temperature 5.176028\n",
      "160/160 [==============================] - 1s 8ms/step - loss: 0.0421 - val_loss: 0.0432\n",
      "Epoch 24/200\n",
      "mean max of probabilities: 0.00010331329 - temperature 5.023384\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0421 - val_loss: 0.0431\n",
      "Epoch 25/200\n",
      "mean max of probabilities: 0.00010331455 - temperature 4.8752427\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0420 - val_loss: 0.0431\n",
      "Epoch 26/200\n",
      "mean max of probabilities: 0.000103316415 - temperature 4.73147\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 0.0420 - val_loss: 0.0433\n",
      "Epoch 27/200\n",
      "mean max of probabilities: 0.00010331831 - temperature 4.5919366\n",
      "160/160 [==============================] - 2s 11ms/step - loss: 0.0420 - val_loss: 0.0431\n",
      "Epoch 28/200\n",
      "mean max of probabilities: 0.000103319646 - temperature 4.4565187\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0419 - val_loss: 0.0430\n",
      "Epoch 29/200\n",
      "mean max of probabilities: 0.00010332163 - temperature 4.325094\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0419 - val_loss: 0.0430\n",
      "Epoch 30/200\n",
      "mean max of probabilities: 0.00010332486 - temperature 4.1975446\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 0.0418 - val_loss: 0.0431\n",
      "Epoch 31/200\n",
      "mean max of probabilities: 0.000103328755 - temperature 4.0737567\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 0.0418 - val_loss: 0.0429\n",
      "Epoch 32/200\n",
      "mean max of probabilities: 0.000103331964 - temperature 3.9536202\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0417 - val_loss: 0.0431\n",
      "Epoch 33/200\n",
      "mean max of probabilities: 0.00010333647 - temperature 3.8370266\n",
      "160/160 [==============================] - 2s 9ms/step - loss: 0.0417 - val_loss: 0.0430\n",
      "Epoch 34/200\n",
      "mean max of probabilities: 0.00010334301 - temperature 3.7238712\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0416 - val_loss: 0.0428\n",
      "Epoch 35/200\n",
      "mean max of probabilities: 0.00010335234 - temperature 3.6140528\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 0.0416 - val_loss: 0.0427\n",
      "Epoch 36/200\n",
      "mean max of probabilities: 0.00010336463 - temperature 3.5074725\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0415 - val_loss: 0.0427\n",
      "Epoch 37/200\n",
      "mean max of probabilities: 0.0001033793 - temperature 3.4040358\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0415 - val_loss: 0.0428\n",
      "Epoch 38/200\n",
      "mean max of probabilities: 0.00010339651 - temperature 3.3036494\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0415 - val_loss: 0.0426\n",
      "Epoch 39/200\n",
      "mean max of probabilities: 0.00010341609 - temperature 3.2062237\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0414 - val_loss: 0.0427\n",
      "Epoch 40/200\n",
      "mean max of probabilities: 0.00010343802 - temperature 3.1116705\n",
      "160/160 [==============================] - 1s 8ms/step - loss: 0.0414 - val_loss: 0.0426\n",
      "Epoch 41/200\n",
      "mean max of probabilities: 0.00010346103 - temperature 3.0199058\n",
      "160/160 [==============================] - 1s 8ms/step - loss: 0.0413 - val_loss: 0.0425\n",
      "Epoch 42/200\n",
      "mean max of probabilities: 0.000103487066 - temperature 2.9308476\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0413 - val_loss: 0.0425\n",
      "Epoch 43/200\n",
      "mean max of probabilities: 0.000103514525 - temperature 2.8444157\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0412 - val_loss: 0.0425\n",
      "Epoch 44/200\n",
      "mean max of probabilities: 0.000103545804 - temperature 2.7605326\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0412 - val_loss: 0.0424\n",
      "Epoch 45/200\n",
      "mean max of probabilities: 0.00010357958 - temperature 2.6791236\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0411 - val_loss: 0.0425\n",
      "Epoch 46/200\n",
      "mean max of probabilities: 0.00010361819 - temperature 2.6001153\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0411 - val_loss: 0.0423\n",
      "Epoch 47/200\n",
      "mean max of probabilities: 0.00010366155 - temperature 2.5234365\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 0.0411 - val_loss: 0.0423\n",
      "Epoch 48/200\n",
      "mean max of probabilities: 0.00010370659 - temperature 2.4490192\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 0.0410 - val_loss: 0.0422\n",
      "Epoch 49/200\n",
      "mean max of probabilities: 0.00010375599 - temperature 2.3767967\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 0.0410 - val_loss: 0.0421\n",
      "Epoch 50/200\n",
      "mean max of probabilities: 0.0001038089 - temperature 2.306704\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 0.0409 - val_loss: 0.0423\n",
      "Epoch 51/200\n",
      "mean max of probabilities: 0.000103861355 - temperature 2.2386785\n",
      "160/160 [==============================] - 2s 9ms/step - loss: 0.0409 - val_loss: 0.0423\n",
      "Epoch 52/200\n",
      "mean max of probabilities: 0.00010392278 - temperature 2.172659\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0408 - val_loss: 0.0423\n",
      "Epoch 53/200\n",
      "mean max of probabilities: 0.00010398953 - temperature 2.108586\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 0.0409 - val_loss: 0.0418\n",
      "Epoch 54/200\n",
      "mean max of probabilities: 0.00010406581 - temperature 2.0464027\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0408 - val_loss: 0.0420\n",
      "Epoch 55/200\n",
      "mean max of probabilities: 0.00010414609 - temperature 1.9860538\n",
      "160/160 [==============================] - 2s 9ms/step - loss: 0.0407 - val_loss: 0.0420\n",
      "Epoch 56/200\n",
      "mean max of probabilities: 0.00010422383 - temperature 1.9274842\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0407 - val_loss: 0.0421\n",
      "Epoch 57/200\n",
      "mean max of probabilities: 0.000104309715 - temperature 1.8706421\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 0.0407 - val_loss: 0.0422\n",
      "Epoch 58/200\n",
      "mean max of probabilities: 0.0001044146 - temperature 1.8154762\n",
      "160/160 [==============================] - 2s 9ms/step - loss: 0.0408 - val_loss: 0.0416\n",
      "Epoch 59/200\n",
      "mean max of probabilities: 0.00010451244 - temperature 1.761937\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 0.0406 - val_loss: 0.0417\n",
      "Epoch 60/200\n",
      "mean max of probabilities: 0.00010460216 - temperature 1.7099768\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0405 - val_loss: 0.0420\n",
      "Epoch 61/200\n",
      "mean max of probabilities: 0.00010470871 - temperature 1.659549\n",
      "160/160 [==============================] - 2s 9ms/step - loss: 0.0404 - val_loss: 0.0418\n",
      "Epoch 62/200\n",
      "mean max of probabilities: 0.00010484745 - temperature 1.6106081\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0404 - val_loss: 0.0419\n",
      "Epoch 63/200\n",
      "mean max of probabilities: 0.00010499534 - temperature 1.5631108\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 0.0403 - val_loss: 0.0417\n",
      "Epoch 64/200\n",
      "mean max of probabilities: 0.00010513572 - temperature 1.5170141\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 0.0403 - val_loss: 0.0416\n",
      "Epoch 65/200\n",
      "mean max of probabilities: 0.00010530463 - temperature 1.4722769\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.0403 - val_loss: 0.0418\n",
      "Epoch 66/200\n",
      "mean max of probabilities: 0.00010546191 - temperature 1.4288589\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0403 - val_loss: 0.0413\n",
      "Epoch 67/200\n",
      "mean max of probabilities: 0.00010562926 - temperature 1.3867214\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0402 - val_loss: 0.0414\n",
      "Epoch 68/200\n",
      "mean max of probabilities: 0.00010579508 - temperature 1.3458263\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0402 - val_loss: 0.0414\n",
      "Epoch 69/200\n",
      "mean max of probabilities: 0.00010593705 - temperature 1.3061373\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0402 - val_loss: 0.0416\n",
      "Epoch 70/200\n",
      "mean max of probabilities: 0.00010608447 - temperature 1.267619\n",
      "160/160 [==============================] - 2s 11ms/step - loss: 0.0401 - val_loss: 0.0418\n",
      "Epoch 71/200\n",
      "mean max of probabilities: 0.00010627466 - temperature 1.2302365\n",
      "160/160 [==============================] - 2s 9ms/step - loss: 0.0401 - val_loss: 0.0414\n",
      "Epoch 72/200\n",
      "mean max of probabilities: 0.00010648627 - temperature 1.1939563\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 0.0400 - val_loss: 0.0415\n",
      "Epoch 73/200\n",
      "mean max of probabilities: 0.00010667663 - temperature 1.158746\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0403 - val_loss: 0.0410\n",
      "Epoch 74/200\n",
      "mean max of probabilities: 0.00010684822 - temperature 1.1245742\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0401 - val_loss: 0.0414\n",
      "Epoch 75/200\n",
      "mean max of probabilities: 0.00010704911 - temperature 1.09141\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 0.0400 - val_loss: 0.0416\n",
      "Epoch 76/200\n",
      "mean max of probabilities: 0.00010726269 - temperature 1.0592241\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 0.0401 - val_loss: 0.0413\n",
      "Epoch 77/200\n",
      "mean max of probabilities: 0.000107490574 - temperature 1.0279874\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 0.0400 - val_loss: 0.0415\n",
      "Epoch 78/200\n",
      "mean max of probabilities: 0.000107712476 - temperature 0.9976718\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0398 - val_loss: 0.0419\n",
      "Epoch 79/200\n",
      "mean max of probabilities: 0.00010791961 - temperature 0.96825004\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 0.0400 - val_loss: 0.0410\n",
      "Epoch 80/200\n",
      "mean max of probabilities: 0.00010816177 - temperature 0.939696\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0400 - val_loss: 0.0412\n",
      "Epoch 81/200\n",
      "mean max of probabilities: 0.000108361346 - temperature 0.911984\n",
      "160/160 [==============================] - 1s 8ms/step - loss: 0.0399 - val_loss: 0.0430\n",
      "Epoch 82/200\n",
      "mean max of probabilities: 0.000108557295 - temperature 0.8850892\n",
      "160/160 [==============================] - 1s 8ms/step - loss: 0.0400 - val_loss: 0.0413\n",
      "Epoch 83/200\n",
      "mean max of probabilities: 0.000108736516 - temperature 0.85898757\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0399 - val_loss: 0.0407\n",
      "Epoch 84/200\n",
      "mean max of probabilities: 0.00010887245 - temperature 0.83365566\n",
      "160/160 [==============================] - 2s 9ms/step - loss: 0.0395 - val_loss: 0.0419\n",
      "Epoch 85/200\n",
      "mean max of probabilities: 0.00010901269 - temperature 0.8090709\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 0.0401 - val_loss: 0.0431\n",
      "Epoch 86/200\n",
      "mean max of probabilities: 0.00010916837 - temperature 0.7852111\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0406 - val_loss: 0.0418\n",
      "Epoch 87/200\n",
      "mean max of probabilities: 0.000109319146 - temperature 0.762055\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 0.0407 - val_loss: 0.0412\n",
      "Epoch 88/200\n",
      "mean max of probabilities: 0.0001094726 - temperature 0.7395817\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0403 - val_loss: 0.0424\n",
      "Epoch 89/200\n",
      "mean max of probabilities: 0.0001096758 - temperature 0.7177711\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 0.0401 - val_loss: 0.0413\n",
      "Epoch 90/200\n",
      "mean max of probabilities: 0.000109892295 - temperature 0.69660366\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0406 - val_loss: 0.0407\n",
      "Epoch 91/200\n",
      "mean max of probabilities: 0.00011006824 - temperature 0.67606056\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0411 - val_loss: 0.0410\n",
      "Epoch 92/200\n",
      "mean max of probabilities: 0.00011025666 - temperature 0.6561233\n",
      "160/160 [==============================] - 2s 11ms/step - loss: 0.0404 - val_loss: 0.0427\n",
      "Epoch 93/200\n",
      "mean max of probabilities: 0.000110391215 - temperature 0.63677377\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0400 - val_loss: 0.0416\n",
      "Epoch 94/200\n",
      "mean max of probabilities: 0.000110515386 - temperature 0.617995\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 0.0393 - val_loss: 0.0436\n",
      "Epoch 95/200\n",
      "mean max of probabilities: 0.00011060266 - temperature 0.5997701\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0402 - val_loss: 0.0417\n",
      "Epoch 96/200\n",
      "mean max of probabilities: 0.00011068561 - temperature 0.5820826\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0415 - val_loss: 0.0420\n",
      "Epoch 97/200\n",
      "mean max of probabilities: 0.000110733425 - temperature 0.5649167\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0405 - val_loss: 0.0407\n",
      "Epoch 98/200\n",
      "mean max of probabilities: 0.000110809706 - temperature 0.5482572\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0401 - val_loss: 0.0415\n",
      "Epoch 99/200\n",
      "mean max of probabilities: 0.000110932044 - temperature 0.53208894\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0400 - val_loss: 0.0416\n",
      "Epoch 100/200\n",
      "mean max of probabilities: 0.00011102757 - temperature 0.51639754\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 0.0402 - val_loss: 0.0420\n",
      "Epoch 101/200\n",
      "mean max of probabilities: 0.00011112346 - temperature 0.50116867\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0399 - val_loss: 0.0416\n",
      "Epoch 102/200\n",
      "mean max of probabilities: 0.00011123556 - temperature 0.48638898\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0403 - val_loss: 0.0425\n",
      "Epoch 103/200\n",
      "mean max of probabilities: 0.000111327965 - temperature 0.47204518\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 0.0400 - val_loss: 0.0416\n",
      "Epoch 104/200\n",
      "mean max of probabilities: 0.000111428 - temperature 0.45812437\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 0.0394 - val_loss: 0.0413\n",
      "Epoch 105/200\n",
      "mean max of probabilities: 0.00011150275 - temperature 0.4446141\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 0.0393 - val_loss: 0.0409\n",
      "Epoch 106/200\n",
      "mean max of probabilities: 0.00011155894 - temperature 0.43150225\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 0.0402 - val_loss: 0.0425\n",
      "Epoch 107/200\n",
      "mean max of probabilities: 0.00011163916 - temperature 0.41877705\n",
      "160/160 [==============================] - 2s 11ms/step - loss: 0.0421 - val_loss: 0.0417\n",
      "Epoch 108/200\n",
      "mean max of probabilities: 0.00011172659 - temperature 0.40642717\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 0.0403 - val_loss: 0.0439\n",
      "Epoch 109/200\n",
      "mean max of probabilities: 0.00011177722 - temperature 0.3944415\n",
      "160/160 [==============================] - 2s 9ms/step - loss: 0.0414 - val_loss: 0.0414\n",
      "Epoch 110/200\n",
      "mean max of probabilities: 0.000111819136 - temperature 0.38280922\n",
      "160/160 [==============================] - 2s 11ms/step - loss: 0.0405 - val_loss: 0.0406\n",
      "Epoch 111/200\n",
      "mean max of probabilities: 0.00011186035 - temperature 0.37151998\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0390 - val_loss: 0.0435\n",
      "Epoch 112/200\n",
      "mean max of probabilities: 0.00011188414 - temperature 0.36056373\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0398 - val_loss: 0.0425\n",
      "Epoch 113/200\n",
      "mean max of probabilities: 0.00011190726 - temperature 0.34993058\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 0.0399 - val_loss: 0.0408\n",
      "Epoch 114/200\n",
      "mean max of probabilities: 0.000111957925 - temperature 0.33961096\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0410 - val_loss: 0.0393\n",
      "Epoch 115/200\n",
      "mean max of probabilities: 0.00011200736 - temperature 0.32959563\n",
      "160/160 [==============================] - 2s 11ms/step - loss: 0.0406 - val_loss: 0.0410\n",
      "Epoch 116/200\n",
      "mean max of probabilities: 0.0001120947 - temperature 0.31987572\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 0.0394 - val_loss: 0.0401\n",
      "Epoch 117/200\n",
      "mean max of probabilities: 0.000112154536 - temperature 0.31044245\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0398 - val_loss: 0.0407\n",
      "Epoch 118/200\n",
      "mean max of probabilities: 0.00011218117 - temperature 0.30128738\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0414 - val_loss: 0.0426\n",
      "Epoch 119/200\n",
      "mean max of probabilities: 0.00011220373 - temperature 0.2924023\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0395 - val_loss: 0.0414\n",
      "Epoch 120/200\n",
      "mean max of probabilities: 0.000112223664 - temperature 0.28377923\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0407 - val_loss: 0.0428\n",
      "Epoch 121/200\n",
      "mean max of probabilities: 0.00011227208 - temperature 0.2754104\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 0.0382 - val_loss: 0.0433\n",
      "Epoch 122/200\n",
      "mean max of probabilities: 0.00011233238 - temperature 0.2672884\n",
      "160/160 [==============================] - 2s 11ms/step - loss: 0.0402 - val_loss: 0.0404\n",
      "Epoch 123/200\n",
      "mean max of probabilities: 0.00011236997 - temperature 0.25940588\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0396 - val_loss: 0.0415\n",
      "Epoch 124/200\n",
      "mean max of probabilities: 0.000112419126 - temperature 0.2517559\n",
      "160/160 [==============================] - 2s 14ms/step - loss: 0.0408 - val_loss: 0.0430\n",
      "Epoch 125/200\n",
      "mean max of probabilities: 0.000112465 - temperature 0.24433151\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0397 - val_loss: 0.0452\n",
      "Epoch 126/200\n",
      "mean max of probabilities: 0.0001125032 - temperature 0.23712608\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 0.0391 - val_loss: 0.0423\n",
      "Epoch 127/200\n",
      "mean max of probabilities: 0.000112544105 - temperature 0.23013313\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0401 - val_loss: 0.0431\n",
      "Epoch 128/200\n",
      "mean max of probabilities: 0.00011258339 - temperature 0.22334641\n",
      "160/160 [==============================] - 2s 11ms/step - loss: 0.0396 - val_loss: 0.0378\n",
      "Epoch 129/200\n",
      "mean max of probabilities: 0.00011260958 - temperature 0.21675983\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 0.0391 - val_loss: 0.0413\n",
      "Epoch 130/200\n",
      "mean max of probabilities: 0.00011264389 - temperature 0.2103675\n",
      "160/160 [==============================] - 2s 11ms/step - loss: 0.0397 - val_loss: 0.0460\n",
      "Epoch 131/200\n",
      "mean max of probabilities: 0.00011267633 - temperature 0.20416367\n",
      "160/160 [==============================] - 2s 11ms/step - loss: 0.0408 - val_loss: 0.0431\n",
      "Epoch 132/200\n",
      "mean max of probabilities: 0.000112699185 - temperature 0.19814283\n",
      "160/160 [==============================] - 2s 11ms/step - loss: 0.0402 - val_loss: 0.0424\n",
      "Epoch 133/200\n",
      "mean max of probabilities: 0.000112728805 - temperature 0.19229952\n",
      "160/160 [==============================] - 2s 9ms/step - loss: 0.0416 - val_loss: 0.0413\n",
      "Epoch 134/200\n",
      "mean max of probabilities: 0.00011275159 - temperature 0.18662854\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 0.0411 - val_loss: 0.0444\n",
      "Epoch 135/200\n",
      "mean max of probabilities: 0.00011277696 - temperature 0.18112479\n",
      "160/160 [==============================] - 2s 11ms/step - loss: 0.0418 - val_loss: 0.0416\n",
      "Epoch 136/200\n",
      "mean max of probabilities: 0.00011279312 - temperature 0.17578335\n",
      "160/160 [==============================] - 2s 9ms/step - loss: 0.0404 - val_loss: 0.0384\n",
      "Epoch 137/200\n",
      "mean max of probabilities: 0.000112804584 - temperature 0.17059945\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 0.0390 - val_loss: 0.0407\n",
      "Epoch 138/200\n",
      "mean max of probabilities: 0.000112808986 - temperature 0.16556841\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 0.0411 - val_loss: 0.0397\n",
      "Epoch 139/200\n",
      "mean max of probabilities: 0.00011283409 - temperature 0.16068572\n",
      "160/160 [==============================] - 2s 9ms/step - loss: 0.0408 - val_loss: 0.0390\n",
      "Epoch 140/200\n",
      "mean max of probabilities: 0.000112881484 - temperature 0.15594701\n",
      "160/160 [==============================] - 2s 11ms/step - loss: 0.0409 - val_loss: 0.0395\n",
      "Epoch 141/200\n",
      "mean max of probabilities: 0.00011291954 - temperature 0.15134808\n",
      "160/160 [==============================] - 2s 9ms/step - loss: 0.0418 - val_loss: 0.0428\n",
      "Epoch 142/200\n",
      "mean max of probabilities: 0.00011296545 - temperature 0.14688475\n",
      "160/160 [==============================] - 2s 11ms/step - loss: 0.0399 - val_loss: 0.0409\n",
      "Epoch 143/200\n",
      "mean max of probabilities: 0.00011302038 - temperature 0.14255308\n",
      "160/160 [==============================] - 2s 11ms/step - loss: 0.0412 - val_loss: 0.0391\n",
      "Epoch 144/200\n",
      "mean max of probabilities: 0.000113051596 - temperature 0.13834915\n",
      "160/160 [==============================] - 2s 11ms/step - loss: 0.0401 - val_loss: 0.0435\n",
      "Epoch 145/200\n",
      "mean max of probabilities: 0.00011307239 - temperature 0.13426918\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 0.0396 - val_loss: 0.0425\n",
      "Epoch 146/200\n",
      "mean max of probabilities: 0.00011309162 - temperature 0.13030952\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0388 - val_loss: 0.0409\n",
      "Epoch 147/200\n",
      "mean max of probabilities: 0.00011311576 - temperature 0.12646663\n",
      "160/160 [==============================] - 2s 9ms/step - loss: 0.0405 - val_loss: 0.0403\n",
      "Epoch 148/200\n",
      "mean max of probabilities: 0.00011313747 - temperature 0.12273709\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 0.0406 - val_loss: 0.0407\n",
      "Epoch 149/200\n",
      "mean max of probabilities: 0.00011315978 - temperature 0.11911752\n",
      "160/160 [==============================] - 2s 11ms/step - loss: 0.0403 - val_loss: 0.0405\n",
      "Epoch 150/200\n",
      "mean max of probabilities: 0.000113176924 - temperature 0.1156047\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 0.0413 - val_loss: 0.0405\n",
      "Epoch 151/200\n",
      "mean max of probabilities: 0.00011319289 - temperature 0.11219547\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 0.0397 - val_loss: 0.0403\n",
      "Epoch 152/200\n",
      "mean max of probabilities: 0.00011319843 - temperature 0.10888678\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 0.0404 - val_loss: 0.0392\n",
      "Epoch 153/200\n",
      "mean max of probabilities: 0.00011320345 - temperature 0.10567566\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.0413 - val_loss: 0.0382\n",
      "Epoch 154/200\n",
      "mean max of probabilities: 0.00011322099 - temperature 0.10255923\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.0385 - val_loss: 0.0389\n",
      "Epoch 155/200\n",
      "mean max of probabilities: 0.00011322705 - temperature 0.1\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 0.0383 - val_loss: 0.0422\n",
      "Epoch 156/200\n",
      "mean max of probabilities: 0.000113229486 - temperature 0.1\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 0.0403 - val_loss: 0.0431\n",
      "Epoch 157/200\n",
      "mean max of probabilities: 0.000113250426 - temperature 0.1\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 0.0421 - val_loss: 0.0422\n",
      "Epoch 158/200\n",
      "mean max of probabilities: 0.000113282236 - temperature 0.1\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.0391 - val_loss: 0.0412\n",
      "Epoch 159/200\n",
      "mean max of probabilities: 0.000113304166 - temperature 0.1\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.0392 - val_loss: 0.0405\n",
      "Epoch 160/200\n",
      "mean max of probabilities: 0.000113325295 - temperature 0.1\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.0417 - val_loss: 0.0429\n",
      "Epoch 161/200\n",
      "mean max of probabilities: 0.00011333868 - temperature 0.1\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.0409 - val_loss: 0.0424\n",
      "Epoch 162/200\n",
      "mean max of probabilities: 0.0001133654 - temperature 0.1\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.0394 - val_loss: 0.0424\n",
      "Epoch 163/200\n",
      "mean max of probabilities: 0.0001133759 - temperature 0.1\n",
      "160/160 [==============================] - 2s 11ms/step - loss: 0.0389 - val_loss: 0.0398\n",
      "Epoch 164/200\n",
      "mean max of probabilities: 0.0001133795 - temperature 0.1\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 0.0390 - val_loss: 0.0401\n",
      "Epoch 165/200\n",
      "mean max of probabilities: 0.00011339666 - temperature 0.1\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 0.0382 - val_loss: 0.0479\n",
      "Epoch 166/200\n",
      "mean max of probabilities: 0.00011340321 - temperature 0.1\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.0429 - val_loss: 0.0392\n",
      "Epoch 167/200\n",
      "mean max of probabilities: 0.00011341506 - temperature 0.1\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.0405 - val_loss: 0.0393\n",
      "Epoch 168/200\n",
      "mean max of probabilities: 0.000113428105 - temperature 0.1\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.0386 - val_loss: 0.0404\n",
      "Epoch 169/200\n",
      "mean max of probabilities: 0.000113445705 - temperature 0.1\n",
      "160/160 [==============================] - 2s 14ms/step - loss: 0.0393 - val_loss: 0.0414\n",
      "Epoch 170/200\n",
      "mean max of probabilities: 0.00011345981 - temperature 0.1\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.0400 - val_loss: 0.0417\n",
      "Epoch 171/200\n",
      "mean max of probabilities: 0.000113471135 - temperature 0.1\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.0397 - val_loss: 0.0419\n",
      "Epoch 172/200\n",
      "mean max of probabilities: 0.00011347577 - temperature 0.1\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.0406 - val_loss: 0.0416\n",
      "Epoch 173/200\n",
      "mean max of probabilities: 0.0001134815 - temperature 0.1\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.0407 - val_loss: 0.0400\n",
      "Epoch 174/200\n",
      "mean max of probabilities: 0.00011349063 - temperature 0.1\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 0.0384 - val_loss: 0.0400\n",
      "Epoch 175/200\n",
      "mean max of probabilities: 0.00011349396 - temperature 0.1\n",
      "160/160 [==============================] - 2s 11ms/step - loss: 0.0388 - val_loss: 0.0414\n",
      "Epoch 176/200\n",
      "mean max of probabilities: 0.00011349936 - temperature 0.1\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 0.0380 - val_loss: 0.0415\n",
      "Epoch 177/200\n",
      "mean max of probabilities: 0.00011350213 - temperature 0.1\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.0389 - val_loss: 0.0381\n",
      "Epoch 178/200\n",
      "mean max of probabilities: 0.000113504284 - temperature 0.1\n",
      "160/160 [==============================] - 2s 11ms/step - loss: 0.0394 - val_loss: 0.0423\n",
      "Epoch 179/200\n",
      "mean max of probabilities: 0.00011353284 - temperature 0.1\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.0419 - val_loss: 0.0405\n",
      "Epoch 180/200\n",
      "mean max of probabilities: 0.0001135722 - temperature 0.1\n",
      "160/160 [==============================] - 2s 11ms/step - loss: 0.0422 - val_loss: 0.0409\n",
      "Epoch 181/200\n",
      "mean max of probabilities: 0.00011358847 - temperature 0.1\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.0400 - val_loss: 0.0394\n",
      "Epoch 182/200\n",
      "mean max of probabilities: 0.00011359438 - temperature 0.1\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.0388 - val_loss: 0.0436\n",
      "Epoch 183/200\n",
      "mean max of probabilities: 0.0001136034 - temperature 0.1\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 0.0402 - val_loss: 0.0450\n",
      "Epoch 184/200\n",
      "mean max of probabilities: 0.00011362419 - temperature 0.1\n",
      "160/160 [==============================] - 2s 11ms/step - loss: 0.0417 - val_loss: 0.0464\n",
      "Epoch 185/200\n",
      "mean max of probabilities: 0.000113650276 - temperature 0.1\n",
      "160/160 [==============================] - 2s 11ms/step - loss: 0.0385 - val_loss: 0.0408\n",
      "Epoch 186/200\n",
      "mean max of probabilities: 0.000113675174 - temperature 0.1\n",
      "160/160 [==============================] - 2s 14ms/step - loss: 0.0389 - val_loss: 0.0400\n",
      "Epoch 187/200\n",
      "mean max of probabilities: 0.00011372456 - temperature 0.1\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.0399 - val_loss: 0.0397\n",
      "Epoch 188/200\n",
      "mean max of probabilities: 0.00011376169 - temperature 0.1\n",
      "160/160 [==============================] - 2s 11ms/step - loss: 0.0381 - val_loss: 0.0424\n",
      "Epoch 189/200\n",
      "mean max of probabilities: 0.00011377528 - temperature 0.1\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.0402 - val_loss: 0.0433\n",
      "Epoch 190/200\n",
      "mean max of probabilities: 0.00011379589 - temperature 0.1\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.0402 - val_loss: 0.0385\n",
      "Epoch 191/200\n",
      "mean max of probabilities: 0.00011380534 - temperature 0.1\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 192/200\n",
      "mean max of probabilities: 0.000113810376 - temperature 0.1\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.0405 - val_loss: 0.0390\n",
      "Epoch 193/200\n",
      "mean max of probabilities: 0.00011381585 - temperature 0.1\n",
      "160/160 [==============================] - 2s 11ms/step - loss: 0.0391 - val_loss: 0.0394\n",
      "Epoch 194/200\n",
      "mean max of probabilities: 0.00011381963 - temperature 0.1\n",
      "160/160 [==============================] - 2s 11ms/step - loss: 0.0416 - val_loss: 0.0404\n",
      "Epoch 195/200\n",
      "mean max of probabilities: 0.00011383775 - temperature 0.1\n",
      "160/160 [==============================] - 2s 11ms/step - loss: 0.0397 - val_loss: 0.0398\n",
      "Epoch 196/200\n",
      "mean max of probabilities: 0.00011384652 - temperature 0.1\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 0.0390 - val_loss: 0.0431\n",
      "Epoch 197/200\n",
      "mean max of probabilities: 0.00011385373 - temperature 0.1\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 0.0390 - val_loss: 0.0438\n",
      "Epoch 198/200\n",
      "mean max of probabilities: 0.000113862276 - temperature 0.1\n",
      "160/160 [==============================] - 2s 11ms/step - loss: 0.0383 - val_loss: 0.0402\n",
      "Epoch 199/200\n",
      "mean max of probabilities: 0.00011387694 - temperature 0.1\n",
      "160/160 [==============================] - 2s 11ms/step - loss: 0.0418 - val_loss: 0.0415\n",
      "Epoch 200/200\n",
      "mean max of probabilities: 0.00011389518 - temperature 0.1\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.0404 - val_loss: 0.0400\n",
      "Training accuracy 1.0\n",
      "Training accuracy 1.0\n",
      "Testing accuracy 0.85\n",
      "Testing accuracy 0.85\n",
      "Training accuracy 1.0\n",
      "Training accuracy 1.0\n",
      "Testing accuracy 0.75\n",
      "Testing accuracy 0.75\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "concrete_select (ConcreteSel (None, 55)                550001    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10000)             560000    \n",
      "=================================================================\n",
      "Total params: 1,110,001\n",
      "Trainable params: 1,110,000\n",
      "Non-trainable params: 1\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/200\n",
      "mean max of probabilities: 0.00010324658 - temperature 10.0\n",
      "160/160 [==============================] - 3s 20ms/step - loss: 0.0862 - val_loss: 0.0727\n",
      "Epoch 2/200\n",
      "mean max of probabilities: 0.00010324651 - temperature 9.705095\n",
      "160/160 [==============================] - 2s 11ms/step - loss: 0.0638 - val_loss: 0.0565\n",
      "Epoch 3/200\n",
      "mean max of probabilities: 0.000103247236 - temperature 9.418887\n",
      "160/160 [==============================] - 2s 11ms/step - loss: 0.0518 - val_loss: 0.0490\n",
      "Epoch 4/200\n",
      "mean max of probabilities: 0.00010325135 - temperature 9.141122\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 0.0465 - val_loss: 0.0459\n",
      "Epoch 5/200\n",
      "mean max of probabilities: 0.00010325739 - temperature 8.871547\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.0444 - val_loss: 0.0445\n",
      "Epoch 6/200\n",
      "mean max of probabilities: 0.00010326261 - temperature 8.609923\n",
      "160/160 [==============================] - 2s 11ms/step - loss: 0.0435 - val_loss: 0.0439\n",
      "Epoch 7/200\n",
      "mean max of probabilities: 0.00010326653 - temperature 8.356012\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.0431 - val_loss: 0.0436\n",
      "Epoch 8/200\n",
      "mean max of probabilities: 0.000103269194 - temperature 8.1095915\n",
      "160/160 [==============================] - 2s 11ms/step - loss: 0.0430 - val_loss: 0.0435\n",
      "Epoch 9/200\n",
      "mean max of probabilities: 0.000103271115 - temperature 7.8704367\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 0.0429 - val_loss: 0.0435\n",
      "Epoch 10/200\n",
      "mean max of probabilities: 0.00010327269 - temperature 7.6383343\n",
      "160/160 [==============================] - 2s 11ms/step - loss: 0.0428 - val_loss: 0.0433\n",
      "Epoch 11/200\n",
      "mean max of probabilities: 0.000103274244 - temperature 7.413077\n",
      "160/160 [==============================] - 2s 11ms/step - loss: 0.0428 - val_loss: 0.0432\n",
      "Epoch 12/200\n",
      "mean max of probabilities: 0.00010327593 - temperature 7.1944623\n",
      "160/160 [==============================] - 2s 11ms/step - loss: 0.0427 - val_loss: 0.0432\n",
      "Epoch 13/200\n",
      "mean max of probabilities: 0.00010327771 - temperature 6.9822946\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 0.0427 - val_loss: 0.0433\n",
      "Epoch 14/200\n",
      "mean max of probabilities: 0.00010327965 - temperature 6.7763844\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.0427 - val_loss: 0.0433\n",
      "Epoch 15/200\n",
      "mean max of probabilities: 0.000103281294 - temperature 6.576546\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.0426 - val_loss: 0.0433\n",
      "Epoch 16/200\n",
      "mean max of probabilities: 0.000103282684 - temperature 6.3826013\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 0.0426 - val_loss: 0.0432\n",
      "Epoch 17/200\n",
      "mean max of probabilities: 0.000103283826 - temperature 6.194376\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 0.0426 - val_loss: 0.0429\n",
      "Epoch 18/200\n",
      "mean max of probabilities: 0.00010328496 - temperature 6.0117006\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 0.0425 - val_loss: 0.0431\n",
      "Epoch 19/200\n",
      "mean max of probabilities: 0.00010328648 - temperature 5.8344135\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 0.0425 - val_loss: 0.0431\n",
      "Epoch 20/200\n",
      "mean max of probabilities: 0.00010328761 - temperature 5.662354\n",
      "160/160 [==============================] - 2s 11ms/step - loss: 0.0424 - val_loss: 0.0430\n",
      "Epoch 21/200\n",
      "mean max of probabilities: 0.000103288476 - temperature 5.495369\n",
      "160/160 [==============================] - 2s 14ms/step - loss: 0.0424 - val_loss: 0.0428\n",
      "Epoch 22/200\n",
      "mean max of probabilities: 0.00010328891 - temperature 5.3333087\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.0423 - val_loss: 0.0428\n",
      "Epoch 23/200\n",
      "mean max of probabilities: 0.000103289975 - temperature 5.176028\n",
      "160/160 [==============================] - 2s 11ms/step - loss: 0.0423 - val_loss: 0.0427\n",
      "Epoch 24/200\n",
      "mean max of probabilities: 0.000103290884 - temperature 5.023384\n",
      "160/160 [==============================] - 2s 11ms/step - loss: 0.0423 - val_loss: 0.0427\n",
      "Epoch 25/200\n",
      "mean max of probabilities: 0.0001032919 - temperature 4.8752427\n",
      "160/160 [==============================] - 2s 11ms/step - loss: 0.0422 - val_loss: 0.0428\n",
      "Epoch 26/200\n",
      "mean max of probabilities: 0.000103293074 - temperature 4.73147\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.0422 - val_loss: 0.0429\n",
      "Epoch 27/200\n",
      "mean max of probabilities: 0.000103294165 - temperature 4.5919366\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.0422 - val_loss: 0.0426\n",
      "Epoch 28/200\n",
      "mean max of probabilities: 0.00010329656 - temperature 4.4565187\n",
      "160/160 [==============================] - 2s 11ms/step - loss: 0.0421 - val_loss: 0.0428\n",
      "Epoch 29/200\n",
      "mean max of probabilities: 0.00010330046 - temperature 4.325094\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.0420 - val_loss: 0.0425\n"
     ]
    }
   ],
   "source": [
    "for p_seed in np.arange(0,5):\n",
    "    orig_train_acc,orig_test_acc,selec_train_acc,selec_test_acc,reconstruction_loss=cal(p_data_arr,\\\n",
    "                                                                                        p_label_arr_onehot,\\\n",
    "                                                                                        p_key_feture_number,\\\n",
    "                                                                                        p_epochs_number,\\\n",
    "                                                                                        p_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

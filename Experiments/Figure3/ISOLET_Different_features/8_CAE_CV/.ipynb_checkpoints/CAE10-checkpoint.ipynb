{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#----------------------------Reproducible----------------------------------------------------------------------------------------\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "import os\n",
    "\n",
    "seed=0\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "np.random.seed(seed)\n",
    "rn.seed(seed)\n",
    "\n",
    "#----------------------------Reproducible----------------------------------------------------------------------------------------\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "import random\n",
    "import scipy.sparse as sparse\n",
    "import scipy.io\n",
    "import time\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skfeature.utility import construct_W\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from skfeature.utility.sparse_learning import feature_ranking\n",
    "import time\n",
    "from sklearn.impute import SimpleImputer \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from concrete_autoencoder import ConcreteAutoencoderFeatureSelector\n",
    "from keras.layers import Dense\n",
    "import pandas as pd\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "#Import ourslef defined methods\n",
    "import sys\n",
    "sys.path.append(r\"../Defined\")\n",
    "import Functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_frame=np.array(pd.read_csv('../Dataset/isolet1+2+3+4.data',header=None))\n",
    "test_data_frame=np.array(pd.read_csv('../Dataset/isolet5.data',header=None))\n",
    "\n",
    "train_data_arr=(train_data_frame[:,0:617]).copy()\n",
    "train_label_arr=((train_data_frame[:,617]).copy()-1)\n",
    "test_data_arr=(test_data_frame[:,0:617]).copy()\n",
    "test_label_arr=((test_data_frame[:,617]).copy()-1)\n",
    "\n",
    "data_arr=MinMaxScaler(feature_range=(0,1)).fit_transform(np.r_[train_data_arr,test_data_arr])\n",
    "\n",
    "label_arr_onehot=np.r_[train_label_arr,test_label_arr]#to_categorical(train_label_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_feture_number=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "def write_to_csv(p_data,p_path):\n",
    "    dataframe = pd.DataFrame(p_data)\n",
    "    dataframe.to_csv(p_path, mode='a',header=False,index=False,sep=',')\n",
    "    del dataframe\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------       \n",
    "def mse_check(train, test):\n",
    "    LR = LinearRegression(n_jobs = -1)\n",
    "    LR.fit(train[0], train[1])\n",
    "    MSELR = ((LR.predict(test[0]) - test[1]) ** 2).mean()\n",
    "    return MSELR\n",
    " \n",
    "#--------------------------------------------------------------------------------------------------------------------------------       \n",
    "def cal(p_data_arr,\\\n",
    "        p_label_arr_onehot,\\\n",
    "        p_key_feture_number,\\\n",
    "        p_epochs_number,\\\n",
    "        p_seed):\n",
    "    \n",
    "    C_train_x,C_test_x,C_train_y,C_test_y= train_test_split(p_data_arr,p_label_arr_onehot,test_size=0.2,random_state=p_seed)\n",
    "\n",
    "    os.environ['PYTHONHASHSEED'] = str(p_seed)\n",
    "    np.random.seed(p_seed)\n",
    "    rn.seed(p_seed)\n",
    "    tf.compat.v1.set_random_seed(p_seed)\n",
    "    \n",
    "    #--------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    def decoder(x):\n",
    "        #x = Dense(key_feture_number)(x)\n",
    "        x = Dense(data_arr.shape[1])(x)\n",
    "        return x\n",
    "\n",
    "    t_start = time.time()\n",
    "    selector = ConcreteAutoencoderFeatureSelector(K = p_key_feture_number, output_function = decoder, num_epochs = p_epochs_number)\n",
    "    selector.fit(C_train_x, C_train_x, C_test_x, C_test_x)\n",
    "    t_used=time.time() - t_start\n",
    "    \n",
    "    write_to_csv(np.array([t_used]),\"./log\"+str(key_feture_number)+\"/CAE_time.csv\")\n",
    "    \n",
    "    train_compressed_Data=p_data_arr[:, selector.get_support(indices=True)]\n",
    "    \n",
    "    # Classification on original features\n",
    "    train_feature=C_train_x\n",
    "    train_label=C_train_y\n",
    "    test_feature=C_test_x\n",
    "    test_label=C_test_y \n",
    "    orig_train_acc,orig_test_acc=F.ETree(train_feature,train_label,test_feature,test_label,0)\n",
    "        \n",
    "    # Classification on selected features\n",
    "    C_train_selected_x,C_test_selected_x,C_train_y,C_test_y= train_test_split(train_compressed_Data,p_label_arr_onehot,test_size=0.2,random_state=p_seed)\n",
    "    \n",
    "    train_feature=C_train_selected_x\n",
    "    train_label=C_train_y\n",
    "    test_feature=C_test_selected_x\n",
    "    test_label=C_test_y\n",
    "    selec_train_acc,selec_test_acc=F.ETree(train_feature,train_label,test_feature,test_label,0)\n",
    "    \n",
    "    # Linear reconstruction\n",
    "    train_feature_tuple=(C_train_selected_x,C_train_x)\n",
    "    test_feature_tuple=(C_test_selected_x,C_test_x)\n",
    "\n",
    "    reconstruction_loss=mse_check(train_feature_tuple, test_feature_tuple)\n",
    "    \n",
    "    results=np.array([orig_train_acc,orig_test_acc,selec_train_acc,selec_test_acc,reconstruction_loss])\n",
    "    \n",
    "    write_to_csv(results.reshape(1,len(results)),\"./log\"+str(key_feture_number)+\"/CAE_results.csv\")\n",
    "    \n",
    "    return orig_train_acc,orig_test_acc,selec_train_acc,selec_test_acc,reconstruction_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_number=200\n",
    "\n",
    "p_data_arr=data_arr\n",
    "p_label_arr_onehot=label_arr_onehot\n",
    "p_key_feture_number=key_feture_number\n",
    "p_epochs_number=epochs_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1702: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 617)               0         \n",
      "_________________________________________________________________\n",
      "concrete_select (ConcreteSel (None, 10)                6171      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 617)               6787      \n",
      "=================================================================\n",
      "Total params: 12,958\n",
      "Trainable params: 12,957\n",
      "Non-trainable params: 1\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 6237 samples, validate on 1560 samples\n",
      "Epoch 1/200\n",
      "mean max of probabilities: 0.0018368922 - temperature 10.0\n",
      "6237/6237 [==============================] - 23s 4ms/step - loss: 0.1020 - val_loss: 0.0473\n",
      "Epoch 2/200\n",
      "mean max of probabilities: 0.0019882603 - temperature 9.716229\n",
      "6237/6237 [==============================] - 12s 2ms/step - loss: 0.0473 - val_loss: 0.0473\n",
      "Epoch 3/200\n",
      "mean max of probabilities: 0.0020096474 - temperature 9.440515\n",
      "6237/6237 [==============================] - 12s 2ms/step - loss: 0.0473 - val_loss: 0.0473\n",
      "Epoch 4/200\n",
      "mean max of probabilities: 0.0020361887 - temperature 9.172621\n",
      "6237/6237 [==============================] - 12s 2ms/step - loss: 0.0473 - val_loss: 0.0472\n",
      "Epoch 5/200\n",
      "mean max of probabilities: 0.0020773974 - temperature 8.91233\n",
      "6237/6237 [==============================] - 11s 2ms/step - loss: 0.0472 - val_loss: 0.0470\n",
      "Epoch 6/200\n",
      "mean max of probabilities: 0.0021547223 - temperature 8.659425\n",
      "6237/6237 [==============================] - 11s 2ms/step - loss: 0.0471 - val_loss: 0.0470\n",
      "Epoch 7/200\n",
      "mean max of probabilities: 0.0022632678 - temperature 8.413696\n",
      "6237/6237 [==============================] - 9s 1ms/step - loss: 0.0470 - val_loss: 0.0469\n",
      "Epoch 8/200\n",
      "mean max of probabilities: 0.0024120153 - temperature 8.174943\n",
      "6237/6237 [==============================] - 10s 2ms/step - loss: 0.0470 - val_loss: 0.0471\n",
      "Epoch 9/200\n",
      "mean max of probabilities: 0.00259897 - temperature 7.9429646\n",
      "6237/6237 [==============================] - 10s 2ms/step - loss: 0.0469 - val_loss: 0.0467\n",
      "Epoch 10/200\n",
      "mean max of probabilities: 0.0028357212 - temperature 7.7175684\n",
      "6237/6237 [==============================] - 6s 1ms/step - loss: 0.0468 - val_loss: 0.0466\n",
      "Epoch 11/200\n",
      "mean max of probabilities: 0.0031234913 - temperature 7.498568\n",
      "6237/6237 [==============================] - 7s 1ms/step - loss: 0.0467 - val_loss: 0.0466\n",
      "Epoch 12/200\n",
      "mean max of probabilities: 0.003491162 - temperature 7.285782\n",
      "6237/6237 [==============================] - 5s 850us/step - loss: 0.0466 - val_loss: 0.0464\n",
      "Epoch 13/200\n",
      "mean max of probabilities: 0.0039456272 - temperature 7.079034\n",
      "6237/6237 [==============================] - 5s 801us/step - loss: 0.0464 - val_loss: 0.0462\n",
      "Epoch 14/200\n",
      "mean max of probabilities: 0.0045654415 - temperature 6.878153\n",
      "6237/6237 [==============================] - 7s 1ms/step - loss: 0.0462 - val_loss: 0.0459\n",
      "Epoch 15/200\n",
      "mean max of probabilities: 0.005405692 - temperature 6.68297\n",
      "6237/6237 [==============================] - 6s 920us/step - loss: 0.0459 - val_loss: 0.0455\n",
      "Epoch 16/200\n",
      "mean max of probabilities: 0.006442441 - temperature 6.4933286\n",
      "6237/6237 [==============================] - 8s 1ms/step - loss: 0.0454 - val_loss: 0.0448\n",
      "Epoch 17/200\n",
      "mean max of probabilities: 0.0076801516 - temperature 6.3090687\n",
      "6237/6237 [==============================] - 10s 2ms/step - loss: 0.0446 - val_loss: 0.0440\n",
      "Epoch 18/200\n",
      "mean max of probabilities: 0.009075897 - temperature 6.1300373\n",
      "6237/6237 [==============================] - 8s 1ms/step - loss: 0.0436 - val_loss: 0.0428\n",
      "Epoch 19/200\n",
      "mean max of probabilities: 0.010469924 - temperature 5.9560833\n",
      "6237/6237 [==============================] - 6s 925us/step - loss: 0.0422 - val_loss: 0.0413\n",
      "Epoch 20/200\n",
      "mean max of probabilities: 0.011823115 - temperature 5.7870684\n",
      "6237/6237 [==============================] - 4s 624us/step - loss: 0.0406 - val_loss: 0.0396\n",
      "Epoch 21/200\n",
      "mean max of probabilities: 0.013022369 - temperature 5.6228485\n",
      "6237/6237 [==============================] - 6s 955us/step - loss: 0.0389 - val_loss: 0.0380\n",
      "Epoch 22/200\n",
      "mean max of probabilities: 0.014103885 - temperature 5.4632907\n",
      "6237/6237 [==============================] - 5s 881us/step - loss: 0.0373 - val_loss: 0.0365\n",
      "Epoch 23/200\n",
      "mean max of probabilities: 0.015044269 - temperature 5.308259\n",
      "6237/6237 [==============================] - 5s 851us/step - loss: 0.0360 - val_loss: 0.0356\n",
      "Epoch 24/200\n",
      "mean max of probabilities: 0.015776321 - temperature 5.1576276\n",
      "6237/6237 [==============================] - 7s 1ms/step - loss: 0.0352 - val_loss: 0.0349\n",
      "Epoch 25/200\n",
      "mean max of probabilities: 0.016327875 - temperature 5.0112705\n",
      "6237/6237 [==============================] - 8s 1ms/step - loss: 0.0347 - val_loss: 0.0347\n",
      "Epoch 26/200\n",
      "mean max of probabilities: 0.01663447 - temperature 4.8690653\n",
      "6237/6237 [==============================] - 8s 1ms/step - loss: 0.0344 - val_loss: 0.0343\n",
      "Epoch 27/200\n",
      "mean max of probabilities: 0.016802458 - temperature 4.7308965\n",
      "6237/6237 [==============================] - 9s 1ms/step - loss: 0.0342 - val_loss: 0.0342\n",
      "Epoch 28/200\n",
      "mean max of probabilities: 0.016912146 - temperature 4.5966487\n",
      "6237/6237 [==============================] - 5s 817us/step - loss: 0.0341 - val_loss: 0.0341\n",
      "Epoch 29/200\n",
      "mean max of probabilities: 0.017214445 - temperature 4.4662094\n",
      "6237/6237 [==============================] - 7s 1ms/step - loss: 0.0340 - val_loss: 0.0340\n",
      "Epoch 30/200\n",
      "mean max of probabilities: 0.017740726 - temperature 4.339473\n",
      "6237/6237 [==============================] - 6s 999us/step - loss: 0.0339 - val_loss: 0.0339\n",
      "Epoch 31/200\n",
      "mean max of probabilities: 0.01870768 - temperature 4.2163315\n",
      "6237/6237 [==============================] - 7s 1ms/step - loss: 0.0337 - val_loss: 0.0337\n",
      "Epoch 32/200\n",
      "mean max of probabilities: 0.020501692 - temperature 4.0966854\n",
      "6237/6237 [==============================] - 6s 921us/step - loss: 0.0336 - val_loss: 0.0335\n",
      "Epoch 33/200\n",
      "mean max of probabilities: 0.022868687 - temperature 3.9804332\n",
      "6237/6237 [==============================] - 5s 829us/step - loss: 0.0334 - val_loss: 0.0334\n",
      "Epoch 34/200\n",
      "mean max of probabilities: 0.02559877 - temperature 3.8674803\n",
      "6237/6237 [==============================] - 4s 614us/step - loss: 0.0332 - val_loss: 0.0331\n",
      "Epoch 35/200\n",
      "mean max of probabilities: 0.028510058 - temperature 3.7577333\n",
      "6237/6237 [==============================] - 4s 641us/step - loss: 0.0329 - val_loss: 0.0329\n",
      "Epoch 36/200\n",
      "mean max of probabilities: 0.031666778 - temperature 3.6511\n",
      "6237/6237 [==============================] - 4s 672us/step - loss: 0.0326 - val_loss: 0.0326\n",
      "Epoch 37/200\n",
      "mean max of probabilities: 0.03500954 - temperature 3.5474925\n",
      "6237/6237 [==============================] - 4s 708us/step - loss: 0.0323 - val_loss: 0.0322\n",
      "Epoch 38/200\n",
      "mean max of probabilities: 0.03855524 - temperature 3.4468255\n",
      "6237/6237 [==============================] - 5s 726us/step - loss: 0.0319 - val_loss: 0.0319\n",
      "Epoch 39/200\n",
      "mean max of probabilities: 0.04192797 - temperature 3.3490164\n",
      "6237/6237 [==============================] - 4s 586us/step - loss: 0.0316 - val_loss: 0.0315\n",
      "Epoch 40/200\n",
      "mean max of probabilities: 0.045284748 - temperature 3.2539816\n",
      "6237/6237 [==============================] - 4s 613us/step - loss: 0.0312 - val_loss: 0.0312\n",
      "Epoch 41/200\n",
      "mean max of probabilities: 0.048467897 - temperature 3.1616435\n",
      "6237/6237 [==============================] - 5s 811us/step - loss: 0.0309 - val_loss: 0.0309\n",
      "Epoch 42/200\n",
      "mean max of probabilities: 0.052669078 - temperature 3.0719256\n",
      "6237/6237 [==============================] - 6s 962us/step - loss: 0.0306 - val_loss: 0.0306\n",
      "Epoch 43/200\n",
      "mean max of probabilities: 0.05688739 - temperature 2.9847543\n",
      "6237/6237 [==============================] - 5s 875us/step - loss: 0.0303 - val_loss: 0.0303\n",
      "Epoch 44/200\n",
      "mean max of probabilities: 0.061504792 - temperature 2.9000561\n",
      "6237/6237 [==============================] - 6s 1ms/step - loss: 0.0301 - val_loss: 0.0301\n",
      "Epoch 45/200\n",
      "mean max of probabilities: 0.06636112 - temperature 2.8177617\n",
      "6237/6237 [==============================] - 10s 2ms/step - loss: 0.0298 - val_loss: 0.0298\n",
      "Epoch 46/200\n",
      "mean max of probabilities: 0.071674846 - temperature 2.737801\n",
      "6237/6237 [==============================] - 7s 1ms/step - loss: 0.0296 - val_loss: 0.0295\n",
      "Epoch 47/200\n",
      "mean max of probabilities: 0.07765709 - temperature 2.6601112\n",
      "6237/6237 [==============================] - 4s 618us/step - loss: 0.0292 - val_loss: 0.0292\n",
      "Epoch 48/200\n",
      "mean max of probabilities: 0.08463124 - temperature 2.5846252\n",
      "6237/6237 [==============================] - 4s 591us/step - loss: 0.0289 - val_loss: 0.0288\n",
      "Epoch 49/200\n",
      "mean max of probabilities: 0.09178806 - temperature 2.5112817\n",
      "6237/6237 [==============================] - 4s 700us/step - loss: 0.0285 - val_loss: 0.0284\n",
      "Epoch 50/200\n",
      "mean max of probabilities: 0.09980366 - temperature 2.4400187\n",
      "6237/6237 [==============================] - 4s 649us/step - loss: 0.0281 - val_loss: 0.0279\n",
      "Epoch 51/200\n",
      "mean max of probabilities: 0.10773301 - temperature 2.3707783\n",
      "6237/6237 [==============================] - 4s 597us/step - loss: 0.0277 - val_loss: 0.0276\n",
      "Epoch 52/200\n",
      "mean max of probabilities: 0.11598978 - temperature 2.303502\n",
      "6237/6237 [==============================] - 4s 694us/step - loss: 0.0273 - val_loss: 0.0272\n",
      "Epoch 53/200\n",
      "mean max of probabilities: 0.121884406 - temperature 2.2381356\n",
      "6237/6237 [==============================] - 8s 1ms/step - loss: 0.0269 - val_loss: 0.0268\n",
      "Epoch 54/200\n",
      "mean max of probabilities: 0.12609804 - temperature 2.1746244\n",
      "6237/6237 [==============================] - 8s 1ms/step - loss: 0.0265 - val_loss: 0.0266\n",
      "Epoch 55/200\n",
      "mean max of probabilities: 0.12803602 - temperature 2.1129148\n",
      "6237/6237 [==============================] - 8s 1ms/step - loss: 0.0263 - val_loss: 0.0262\n",
      "Epoch 56/200\n",
      "mean max of probabilities: 0.12954216 - temperature 2.0529566\n",
      "6237/6237 [==============================] - 7s 1ms/step - loss: 0.0261 - val_loss: 0.0260\n",
      "Epoch 57/200\n",
      "mean max of probabilities: 0.12867583 - temperature 1.9947006\n",
      "6237/6237 [==============================] - 5s 838us/step - loss: 0.0258 - val_loss: 0.0258\n",
      "Epoch 58/200\n",
      "mean max of probabilities: 0.12832072 - temperature 1.9380969\n",
      "6237/6237 [==============================] - 8s 1ms/step - loss: 0.0256 - val_loss: 0.0257\n",
      "Epoch 59/200\n",
      "mean max of probabilities: 0.12740964 - temperature 1.8831\n",
      "6237/6237 [==============================] - 9s 1ms/step - loss: 0.0255 - val_loss: 0.0254\n",
      "Epoch 60/200\n",
      "mean max of probabilities: 0.12635428 - temperature 1.8296632\n",
      "6237/6237 [==============================] - 9s 1ms/step - loss: 0.0255 - val_loss: 0.0254\n",
      "Epoch 61/200\n",
      "mean max of probabilities: 0.12493682 - temperature 1.7777432\n",
      "6237/6237 [==============================] - 11s 2ms/step - loss: 0.0254 - val_loss: 0.0254\n",
      "Epoch 62/200\n",
      "mean max of probabilities: 0.12170999 - temperature 1.7272961\n",
      "6237/6237 [==============================] - 10s 2ms/step - loss: 0.0254 - val_loss: 0.0254\n",
      "Epoch 63/200\n",
      "mean max of probabilities: 0.118190564 - temperature 1.6782807\n",
      "6237/6237 [==============================] - 9s 1ms/step - loss: 0.0255 - val_loss: 0.0255\n",
      "Epoch 64/200\n",
      "mean max of probabilities: 0.11612101 - temperature 1.6306561\n",
      "6237/6237 [==============================] - 10s 2ms/step - loss: 0.0254 - val_loss: 0.0255\n",
      "Epoch 65/200\n",
      "mean max of probabilities: 0.11501596 - temperature 1.584383\n",
      "6237/6237 [==============================] - 8s 1ms/step - loss: 0.0255 - val_loss: 0.0255\n",
      "Epoch 66/200\n",
      "mean max of probabilities: 0.11526887 - temperature 1.5394229\n",
      "6237/6237 [==============================] - 9s 1ms/step - loss: 0.0255 - val_loss: 0.0257\n",
      "Epoch 67/200\n",
      "mean max of probabilities: 0.115745686 - temperature 1.4957385\n",
      "6237/6237 [==============================] - 8s 1ms/step - loss: 0.0256 - val_loss: 0.0256\n",
      "Epoch 68/200\n",
      "mean max of probabilities: 0.1164781 - temperature 1.453294\n",
      "6237/6237 [==============================] - 7s 1ms/step - loss: 0.0255 - val_loss: 0.0257\n",
      "Epoch 69/200\n",
      "mean max of probabilities: 0.11830763 - temperature 1.4120538\n",
      "6237/6237 [==============================] - 7s 1ms/step - loss: 0.0257 - val_loss: 0.0257\n",
      "Epoch 70/200\n",
      "mean max of probabilities: 0.11937938 - temperature 1.371984\n",
      "6237/6237 [==============================] - 4s 610us/step - loss: 0.0260 - val_loss: 0.0259\n",
      "Epoch 71/200\n",
      "mean max of probabilities: 0.12177777 - temperature 1.3330511\n",
      "6237/6237 [==============================] - 4s 660us/step - loss: 0.0260 - val_loss: 0.0261\n",
      "Epoch 72/200\n",
      "mean max of probabilities: 0.12303193 - temperature 1.2952231\n",
      "6237/6237 [==============================] - 4s 639us/step - loss: 0.0258 - val_loss: 0.0263\n",
      "Epoch 73/200\n",
      "mean max of probabilities: 0.124378346 - temperature 1.2584686\n",
      "6237/6237 [==============================] - 3s 526us/step - loss: 0.0260 - val_loss: 0.0261\n",
      "Epoch 74/200\n",
      "mean max of probabilities: 0.12572463 - temperature 1.2227571\n",
      "6237/6237 [==============================] - 3s 531us/step - loss: 0.0262 - val_loss: 0.0260\n",
      "Epoch 75/200\n",
      "mean max of probabilities: 0.1279479 - temperature 1.1880591\n",
      "6237/6237 [==============================] - 3s 560us/step - loss: 0.0262 - val_loss: 0.0264\n",
      "Epoch 76/200\n",
      "mean max of probabilities: 0.13045244 - temperature 1.1543458\n",
      "6237/6237 [==============================] - 3s 522us/step - loss: 0.0264 - val_loss: 0.0266\n",
      "Epoch 77/200\n",
      "mean max of probabilities: 0.13302454 - temperature 1.1215891\n",
      "6237/6237 [==============================] - 5s 809us/step - loss: 0.0265 - val_loss: 0.0266\n",
      "Epoch 78/200\n",
      "mean max of probabilities: 0.13488732 - temperature 1.0897619\n",
      "6237/6237 [==============================] - 5s 756us/step - loss: 0.0265 - val_loss: 0.0263\n",
      "Epoch 79/200\n",
      "mean max of probabilities: 0.13733727 - temperature 1.0588379\n",
      "6237/6237 [==============================] - 7s 1ms/step - loss: 0.0267 - val_loss: 0.0266\n",
      "Epoch 80/200\n",
      "mean max of probabilities: 0.13973892 - temperature 1.0287911\n",
      "6237/6237 [==============================] - 6s 970us/step - loss: 0.0270 - val_loss: 0.0269\n",
      "Epoch 81/200\n",
      "mean max of probabilities: 0.1417264 - temperature 0.99959683\n",
      "6237/6237 [==============================] - 5s 766us/step - loss: 0.0268 - val_loss: 0.0268\n",
      "Epoch 82/200\n",
      "mean max of probabilities: 0.14434695 - temperature 0.97123134\n",
      "6237/6237 [==============================] - 4s 581us/step - loss: 0.0270 - val_loss: 0.0274\n",
      "Epoch 83/200\n",
      "mean max of probabilities: 0.14843461 - temperature 0.9436705\n",
      "6237/6237 [==============================] - 3s 461us/step - loss: 0.0274 - val_loss: 0.0270\n",
      "Epoch 84/200\n",
      "mean max of probabilities: 0.15229593 - temperature 0.916892\n",
      "6237/6237 [==============================] - 4s 711us/step - loss: 0.0272 - val_loss: 0.0275\n",
      "Epoch 85/200\n",
      "mean max of probabilities: 0.15593013 - temperature 0.89087355\n",
      "6237/6237 [==============================] - 5s 773us/step - loss: 0.0274 - val_loss: 0.0274\n",
      "Epoch 86/200\n",
      "mean max of probabilities: 0.15888172 - temperature 0.8655933\n",
      "6237/6237 [==============================] - 4s 592us/step - loss: 0.0273 - val_loss: 0.0273\n",
      "Epoch 87/200\n",
      "mean max of probabilities: 0.1643627 - temperature 0.8410305\n",
      "6237/6237 [==============================] - 5s 773us/step - loss: 0.0276 - val_loss: 0.0277\n",
      "Epoch 88/200\n",
      "mean max of probabilities: 0.169753 - temperature 0.8171646\n",
      "6237/6237 [==============================] - 5s 767us/step - loss: 0.0275 - val_loss: 0.0279\n",
      "Epoch 89/200\n",
      "mean max of probabilities: 0.17456546 - temperature 0.7939759\n",
      "3000/6237 [=============>................] - ETA: 3s - loss: 0.0276"
     ]
    }
   ],
   "source": [
    "for p_seed in np.arange(0,50):\n",
    "    orig_train_acc,orig_test_acc,selec_train_acc,selec_test_acc,reconstruction_loss=cal(p_data_arr,\\\n",
    "                                                                                        p_label_arr_onehot,\\\n",
    "                                                                                        p_key_feture_number,\\\n",
    "                                                                                        p_epochs_number,\\\n",
    "                                                                                        p_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

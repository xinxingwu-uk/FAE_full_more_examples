{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#----------------------------Reproducible----------------------------------------------------------------------------------------\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "import os\n",
    "\n",
    "seed=0\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "np.random.seed(seed)\n",
    "rn.seed(seed)\n",
    "\n",
    "#----------------------------Reproducible----------------------------------------------------------------------------------------\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "import random\n",
    "import scipy.sparse as sparse\n",
    "import scipy.io\n",
    "import time\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skfeature.utility import construct_W\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from skfeature.utility.sparse_learning import feature_ranking\n",
    "import time\n",
    "from sklearn.impute import SimpleImputer \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from concrete_autoencoder import ConcreteAutoencoderFeatureSelector\n",
    "from keras.layers import Dense\n",
    "import pandas as pd\n",
    "from skimage import io\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.sparse as sparse\n",
    "from keras.datasets import fashion_mnist\n",
    "import scipy.io\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "#Import ourslef defined methods\n",
    "import sys\n",
    "sys.path.append(r\"../Defined\")\n",
    "import Functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=\"../Dataset/pixraw10P.mat\"\n",
    "Data = scipy.io.loadmat(data_path)\n",
    "\n",
    "data_arr=Data['X'].astype('float32')/255\n",
    "label_arr=Data['Y'][:, 0]\n",
    "label_arr_onehot=label_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_feture_number=64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "def write_to_csv(p_data,p_path):\n",
    "    dataframe = pd.DataFrame(p_data)\n",
    "    dataframe.to_csv(p_path, mode='a',header=False,index=False,sep=',')\n",
    "    del dataframe\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------       \n",
    "def mse_check(train, test):\n",
    "    LR = LinearRegression(n_jobs = -1)\n",
    "    LR.fit(train[0], train[1])\n",
    "    MSELR = ((LR.predict(test[0]) - test[1]) ** 2).mean()\n",
    "    return MSELR\n",
    " \n",
    "#--------------------------------------------------------------------------------------------------------------------------------       \n",
    "def cal(p_data_arr,\\\n",
    "        p_label_arr_onehot,\\\n",
    "        p_key_feture_number,\\\n",
    "        p_epochs_number,\\\n",
    "        p_seed):\n",
    "    \n",
    "    C_train_x,C_test_x,C_train_y,C_test_y= train_test_split(p_data_arr,p_label_arr_onehot,test_size=0.2,random_state=p_seed)\n",
    "\n",
    "    os.environ['PYTHONHASHSEED'] = str(p_seed)\n",
    "    np.random.seed(p_seed)\n",
    "    rn.seed(p_seed)\n",
    "    tf.compat.v1.set_random_seed(p_seed)\n",
    "    \n",
    "    #--------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    def decoder(x):\n",
    "        #x = Dense(key_feture_number)(x)\n",
    "        x = Dense(data_arr.shape[1])(x)\n",
    "        return x\n",
    "\n",
    "    t_start = time.time()\n",
    "    selector = ConcreteAutoencoderFeatureSelector(K = p_key_feture_number, output_function = decoder, num_epochs = p_epochs_number)\n",
    "    selector.fit(C_train_x, C_train_x, C_test_x, C_test_x)\n",
    "    t_used=time.time() - t_start\n",
    "    \n",
    "    write_to_csv(np.array([t_used]),\"./log/CAE_time.csv\")\n",
    "    \n",
    "    train_compressed_Data=p_data_arr[:, selector.get_support(indices=True)]\n",
    "    \n",
    "    # Classification on original features\n",
    "    train_feature=C_train_x\n",
    "    train_label=C_train_y\n",
    "    test_feature=C_test_x\n",
    "    test_label=C_test_y \n",
    "    orig_train_acc,orig_test_acc=F.ETree(train_feature,train_label,test_feature,test_label,0)\n",
    "        \n",
    "    # Classification on selected features\n",
    "    C_train_selected_x,C_test_selected_x,C_train_y,C_test_y= train_test_split(train_compressed_Data,p_label_arr_onehot,test_size=0.2,random_state=p_seed)\n",
    "    \n",
    "    train_feature=C_train_selected_x\n",
    "    train_label=C_train_y\n",
    "    test_feature=C_test_selected_x\n",
    "    test_label=C_test_y\n",
    "    selec_train_acc,selec_test_acc=F.ETree(train_feature,train_label,test_feature,test_label,0)\n",
    "    \n",
    "    # Linear reconstruction\n",
    "    train_feature_tuple=(C_train_selected_x,C_train_x)\n",
    "    test_feature_tuple=(C_test_selected_x,C_test_x)\n",
    "\n",
    "    reconstruction_loss=mse_check(train_feature_tuple, test_feature_tuple)\n",
    "    \n",
    "    results=np.array([orig_train_acc,orig_test_acc,selec_train_acc,selec_test_acc,reconstruction_loss])\n",
    "    \n",
    "    write_to_csv(results.reshape(1,len(results)),\"./log/CAE_results.csv\")\n",
    "    \n",
    "    return orig_train_acc,orig_test_acc,selec_train_acc,selec_test_acc,reconstruction_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_number=200\n",
    "\n",
    "p_data_arr=data_arr\n",
    "p_label_arr_onehot=label_arr_onehot\n",
    "p_key_feture_number=key_feture_number\n",
    "p_epochs_number=epochs_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "concrete_select (ConcreteSel (None, 64)                640001    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10000)             650000    \n",
      "=================================================================\n",
      "Total params: 1,290,001\n",
      "Trainable params: 1,290,000\n",
      "Non-trainable params: 1\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/200\n",
      "mean max of probabilities: 0.0001032453 - temperature 10.0\n",
      "80/80 [==============================] - 5s 62ms/step - loss: 0.0184 - val_loss: 0.0164\n",
      "Epoch 2/200\n",
      "mean max of probabilities: 0.0001032453 - temperature 9.682779\n",
      "80/80 [==============================] - 3s 40ms/step - loss: 0.0125 - val_loss: 0.0104\n",
      "Epoch 3/200\n",
      "mean max of probabilities: 0.0001032453 - temperature 9.375622\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 0.0076 - val_loss: 0.0065\n",
      "Epoch 4/200\n",
      "mean max of probabilities: 0.00010324533 - temperature 9.078209\n",
      "80/80 [==============================] - 6s 69ms/step - loss: 0.0048 - val_loss: 0.0042\n",
      "Epoch 5/200\n",
      "mean max of probabilities: 0.00010324538 - temperature 8.790229\n",
      "80/80 [==============================] - 3s 38ms/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 6/200\n",
      "mean max of probabilities: 0.00010324545 - temperature 8.511385\n",
      "80/80 [==============================] - 33s 419ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 7/200\n",
      "mean max of probabilities: 0.00010324552 - temperature 8.241387\n",
      "80/80 [==============================] - 10s 127ms/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 8/200\n",
      "mean max of probabilities: 0.00010324558 - temperature 7.979954\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 9/200\n",
      "mean max of probabilities: 0.000103245584 - temperature 7.7268133\n",
      "80/80 [==============================] - 4s 45ms/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 10/200\n",
      "mean max of probabilities: 0.00010324556 - temperature 7.481703\n",
      "80/80 [==============================] - 4s 53ms/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 11/200\n",
      "mean max of probabilities: 0.00010324552 - temperature 7.244368\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 12/200\n",
      "mean max of probabilities: 0.00010324549 - temperature 7.0145626\n",
      "80/80 [==============================] - 11s 138ms/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 13/200\n",
      "mean max of probabilities: 0.00010324545 - temperature 6.792047\n",
      "80/80 [==============================] - 13s 165ms/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 14/200\n",
      "mean max of probabilities: 0.00010324543 - temperature 6.5765896\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 15/200\n",
      "mean max of probabilities: 0.00010324543 - temperature 6.3679667\n",
      "80/80 [==============================] - 13s 161ms/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 16/200\n",
      "mean max of probabilities: 0.00010324543 - temperature 6.1659613\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 17/200\n",
      "mean max of probabilities: 0.000103245446 - temperature 5.9703646\n",
      "80/80 [==============================] - 3s 39ms/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 18/200\n",
      "mean max of probabilities: 0.00010324547 - temperature 5.780973\n",
      "80/80 [==============================] - 3s 32ms/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 19/200\n",
      "mean max of probabilities: 0.0001032455 - temperature 5.597588\n",
      "80/80 [==============================] - 3s 35ms/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 20/200\n",
      "mean max of probabilities: 0.00010324553 - temperature 5.4200206\n",
      "80/80 [==============================] - 3s 35ms/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 21/200\n",
      "mean max of probabilities: 0.000103245555 - temperature 5.2480865\n",
      "80/80 [==============================] - 3s 35ms/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 22/200\n",
      "mean max of probabilities: 0.00010324559 - temperature 5.0816064\n",
      "80/80 [==============================] - 3s 41ms/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 23/200\n",
      "mean max of probabilities: 0.00010324562 - temperature 4.920408\n",
      "80/80 [==============================] - 3s 36ms/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 24/200\n",
      "mean max of probabilities: 0.000103245664 - temperature 4.7643223\n",
      "80/80 [==============================] - 3s 40ms/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 25/200\n",
      "mean max of probabilities: 0.0001032457 - temperature 4.6131873\n",
      "80/80 [==============================] - 3s 42ms/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 26/200\n",
      "mean max of probabilities: 0.000103245744 - temperature 4.466848\n",
      "80/80 [==============================] - 3s 34ms/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 27/200\n",
      "mean max of probabilities: 0.0001032458 - temperature 4.32515\n",
      "80/80 [==============================] - 3s 37ms/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 28/200\n",
      "mean max of probabilities: 0.00010324585 - temperature 4.1879478\n",
      "80/80 [==============================] - 2s 30ms/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 29/200\n",
      "mean max of probabilities: 0.000103245926 - temperature 4.055098\n",
      "80/80 [==============================] - 3s 41ms/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 30/200\n",
      "mean max of probabilities: 0.000103245984 - temperature 3.9264624\n",
      "80/80 [==============================] - 3s 34ms/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 31/200\n",
      "mean max of probabilities: 0.000103246064 - temperature 3.801907\n",
      "80/80 [==============================] - 3s 41ms/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 32/200\n",
      "mean max of probabilities: 0.00010324616 - temperature 3.6813028\n",
      "80/80 [==============================] - 11s 133ms/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 33/200\n",
      "mean max of probabilities: 0.00010324626 - temperature 3.5645244\n",
      "80/80 [==============================] - 4s 54ms/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 34/200\n",
      "mean max of probabilities: 0.00010324638 - temperature 3.4514508\n",
      "80/80 [==============================] - 6s 80ms/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 35/200\n",
      "mean max of probabilities: 0.00010324649 - temperature 3.341964\n",
      "80/80 [==============================] - 5s 57ms/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 36/200\n",
      "mean max of probabilities: 0.00010324664 - temperature 3.23595\n",
      "80/80 [==============================] - 3s 42ms/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 37/200\n",
      "mean max of probabilities: 0.0001032468 - temperature 3.133299\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 38/200\n",
      "mean max of probabilities: 0.00010324699 - temperature 3.0339048\n",
      "80/80 [==============================] - 3s 42ms/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 39/200\n",
      "mean max of probabilities: 0.00010324721 - temperature 2.9376633\n",
      "80/80 [==============================] - 3s 36ms/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 40/200\n",
      "mean max of probabilities: 0.00010324746 - temperature 2.8444746\n",
      "80/80 [==============================] - 3s 40ms/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 41/200\n",
      "mean max of probabilities: 0.00010324773 - temperature 2.7542422\n",
      "80/80 [==============================] - 3s 33ms/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 42/200\n",
      "mean max of probabilities: 0.00010324801 - temperature 2.666872\n",
      "80/80 [==============================] - 3s 39ms/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 43/200\n",
      "mean max of probabilities: 0.00010324829 - temperature 2.5822737\n",
      "80/80 [==============================] - 3s 35ms/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 44/200\n",
      "mean max of probabilities: 0.00010324861 - temperature 2.5003588\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 45/200\n",
      "mean max of probabilities: 0.00010324893 - temperature 2.4210424\n",
      "80/80 [==============================] - 3s 41ms/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 46/200\n",
      "mean max of probabilities: 0.000103249244 - temperature 2.344242\n",
      "80/80 [==============================] - 3s 37ms/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 47/200\n",
      "mean max of probabilities: 0.00010324961 - temperature 2.269878\n",
      "80/80 [==============================] - 3s 37ms/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 48/200\n",
      "mean max of probabilities: 0.00010324995 - temperature 2.1978726\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 49/200\n",
      "mean max of probabilities: 0.00010325035 - temperature 2.1281517\n",
      "80/80 [==============================] - 3s 41ms/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 50/200\n",
      "mean max of probabilities: 0.000103250786 - temperature 2.0606422\n",
      "80/80 [==============================] - 3s 39ms/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 51/200\n",
      "mean max of probabilities: 0.00010325125 - temperature 1.9952742\n",
      "80/80 [==============================] - 3s 42ms/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 52/200\n",
      "mean max of probabilities: 0.00010325172 - temperature 1.93198\n",
      "80/80 [==============================] - 4s 45ms/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 53/200\n",
      "mean max of probabilities: 0.00010325221 - temperature 1.8706938\n",
      "80/80 [==============================] - 4s 45ms/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 54/200\n",
      "mean max of probabilities: 0.00010325283 - temperature 1.8113518\n",
      "80/80 [==============================] - 4s 48ms/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 55/200\n",
      "mean max of probabilities: 0.000103253406 - temperature 1.7538921\n"
     ]
    }
   ],
   "source": [
    "for p_seed in np.arange(0,50):\n",
    "    orig_train_acc,orig_test_acc,selec_train_acc,selec_test_acc,reconstruction_loss=cal(p_data_arr,\\\n",
    "                                                                                        p_label_arr_onehot,\\\n",
    "                                                                                        p_key_feture_number,\\\n",
    "                                                                                        p_epochs_number,\\\n",
    "                                                                                        p_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

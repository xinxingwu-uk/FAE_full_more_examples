{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#----------------------------Reproducible----------------------------------------------------------------------------------------\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "import os\n",
    "\n",
    "seed=0\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "np.random.seed(seed)\n",
    "rn.seed(seed)\n",
    "#session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "session_conf =tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "#tf.set_random_seed(seed)\n",
    "tf.compat.v1.set_random_seed(seed)\n",
    "#sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "\n",
    "K.set_session(sess)\n",
    "#----------------------------Reproducible----------------------------------------------------------------------------------------\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "import random\n",
    "import scipy.sparse as sparse\n",
    "import scipy.io\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skfeature.utility import construct_W\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from skfeature.utility import construct_W\n",
    "from skfeature.utility.sparse_learning import feature_ranking\n",
    "import time\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.impute import SimpleImputer \n",
    "import pandas as pd\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "#Import ourslef defined methods\n",
    "import sys\n",
    "sys.path.append(r\"../Defined\")\n",
    "import Functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=\"../Dataset/GLIOMA.mat\"\n",
    "Data = scipy.io.loadmat(data_path)\n",
    "\n",
    "data_arr_=Data['X']\n",
    "label_arr=Data['Y'][:, 0]\n",
    "\n",
    "data_arr=MinMaxScaler(feature_range=(0,1)).fit_transform(data_arr_)\n",
    "\n",
    "label_arr_onehot=label_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_feture_number=64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 .Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "def write_to_csv(p_data,p_path):\n",
    "    dataframe = pd.DataFrame(p_data)\n",
    "    dataframe.to_csv(p_path, mode='a',header=False,index=False,sep=',')\n",
    "    del dataframe\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------       \n",
    "def mse_check(train, test):\n",
    "    LR = LinearRegression(n_jobs = -1)\n",
    "    LR.fit(train[0], train[1])\n",
    "    MSELR = ((LR.predict(test[0]) - test[1]) ** 2).mean()\n",
    "    return MSELR\n",
    "\n",
    "def next_batch(samples, labels, num):\n",
    "    # Return a total of `num` random samples and labels.\n",
    "    idx = np.random.choice(len(samples), num)\n",
    "\n",
    "    return samples[idx], labels[idx]\n",
    "\n",
    "def standard_single_hidden_layer_autoencoder(X, units, O):\n",
    "    reg_alpha = 1e-3\n",
    "    D = X.shape[1]\n",
    "    weights = tf.get_variable(\"weights\", [D, units])\n",
    "    biases = tf.get_variable(\"biases\", [units])\n",
    "    X = tf.matmul(X, weights) + biases\n",
    "    X = tf.layers.dense(X, O, kernel_regularizer = tf.contrib.layers.l2_regularizer(reg_alpha))\n",
    "    return X, weights\n",
    "\n",
    "def aefs_subset_selector(train, K, epoch_num=1000, alpha=0.1):\n",
    "    D = train[0].shape[1]\n",
    "    O = train[1].shape[1]\n",
    "    learning_rate = 0.001\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    X = tf.placeholder(tf.float32, (None, D))\n",
    "    TY = tf.placeholder(tf.float32, (None, O))\n",
    "    Y, weights = standard_single_hidden_layer_autoencoder(X, K, O)\n",
    "    \n",
    "    loss = tf.reduce_mean(tf.square(TY - Y)) + alpha * tf.reduce_sum(tf.sqrt(tf.reduce_sum(tf.square(weights), axis=1)), axis=0) + tf.losses.get_total_loss()\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    batch_size = 8\n",
    "    batch_per_epoch = train[0].shape[0] // batch_size\n",
    "    \n",
    "    costs = []\n",
    "    \n",
    "    session_config = tf.ConfigProto()\n",
    "    session_config.gpu_options.allow_growth = False\n",
    "    \n",
    "    with tf.Session(config = session_config) as sess:\n",
    "        sess.run(init)\n",
    "        for ep in range(epoch_num):\n",
    "            cost = 0\n",
    "            for batch_n in range(batch_per_epoch):\n",
    "                imgs, yimgs = next_batch(train[0], train[1], batch_size)\n",
    "                _, c, p = sess.run([train_op, loss, weights], feed_dict = {X: imgs, TY: yimgs})\n",
    "                cost += c / batch_per_epoch\n",
    "            costs.append(cost)\n",
    "            \n",
    "    return list(np.argmax(np.abs(p), axis=0)), costs\n",
    "\n",
    "def AEFS(train, test, K, debug = True):\n",
    "    x_train, x_val, y_train, y_val = train_test_split(train[0], train[1], test_size = 0.1)\n",
    "    print(\"y_train.shape\",y_train.shape)\n",
    "    bindices = []\n",
    "    bmse = 1e100\n",
    "    for alpha in [1e-3, 1e-1, 1e1, 1e3]:\n",
    "        print(\"alpha\",alpha)\n",
    "        indices, _ = aefs_subset_selector(train, K)\n",
    "        mse = mse_check((train[0][:, indices], train[1]), (x_val[:, indices], y_val))\n",
    "        if bmse > mse:\n",
    "            bmse = mse\n",
    "            bindices = indices\n",
    "    if debug:\n",
    "        print(bindices, bmse)\n",
    "    return train[0][:, bindices], test[0][:, bindices]\n",
    " \n",
    "#--------------------------------------------------------------------------------------------------------------------------------       \n",
    "def cal(p_data_arr,\\\n",
    "        p_label_arr_onehot,\\\n",
    "        p_key_feture_number,\\\n",
    "        p_seed):\n",
    "    \n",
    "    C_train_x,C_test_x,C_train_y,C_test_y= train_test_split(p_data_arr,p_label_arr_onehot,test_size=0.2,random_state=p_seed)\n",
    "\n",
    "    os.environ['PYTHONHASHSEED'] = str(p_seed)\n",
    "    np.random.seed(p_seed)\n",
    "    rn.seed(p_seed)\n",
    "    \n",
    "    train=(C_train_x,C_train_x)\n",
    "    test=(C_test_x,C_test_x)\n",
    "    \n",
    "    #--------------------------------------------------------------------------------------------------------------------------------\n",
    "    t_start = time.time()\n",
    "\n",
    "    C_train_selected_x, C_test_selected_x = AEFS((train[0], train[0]), (test[0], test[0]),  key_feture_number)\n",
    "\n",
    "    t_used=time.time() - t_start\n",
    "    \n",
    "    write_to_csv(np.array([t_used]),\"./log/AEFS_time.csv\")\n",
    "    \n",
    "    # Classification on original features\n",
    "    train_feature=C_train_x\n",
    "    train_label=C_train_y\n",
    "    test_feature=C_test_x\n",
    "    test_label=C_test_y\n",
    "    \n",
    "    orig_train_acc,orig_test_acc=F.ETree(train_feature,train_label,test_feature,test_label,0)\n",
    "    \n",
    "    # Classification on selected features\n",
    "    train_feature=C_train_selected_x\n",
    "    train_label=C_train_y\n",
    "    test_feature=C_test_selected_x\n",
    "    test_label=C_test_y\n",
    "\n",
    "    selec_train_acc,selec_test_acc=F.ETree(train_feature,train_label,test_feature,test_label,0)\n",
    "\n",
    "    # Linear reconstruction\n",
    "    train_feature_tuple=(C_train_selected_x,C_train_x)\n",
    "    test_feature_tuple=(C_test_selected_x,C_test_x)\n",
    "\n",
    "    reconstruction_loss=mse_check(train_feature_tuple, test_feature_tuple)\n",
    "    results=np.array([orig_train_acc,orig_test_acc,selec_train_acc,selec_test_acc,reconstruction_loss])\n",
    "    \n",
    "    write_to_csv(results.reshape(1,len(results)),\"./log/AEFS_results.csv\")\n",
    "    \n",
    "    return orig_train_acc,orig_test_acc,selec_train_acc,selec_test_acc,reconstruction_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_data_arr=data_arr\n",
    "p_label_arr_onehot=label_arr_onehot\n",
    "p_key_feture_number=key_feture_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train.shape (36, 4434)\n",
      "alpha 0.001\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-4-5f3f0c6cee40>:26: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "alpha 0.1\n",
      "alpha 10.0\n",
      "alpha 1000.0\n",
      "[1999, 1536, 1947, 3386, 1419, 2324, 2490, 694, 2991, 2091, 1415, 2905, 4296, 2046, 2998, 3762, 2841, 4046, 4234, 1118, 326, 1212, 1353, 2963, 1751, 2696, 1205, 85, 4389, 805, 1683, 3258, 4373, 43, 2345, 1218, 1118, 2516, 3187, 2671, 2913, 3696, 2248, 1385, 969, 980, 3636, 1412, 3696, 1537, 3400, 2964, 334, 856, 2309, 780, 3293, 689, 3288, 4063, 3846, 4207, 1210, 3678] 7.05450927702547e-31\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9\n",
      "Testing accuracy： 0.9\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9\n",
      "Testing accuracy： 0.9\n",
      "y_train.shape (36, 4434)\n",
      "alpha 0.001\n",
      "alpha 0.1\n",
      "alpha 10.0\n",
      "alpha 1000.0\n",
      "[290, 540, 843, 1765, 2836, 1861, 563, 2399, 618, 1599, 3291, 3602, 3052, 1237, 1084, 3010, 3231, 2133, 380, 1012, 3585, 72, 1290, 2391, 2274, 1237, 2144, 2091, 380, 2233, 705, 1207, 2278, 1886, 799, 3334, 203, 1222, 618, 4210, 2849, 3957, 2382, 684, 1903, 2650, 3905, 131, 3721, 1906, 2694, 1888, 802, 792, 2994, 2080, 2605, 2336, 4340, 3886, 4242, 869, 433, 2860] 3.7171230096640535e-31\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.5\n",
      "Testing accuracy： 0.5\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.5\n",
      "Testing accuracy： 0.5\n",
      "y_train.shape (36, 4434)\n",
      "alpha 0.001\n",
      "alpha 0.1\n",
      "alpha 10.0\n",
      "alpha 1000.0\n",
      "[4363, 1707, 3224, 4174, 3846, 1595, 774, 3623, 584, 2768, 1025, 3546, 3888, 990, 916, 302, 1398, 3916, 4264, 2378, 3610, 444, 3313, 328, 3136, 4347, 574, 4292, 4332, 879, 2847, 412, 3106, 365, 1163, 2831, 4423, 3869, 539, 1077, 3415, 3343, 819, 2132, 2296, 11, 526, 1185, 335, 3411, 1496, 3317, 1543, 4286, 3844, 4143, 2432, 3973, 261, 2752, 2171, 3129, 2132, 2573] 4.158075909600217e-31\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.7\n",
      "Testing accuracy： 0.7\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.7\n",
      "Testing accuracy： 0.7\n",
      "y_train.shape (36, 4434)\n",
      "alpha 0.001\n",
      "alpha 0.1\n",
      "alpha 10.0\n",
      "alpha 1000.0\n",
      "[2345, 2810, 3172, 431, 1568, 3373, 751, 2685, 4380, 2286, 3316, 1829, 2753, 876, 2652, 3225, 1562, 4313, 3314, 1529, 3033, 1060, 4418, 593, 339, 2606, 3418, 1654, 210, 2960, 1247, 2991, 2526, 363, 445, 1308, 2349, 3260, 1573, 498, 520, 2566, 3786, 3204, 367, 2168, 2388, 126, 4000, 3179, 1210, 2500, 2828, 2034, 3687, 1946, 809, 920, 3780, 3271, 99, 440, 2749, 1106] 2.9137899387656957e-31\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9\n",
      "Testing accuracy： 0.9\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.6\n",
      "Testing accuracy： 0.6\n",
      "y_train.shape (36, 4434)\n",
      "alpha 0.001\n",
      "alpha 0.1\n",
      "alpha 10.0\n",
      "alpha 1000.0\n",
      "[2439, 2606, 3067, 2992, 4089, 3620, 3931, 1006, 4194, 2219, 2413, 2218, 2954, 3691, 346, 3648, 1711, 312, 1249, 3043, 4124, 2081, 1082, 3828, 2652, 730, 1559, 1671, 2468, 1147, 4004, 3656, 84, 3205, 730, 4163, 2306, 3637, 2900, 2281, 1190, 1147, 4218, 1554, 3495, 1500, 2345, 1260, 1090, 1536, 2328, 4118, 1844, 2590, 3989, 605, 2233, 190, 269, 4396, 4199, 3281, 3177, 489] 8.489793444018093e-31\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9\n",
      "Testing accuracy： 0.9\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.7\n",
      "Testing accuracy： 0.7\n",
      "y_train.shape (36, 4434)\n",
      "alpha 0.001\n",
      "alpha 0.1\n",
      "alpha 10.0\n",
      "alpha 1000.0\n",
      "[365, 37, 4075, 3251, 4423, 2900, 767, 1382, 2740, 4239, 1676, 1451, 1974, 620, 585, 3356, 2780, 2329, 1427, 1365, 2325, 2333, 1303, 2680, 4315, 134, 2391, 756, 462, 3003, 1885, 4004, 1068, 2329, 767, 1286, 2714, 2871, 2067, 362, 4049, 120, 2508, 2039, 1249, 2606, 3695, 84, 4120, 2194, 2542, 4233, 3431, 362, 2680, 2585, 2163, 387, 3022, 231, 2695, 3363, 2907, 1196] 5.428883150381337e-31\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.7\n",
      "Testing accuracy： 0.7\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.7\n",
      "Testing accuracy： 0.7\n",
      "y_train.shape (36, 4434)\n",
      "alpha 0.001\n",
      "alpha 0.1\n",
      "alpha 10.0\n",
      "alpha 1000.0\n",
      "[1358, 2797, 3596, 1455, 39, 2742, 1512, 944, 2345, 1280, 4333, 3927, 560, 3503, 1738, 1969, 2978, 954, 1396, 3647, 1796, 4275, 538, 2, 274, 3160, 3167, 2451, 903, 3948, 134, 1006, 81, 4269, 1779, 3886, 3674, 343, 2546, 1993, 3017, 188, 2768, 4353, 3831, 3307, 3153, 3160, 337, 2825, 470, 3199, 3486, 120, 145, 2345, 1488, 2565, 355, 302, 1222, 4281, 4151, 1697] 1.2455968010924668e-30\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.6\n",
      "Testing accuracy： 0.6\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.6\n",
      "Testing accuracy： 0.6\n",
      "y_train.shape (36, 4434)\n",
      "alpha 0.001\n",
      "alpha 0.1\n",
      "alpha 10.0\n",
      "alpha 1000.0\n",
      "[3173, 3880, 3880, 1422, 2360, 3780, 964, 2372, 3920, 3490, 4383, 2612, 455, 4090, 3965, 2739, 1688, 2694, 1468, 2295, 2885, 1123, 1010, 2298, 2187, 1375, 2992, 4308, 1734, 2295, 4063, 4328, 1798, 2641, 1171, 2257, 4138, 375, 2016, 154, 1647, 2697, 1336, 2171, 2468, 1153, 1204, 2077, 2704, 3322, 581, 2562, 4310, 573, 3561, 3127, 4303, 511, 2752, 3016, 1449, 2818, 3949, 264] 1.2040991722770998e-30\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.7\n",
      "Testing accuracy： 0.7\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.5\n",
      "Testing accuracy： 0.5\n",
      "y_train.shape (36, 4434)\n",
      "alpha 0.001\n",
      "alpha 0.1\n",
      "alpha 10.0\n",
      "alpha 1000.0\n",
      "[812, 1393, 871, 238, 4307, 230, 685, 2208, 1833, 1293, 1345, 2361, 1245, 291, 3207, 2095, 4365, 3994, 552, 3163, 3251, 2137, 4398, 3454, 3548, 1644, 1177, 3496, 1002, 2575, 612, 3507, 867, 3730, 2211, 3834, 4253, 685, 3380, 167, 396, 2751, 222, 2290, 3793, 2075, 4368, 2757, 1756, 1345, 3000, 226, 1517, 1302, 3067, 506, 3989, 2513, 3937, 678, 3995, 1263, 2166, 32] 2.9068677989817664e-31\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.8\n",
      "Testing accuracy： 0.8\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.6\n",
      "Testing accuracy： 0.6\n",
      "y_train.shape (36, 4434)\n",
      "alpha 0.001\n",
      "alpha 0.1\n",
      "alpha 10.0\n",
      "alpha 1000.0\n",
      "[4303, 1006, 3328, 3982, 2942, 411, 664, 1780, 981, 2021, 1522, 106, 971, 2253, 1109, 805, 3392, 4211, 3519, 1139, 1114, 1066, 3169, 2426, 2193, 3652, 4365, 3068, 484, 3253, 3363, 1767, 4303, 1767, 2691, 2254, 3385, 2030, 3850, 24, 1703, 2002, 704, 4120, 3804, 1226, 2567, 572, 1271, 2460, 4357, 1698, 664, 3775, 4179, 4243, 2104, 1326, 3781, 3381, 1444, 1485, 3161, 3634] 3.0153294321882697e-31\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.7\n",
      "Testing accuracy： 0.7\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9\n",
      "Testing accuracy： 0.9\n",
      "y_train.shape (36, 4434)\n",
      "alpha 0.001\n",
      "alpha 0.1\n",
      "alpha 10.0\n",
      "alpha 1000.0\n",
      "[807, 1279, 4151, 2636, 1072, 1140, 4004, 624, 107, 2937, 164, 1483, 3283, 1953, 3694, 856, 3249, 1594, 3726, 1947, 1054, 3081, 2510, 4216, 3467, 2652, 237, 1844, 2479, 931, 962, 2010, 1206, 1243, 3158, 2907, 3158, 1580, 1280, 4325, 1649, 3475, 4087, 19, 2582, 1557, 2250, 1784, 2912, 4101, 4384, 2676, 3682, 1234, 1954, 3956, 2957, 204, 1591, 618, 4075, 1602, 377, 3264] 3.4844271314685496e-31\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9\n",
      "Testing accuracy： 0.9\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.8\n",
      "Testing accuracy： 0.8\n",
      "y_train.shape (36, 4434)\n",
      "alpha 0.001\n",
      "alpha 0.1\n",
      "alpha 10.0\n",
      "alpha 1000.0\n",
      "[2530, 851, 3560, 838, 3975, 1403, 420, 1729, 1746, 230, 2054, 78, 1108, 441, 2373, 4171, 151, 2530, 6, 1868, 2731, 4143, 227, 1212, 4174, 296, 2884, 3728, 4238, 2893, 122, 2135, 3785, 2627, 4199, 3787, 4396, 570, 3163, 1635, 437, 2353, 815, 1212, 516, 3663, 1075, 3699, 4079, 3611, 1597, 572, 279, 4139, 1627, 1014, 3102, 2723, 2779, 844, 1764, 216, 1736, 3485] 3.545337543147509e-31\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9\n",
      "Testing accuracy： 0.9\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9\n",
      "Testing accuracy： 0.9\n",
      "y_train.shape (36, 4434)\n",
      "alpha 0.001\n",
      "alpha 0.1\n",
      "alpha 10.0\n",
      "alpha 1000.0\n",
      "[2764, 3180, 2079, 4095, 3049, 4140, 142, 3120, 1198, 454, 4321, 1564, 3918, 2810, 3764, 931, 83, 92, 1210, 2377, 2990, 1342, 1160, 953, 909, 1686, 947, 1531, 1633, 615, 2016, 1978, 3987, 695, 2288, 2686, 793, 3475, 1894, 2657, 461, 2203, 3494, 1965, 669, 947, 867, 1337, 2333, 1520, 2159, 2089, 1493, 789, 2051, 1645, 3877, 919, 3757, 1050, 3581, 3029, 663, 3542] 2.990087954707504e-31\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.8\n",
      "Testing accuracy： 0.8\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9\n",
      "Testing accuracy： 0.9\n",
      "y_train.shape (36, 4434)\n",
      "alpha 0.001\n",
      "alpha 0.1\n",
      "alpha 10.0\n",
      "alpha 1000.0\n",
      "[1191, 109, 2751, 2306, 305, 513, 4030, 1501, 2407, 2431, 1519, 1393, 575, 2964, 1246, 271, 269, 2042, 4421, 4342, 1204, 2251, 45, 2811, 2074, 399, 2171, 1640, 1371, 3853, 2506, 1624, 4131, 3448, 1234, 4131, 4168, 1866, 3131, 1469, 2815, 1723, 844, 3382, 1119, 1898, 1256, 2132, 2810, 3382, 2999, 2311, 3138, 3657, 1234, 2317, 1085, 1249, 3761, 4330, 3625, 190, 2251, 3597] 3.920287474127295e-31\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9\n",
      "Testing accuracy： 0.9\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.8\n",
      "Testing accuracy： 0.8\n",
      "y_train.shape (36, 4434)\n",
      "alpha 0.001\n",
      "alpha 0.1\n",
      "alpha 10.0\n",
      "alpha 1000.0\n",
      "[1519, 2753, 303, 788, 1626, 1641, 1952, 4409, 2962, 3899, 3413, 3507, 2273, 3602, 2240, 3232, 2196, 4221, 1039, 1920, 2842, 829, 2015, 2906, 3109, 3514, 2643, 1208, 197, 829, 3518, 2637, 1714, 4409, 2980, 3533, 2534, 678, 3735, 2463, 1924, 2972, 3187, 2297, 4277, 2884, 1063, 2369, 3534, 13, 4221, 4109, 1179, 197, 2769, 1913, 2451, 1714, 3735, 64, 244, 1307, 1077, 3567] 7.0721078478972375e-31\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.8\n",
      "Testing accuracy： 0.8\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9\n",
      "Testing accuracy： 0.9\n",
      "y_train.shape (36, 4434)\n",
      "alpha 0.001\n",
      "alpha 0.1\n",
      "alpha 10.0\n",
      "alpha 1000.0\n",
      "[3226, 1309, 1308, 2699, 2576, 227, 1045, 159, 163, 2367, 3003, 3524, 2638, 869, 1957, 3407, 357, 3202, 217, 3941, 106, 4229, 2071, 1676, 685, 1149, 305, 2737, 2149, 2622, 3910, 1788, 1768, 286, 894, 1581, 2549, 2950, 494, 3382, 1485, 1902, 217, 918, 1516, 1041, 3834, 1589, 771, 1754, 4381, 2622, 2304, 248, 1990, 4063, 1946, 2232, 1243, 984, 1520, 1660, 2071, 3041] 5.541477076169236e-31\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.8\n",
      "Testing accuracy： 0.8\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.7\n",
      "Testing accuracy： 0.7\n",
      "y_train.shape (36, 4434)\n",
      "alpha 0.001\n",
      "alpha 0.1\n",
      "alpha 10.0\n",
      "alpha 1000.0\n",
      "[4416, 1026, 4013, 1109, 2652, 1109, 1074, 3463, 1469, 579, 1349, 1602, 449, 2478, 1997, 3042, 1352, 1114, 4213, 80, 82, 4362, 2820, 2316, 2276, 2072, 4273, 1228, 0, 2953, 2627, 913, 3616, 1052, 531, 1227, 1469, 2132, 3149, 1519, 1086, 1752, 3181, 1714, 4326, 340, 4287, 2949, 446, 2282, 1086, 3068, 851, 1351, 4018, 3365, 2967, 113, 2197, 906, 2237, 4217, 4358, 709] 5.318163491755738e-31\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.3\n",
      "Testing accuracy： 0.3\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.4\n",
      "Testing accuracy： 0.4\n",
      "y_train.shape (36, 4434)\n",
      "alpha 0.001\n",
      "alpha 0.1\n",
      "alpha 10.0\n",
      "alpha 1000.0\n",
      "[3764, 3473, 4301, 161, 1914, 2180, 4301, 2777, 2473, 351, 1722, 662, 1179, 1877, 2752, 4408, 3685, 625, 855, 2926, 1787, 3193, 1008, 3071, 1228, 3148, 4047, 1912, 328, 4017, 2921, 1922, 3341, 883, 4128, 724, 1961, 1041, 2464, 3341, 1643, 4348, 1000, 1291, 3747, 883, 2171, 4323, 1709, 783, 1185, 955, 1670, 3362, 1773, 1616, 1968, 731, 2319, 2996, 2599, 3090, 2845, 3397] 2.902358092715718e-31\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.6\n",
      "Testing accuracy： 0.6\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.5\n",
      "Testing accuracy： 0.5\n",
      "y_train.shape (36, 4434)\n",
      "alpha 0.001\n",
      "alpha 0.1\n",
      "alpha 10.0\n",
      "alpha 1000.0\n",
      "[4171, 1842, 4284, 1191, 610, 2482, 755, 4325, 4095, 3311, 2923, 3800, 2135, 2092, 4071, 2895, 170, 3677, 3158, 3422, 3418, 4423, 2961, 1137, 1415, 2847, 3709, 3282, 323, 2679, 3344, 1496, 2384, 2130, 4195, 4126, 1617, 2091, 759, 3194, 3715, 2727, 2203, 4051, 788, 467, 4013, 3715, 2050, 3407, 3009, 2764, 747, 2406, 2337, 1064, 2146, 731, 2982, 1101, 2917, 1676, 222, 2681] 8.60769346263263e-31\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.6\n",
      "Testing accuracy： 0.6\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.7\n",
      "Testing accuracy： 0.7\n",
      "y_train.shape (36, 4434)\n",
      "alpha 0.001\n",
      "alpha 0.1\n",
      "alpha 10.0\n",
      "alpha 1000.0\n",
      "[584, 2139, 313, 1555, 656, 1719, 3919, 88, 2778, 1204, 707, 3311, 2991, 452, 2652, 707, 3726, 1423, 1383, 228, 215, 225, 427, 3466, 743, 1297, 1184, 1865, 1204, 2195, 965, 3206, 112, 1665, 3697, 474, 3179, 2351, 2878, 771, 3032, 2565, 1951, 4394, 1953, 773, 141, 1566, 2424, 3549, 1914, 1156, 309, 169, 240, 3902, 613, 2854, 321, 2616, 2600, 19, 3450, 1073] 2.852601144721727e-31\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.8\n",
      "Testing accuracy： 0.8\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 1.0\n",
      "Testing accuracy： 1.0\n",
      "y_train.shape (36, 4434)\n",
      "alpha 0.001\n",
      "alpha 0.1\n",
      "alpha 10.0\n",
      "alpha 1000.0\n",
      "[3339, 3678, 3011, 925, 50, 2577, 1451, 2478, 2130, 85, 1455, 2603, 2752, 716, 3117, 1826, 2166, 4004, 465, 1826, 912, 1648, 258, 146, 3961, 1590, 2541, 2041, 2438, 2336, 734, 1540, 4171, 3148, 3014, 2449, 3010, 3363, 2206, 2207, 1540, 2577, 0, 2631, 3944, 465, 1763, 616, 3658, 3282, 839, 3705, 4022, 4334, 2318, 2528, 2275, 4023, 1960, 793, 2674, 3119, 1024, 2283] 1.4356389226195263e-30\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.6\n",
      "Testing accuracy： 0.6\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.8\n",
      "Testing accuracy： 0.8\n",
      "y_train.shape (36, 4434)\n",
      "alpha 0.001\n",
      "alpha 0.1\n",
      "alpha 10.0\n",
      "alpha 1000.0\n",
      "[3483, 3522, 2477, 3223, 1783, 1120, 3544, 2581, 1614, 4010, 174, 2697, 4399, 1641, 1308, 4115, 1470, 3616, 3236, 1574, 2253, 3969, 308, 2673, 329, 3621, 1752, 1854, 1378, 1694, 2143, 3245, 3709, 2430, 17, 1171, 2238, 1969, 4061, 1549, 857, 2623, 1577, 3444, 972, 2362, 1, 4364, 364, 2656, 2034, 9, 631, 1854, 953, 2308, 1087, 3776, 3652, 3220, 1706, 1018, 2271, 1735] 4.155615530927682e-31\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.7\n",
      "Testing accuracy： 0.7\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.7\n",
      "Testing accuracy： 0.7\n",
      "y_train.shape (36, 4434)\n",
      "alpha 0.001\n",
      "alpha 0.1\n",
      "alpha 10.0\n",
      "alpha 1000.0\n",
      "[519, 835, 4264, 2016, 837, 2844, 2213, 2711, 1496, 2051, 1107, 723, 3107, 1691, 2649, 779, 3544, 225, 765, 3973, 3610, 2918, 1907, 4238, 4186, 547, 4284, 2137, 2075, 3317, 2495, 480, 3312, 3187, 2725, 900, 4077, 3701, 3774, 1101, 661, 3116, 2406, 1976, 2600, 1022, 1368, 4374, 181, 517, 4107, 578, 1976, 1879, 3402, 686, 194, 1242, 3059, 3291, 1964, 1609, 3532, 4058] 6.306568357865541e-31\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.7\n",
      "Testing accuracy： 0.7\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.7\n",
      "Testing accuracy： 0.7\n",
      "y_train.shape (36, 4434)\n",
      "alpha 0.001\n",
      "alpha 0.1\n",
      "alpha 10.0\n",
      "alpha 1000.0\n",
      "[1639, 2410, 4331, 3867, 2752, 2339, 587, 1505, 1610, 3801, 3955, 4331, 3556, 2518, 2163, 13, 3423, 995, 1306, 2399, 2399, 3013, 3351, 3612, 1734, 763, 1820, 223, 511, 445, 2048, 731, 1828, 4197, 4318, 3235, 4038, 2526, 1925, 3720, 3402, 3804, 4348, 3119, 3307, 2173, 1265, 953, 3202, 3239, 386, 2033, 4388, 1470, 447, 3326, 1804, 3595, 4391, 1905, 2095, 944, 1075, 3594] 3.1906851736527545e-31\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.6\n",
      "Testing accuracy： 0.6\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.5\n",
      "Testing accuracy： 0.5\n",
      "y_train.shape (36, 4434)\n",
      "alpha 0.001\n",
      "alpha 0.1\n",
      "alpha 10.0\n",
      "alpha 1000.0\n",
      "[3989, 2460, 1876, 2485, 1183, 2864, 3143, 3251, 157, 2158, 4253, 4159, 346, 1259, 1089, 3422, 4013, 1270, 854, 187, 3860, 2984, 2655, 3759, 3584, 320, 1159, 2055, 1656, 3393, 2269, 3671, 2979, 4286, 3776, 3817, 8, 2221, 2553, 985, 3786, 1231, 3671, 1279, 1417, 374, 184, 2585, 1737, 4378, 467, 1858, 3014, 3019, 320, 1090, 1201, 2349, 987, 3790, 4243, 1660, 2569, 3782] 4.764435646591275e-31\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.8\n",
      "Testing accuracy： 0.8\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 1.0\n",
      "Testing accuracy： 1.0\n",
      "y_train.shape (36, 4434)\n",
      "alpha 0.001\n",
      "alpha 0.1\n",
      "alpha 10.0\n",
      "alpha 1000.0\n",
      "[1904, 3415, 201, 4340, 2521, 638, 918, 2790, 679, 4082, 504, 129, 4424, 2945, 3373, 4332, 4217, 1692, 1296, 3425, 2233, 4275, 3239, 2382, 531, 91, 662, 3428, 1183, 3639, 22, 1948, 708, 3825, 2046, 3733, 2977, 969, 3899, 3007, 3574, 4018, 4008, 3274, 1522, 2941, 2717, 3019, 3527, 2953, 1272, 3782, 3602, 2332, 12, 3790, 91, 4050, 296, 2046, 2744, 189, 2977, 1603] 3.0082467083409184e-31\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.7\n",
      "Testing accuracy： 0.7\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.8\n",
      "Testing accuracy： 0.8\n",
      "y_train.shape (36, 4434)\n",
      "alpha 0.001\n",
      "alpha 0.1\n",
      "alpha 10.0\n",
      "alpha 1000.0\n",
      "[1604, 316, 211, 2495, 2447, 3850, 3196, 2006, 2733, 2112, 3565, 2757, 1818, 4306, 1562, 1341, 459, 868, 2612, 1724, 2084, 2221, 12, 1533, 1500, 1399, 1454, 1074, 1104, 859, 3865, 2636, 2198, 871, 26, 1252, 2601, 2749, 409, 1399, 1251, 106, 3237, 1934, 1273, 1533, 1093, 3976, 3665, 3178, 3172, 2761, 780, 1120, 4022, 1142, 1185, 2602, 3782, 2447, 1341, 631, 3090, 2514] 8.828514385487802e-31\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 1.0\n",
      "Testing accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 1.0\n",
      "Testing accuracy： 1.0\n",
      "y_train.shape (36, 4434)\n",
      "alpha 0.001\n",
      "alpha 0.1\n",
      "alpha 10.0\n",
      "alpha 1000.0\n",
      "[2572, 2049, 1616, 1273, 404, 2737, 4257, 3594, 3586, 1624, 4068, 1930, 1037, 2632, 2738, 1488, 1498, 3488, 2665, 4094, 2247, 483, 181, 1273, 298, 69, 4162, 3684, 4145, 1634, 821, 1400, 1693, 4034, 2281, 1881, 2054, 2629, 4151, 3718, 4145, 2001, 232, 2991, 2246, 894, 3034, 3351, 3772, 3878, 4329, 191, 1325, 860, 3331, 4096, 2944, 2589, 1694, 303, 3878, 2680, 2281, 3404] 2.7963196971942843e-31\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9\n",
      "Testing accuracy： 0.9\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.7\n",
      "Testing accuracy： 0.7\n",
      "y_train.shape (36, 4434)\n",
      "alpha 0.001\n",
      "alpha 0.1\n",
      "alpha 10.0\n",
      "alpha 1000.0\n",
      "[1936, 2438, 3288, 10, 3591, 1822, 3620, 1582, 3327, 1374, 4286, 1910, 1767, 1342, 1475, 3326, 916, 444, 2532, 727, 4066, 1436, 727, 2036, 2051, 2265, 2389, 1331, 2696, 18, 1559, 3040, 2629, 1415, 2683, 1199, 2228, 2304, 2868, 1237, 3057, 870, 3000, 2478, 3829, 2455, 3393, 2226, 1222, 3180, 4310, 842, 2177, 2733, 1934, 1567, 3645, 3088, 521, 3076, 2577, 4055, 3146, 1371] 3.15662504710679e-31\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.7\n",
      "Testing accuracy： 0.7\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.6\n",
      "Testing accuracy： 0.6\n",
      "y_train.shape (36, 4434)\n",
      "alpha 0.001\n",
      "alpha 0.1\n",
      "alpha 10.0\n",
      "alpha 1000.0\n",
      "[883, 3421, 3926, 4325, 2127, 4135, 58, 1045, 156, 4432, 3520, 875, 2833, 1399, 1973, 222, 3975, 3220, 2962, 2587, 4367, 2644, 3278, 4390, 4361, 1923, 3084, 3434, 863, 3958, 2162, 3483, 970, 1456, 2929, 3809, 788, 863, 95, 2457, 1360, 1342, 3827, 1519, 3366, 2393, 2942, 646, 4392, 1716, 3600, 3421, 4263, 222, 3466, 289, 521, 685, 440, 4390, 2642, 4195, 4414, 3129] 9.686003861768976e-31\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.8\n",
      "Testing accuracy： 0.8\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.6\n",
      "Testing accuracy： 0.6\n",
      "y_train.shape (36, 4434)\n",
      "alpha 0.001\n",
      "alpha 0.1\n",
      "alpha 10.0\n",
      "alpha 1000.0\n",
      "[1375, 3057, 2788, 1252, 3509, 3543, 2163, 381, 2801, 4410, 134, 1613, 3396, 1130, 21, 829, 777, 4021, 886, 4215, 2803, 1100, 3210, 387, 1433, 1710, 1116, 1779, 4033, 2109, 3818, 1591, 1113, 3697, 1240, 155, 155, 1176, 1802, 2028, 1547, 4396, 1858, 2030, 3283, 225, 2982, 2985, 1434, 3694, 2920, 4147, 4382, 4198, 98, 2702, 3451, 3762, 4383, 2482, 246, 401, 1855, 61] 5.450133246505272e-31\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.8\n",
      "Testing accuracy： 0.8\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.5\n",
      "Testing accuracy： 0.5\n",
      "y_train.shape (36, 4434)\n",
      "alpha 0.001\n",
      "alpha 0.1\n",
      "alpha 10.0\n",
      "alpha 1000.0\n",
      "[3157, 3442, 990, 2377, 4301, 688, 3687, 3248, 726, 3248, 2441, 3892, 3806, 2817, 892, 968, 4383, 2210, 3864, 4152, 2677, 3294, 2886, 4246, 4014, 3625, 2121, 634, 1844, 487, 889, 413, 2651, 1400, 1286, 3035, 2802, 2012, 3303, 1200, 249, 1383, 2475, 3913, 2056, 1783, 1145, 4349, 2995, 1233, 540, 494, 1281, 3478, 1665, 3128, 1502, 3650, 1504, 2593, 3574, 1625, 3022, 4145] 3.5942996311143684e-31\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.8\n",
      "Testing accuracy： 0.8\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.8\n",
      "Testing accuracy： 0.8\n",
      "y_train.shape (36, 4434)\n",
      "alpha 0.001\n",
      "alpha 0.1\n",
      "alpha 10.0\n",
      "alpha 1000.0\n",
      "[393, 704, 1214, 1573, 835, 2948, 1464, 1328, 2761, 1973, 2061, 4060, 2615, 3623, 3961, 4235, 2919, 2071, 3562, 213, 290, 1278, 3450, 3203, 4313, 2431, 3966, 3880, 2518, 290, 393, 1768, 4117, 1399, 2467, 565, 302, 4393, 1192, 3040, 658, 2493, 2806, 2518, 1585, 1029, 1566, 1576, 3957, 1962, 4058, 1249, 3573, 630, 1705, 1918, 1678, 617, 4341, 2490, 1764, 3492, 1770, 1640] 6.017622301051952e-31\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9\n",
      "Testing accuracy： 0.9\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 1.0\n",
      "Testing accuracy： 1.0\n",
      "y_train.shape (36, 4434)\n",
      "alpha 0.001\n",
      "alpha 0.1\n",
      "alpha 10.0\n",
      "alpha 1000.0\n",
      "[2142, 3833, 3343, 317, 1695, 1930, 4056, 765, 2230, 4056, 1483, 1645, 1978, 4068, 2687, 3977, 2534, 3002, 1366, 2011, 2510, 3207, 52, 1196, 1472, 559, 2664, 3450, 2445, 2606, 4036, 3409, 3947, 2590, 4083, 1813, 3623, 1178, 2324, 157, 250, 803, 2657, 3308, 829, 1887, 1493, 3914, 3392, 2276, 1109, 3507, 326, 2011, 2216, 2789, 3925, 449, 3950, 3078, 4368, 3999, 731, 250] 6.202534002021235e-31\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.6\n",
      "Testing accuracy： 0.6\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.4\n",
      "Testing accuracy： 0.4\n",
      "y_train.shape (36, 4434)\n",
      "alpha 0.001\n",
      "alpha 0.1\n",
      "alpha 10.0\n",
      "alpha 1000.0\n",
      "[654, 966, 3591, 3930, 3281, 2205, 3614, 2646, 1828, 1437, 4164, 122, 1266, 641, 2861, 4329, 2633, 1752, 2063, 1460, 296, 4336, 575, 3638, 3566, 3411, 2530, 1393, 989, 2205, 3511, 2525, 2577, 1548, 1617, 2063, 2325, 3053, 3032, 4371, 4080, 2637, 4412, 3825, 3930, 1843, 2973, 3731, 4376, 4398, 3266, 925, 3995, 4038, 2187, 2754, 1685, 747, 3828, 3194, 2887, 2373, 4156, 2857] 2.7200270948940826e-31\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.7\n",
      "Testing accuracy： 0.7\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9\n",
      "Testing accuracy： 0.9\n",
      "y_train.shape (36, 4434)\n",
      "alpha 0.001\n",
      "alpha 0.1\n",
      "alpha 10.0\n",
      "alpha 1000.0\n",
      "[1866, 2084, 4107, 66, 4160, 466, 1269, 757, 2321, 2525, 3949, 2670, 2442, 2079, 631, 34, 2960, 2938, 4325, 2631, 1461, 3651, 2347, 49, 4075, 838, 1557, 3628, 4269, 1909, 682, 873, 188, 4098, 1534, 2747, 3514, 2526, 4406, 926, 64, 1760, 4164, 2625, 3203, 4213, 3532, 2592, 188, 2271, 4416, 4164, 3475, 1342, 376, 3982, 1118, 3884, 666, 311, 3348, 1553, 2625, 1214] 3.795550844230418e-31\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.8\n",
      "Testing accuracy： 0.8\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.7\n",
      "Testing accuracy： 0.7\n",
      "y_train.shape (36, 4434)\n",
      "alpha 0.001\n",
      "alpha 0.1\n",
      "alpha 10.0\n",
      "alpha 1000.0\n",
      "[3269, 837, 2470, 2060, 215, 3913, 1956, 835, 1690, 1156, 3374, 83, 2405, 2603, 1837, 2971, 4412, 3302, 2242, 1789, 140, 716, 849, 2691, 926, 2164, 2507, 2670, 2120, 1807, 1194, 3362, 2146, 122, 1933, 2413, 1139, 4375, 1342, 763, 342, 1488, 1822, 4317, 909, 1456, 1293, 2146, 2885, 1062, 3031, 3682, 3843, 518, 2806, 1781, 1062, 1384, 2732, 154, 2228, 1062, 2900, 451] 6.362153718011223e-31\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.7\n",
      "Testing accuracy： 0.7\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.6\n",
      "Testing accuracy： 0.6\n",
      "y_train.shape (36, 4434)\n",
      "alpha 0.001\n",
      "alpha 0.1\n",
      "alpha 10.0\n",
      "alpha 1000.0\n",
      "[2753, 1581, 2066, 2411, 1045, 728, 3348, 2089, 1806, 2902, 2034, 4428, 3158, 1665, 3275, 1942, 1706, 3179, 2203, 3454, 1766, 916, 1804, 1680, 3817, 410, 2426, 1231, 318, 1139, 2245, 2556, 1916, 2270, 2953, 3899, 4286, 511, 1625, 911, 1694, 1018, 337, 1665, 1916, 1485, 2209, 3805, 3273, 848, 1142, 2014, 1031, 4112, 1171, 4094, 1460, 564, 4238, 3699, 4105, 710, 248, 3263] 6.922603683683415e-31\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.8\n",
      "Testing accuracy： 0.8\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.8\n",
      "Testing accuracy： 0.8\n",
      "y_train.shape (36, 4434)\n",
      "alpha 0.001\n",
      "alpha 0.1\n",
      "alpha 10.0\n",
      "alpha 1000.0\n",
      "[827, 4002, 1987, 3251, 2196, 4126, 4304, 3012, 4432, 3109, 2390, 1453, 2924, 202, 4206, 3849, 2153, 1339, 113, 2529, 601, 1836, 1975, 1563, 773, 3181, 2479, 2128, 1731, 1218, 1011, 2345, 3428, 835, 3365, 902, 2385, 3249, 1066, 2124, 1210, 1364, 3883, 4280, 1185, 595, 2013, 1033, 2975, 4215, 1162, 4165, 258, 2929, 3435, 3553, 3025, 1808, 113, 1919, 1847, 787, 3101, 1329] 3.5339974622013618e-31\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.6\n",
      "Testing accuracy： 0.6\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.6\n",
      "Testing accuracy： 0.6\n",
      "y_train.shape (36, 4434)\n",
      "alpha 0.001\n",
      "alpha 0.1\n",
      "alpha 10.0\n",
      "alpha 1000.0\n",
      "[983, 566, 3794, 25, 3320, 221, 1777, 1703, 1627, 411, 3756, 4097, 3879, 4329, 3777, 3477, 2388, 1977, 4329, 899, 445, 2581, 1653, 141, 3609, 550, 4309, 2204, 4404, 3902, 3988, 2786, 229, 3672, 2906, 3674, 1651, 621, 657, 1835, 1183, 1778, 924, 240, 2323, 606, 2230, 330, 4410, 1216, 2617, 4375, 3985, 1042, 3862, 3564, 881, 3649, 229, 1491, 3291, 2462, 50, 3937] 5.908571228861366e-31\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.8\n",
      "Testing accuracy： 0.8\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.6\n",
      "Testing accuracy： 0.6\n",
      "y_train.shape (36, 4434)\n",
      "alpha 0.001\n",
      "alpha 0.1\n",
      "alpha 10.0\n"
     ]
    }
   ],
   "source": [
    "for p_seed in np.arange(0,50):\n",
    "    orig_train_acc,orig_test_acc,selec_train_acc,selec_test_acc,reconstruction_loss=cal(p_data_arr,\\\n",
    "                                                                                        p_label_arr_onehot,\\\n",
    "                                                                                        p_key_feture_number,\\\n",
    "                                                                                        p_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

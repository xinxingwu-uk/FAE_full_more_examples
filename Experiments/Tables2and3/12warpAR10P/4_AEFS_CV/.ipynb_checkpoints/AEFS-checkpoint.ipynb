{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#----------------------------Reproducible----------------------------------------------------------------------------------------\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "import os\n",
    "\n",
    "seed=0\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "np.random.seed(seed)\n",
    "rn.seed(seed)\n",
    "#session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "session_conf =tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "#tf.set_random_seed(seed)\n",
    "tf.compat.v1.set_random_seed(seed)\n",
    "#sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "\n",
    "K.set_session(sess)\n",
    "#----------------------------Reproducible----------------------------------------------------------------------------------------\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "import random\n",
    "import scipy.sparse as sparse\n",
    "import scipy.io\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skfeature.utility import construct_W\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from skfeature.utility import construct_W\n",
    "from skfeature.utility.sparse_learning import feature_ranking\n",
    "import time\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.impute import SimpleImputer \n",
    "import pandas as pd\n",
    "from skimage import io\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.sparse as sparse\n",
    "from keras.datasets import fashion_mnist\n",
    "import scipy.io\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "#Import ourslef defined methods\n",
    "import sys\n",
    "sys.path.append(r\"../Defined\")\n",
    "import Functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=\"../Dataset/warpAR10P.mat\"\n",
    "Data = scipy.io.loadmat(data_path)\n",
    "\n",
    "data_arr_=Data['X'].astype('float32')/255\n",
    "label_arr=Data['Y'][:, 0]\n",
    "\n",
    "Data=MinMaxScaler(feature_range=(0,1)).fit_transform(data_arr_)\n",
    "\n",
    "data_arr=Data\n",
    "label_arr_onehot=label_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_feture_number=64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 .Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "def write_to_csv(p_data,p_path):\n",
    "    dataframe = pd.DataFrame(p_data)\n",
    "    dataframe.to_csv(p_path, mode='a',header=False,index=False,sep=',')\n",
    "    del dataframe\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------       \n",
    "def mse_check(train, test):\n",
    "    LR = LinearRegression(n_jobs = -1)\n",
    "    LR.fit(train[0], train[1])\n",
    "    MSELR = ((LR.predict(test[0]) - test[1]) ** 2).mean()\n",
    "    return MSELR\n",
    "\n",
    "def next_batch(samples, labels, num):\n",
    "    # Return a total of `num` random samples and labels.\n",
    "    idx = np.random.choice(len(samples), num)\n",
    "\n",
    "    return samples[idx], labels[idx]\n",
    "\n",
    "def standard_single_hidden_layer_autoencoder(X, units, O):\n",
    "    reg_alpha = 1e-3\n",
    "    D = X.shape[1]\n",
    "    weights = tf.get_variable(\"weights\", [D, units])\n",
    "    biases = tf.get_variable(\"biases\", [units])\n",
    "    X = tf.matmul(X, weights) + biases\n",
    "    X = tf.layers.dense(X, O, kernel_regularizer = tf.contrib.layers.l2_regularizer(reg_alpha))\n",
    "    return X, weights\n",
    "\n",
    "def aefs_subset_selector(train, K, epoch_num=1000, alpha=0.1):\n",
    "    D = train[0].shape[1]\n",
    "    O = train[1].shape[1]\n",
    "    learning_rate = 0.001\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    X = tf.placeholder(tf.float32, (None, D))\n",
    "    TY = tf.placeholder(tf.float32, (None, O))\n",
    "    Y, weights = standard_single_hidden_layer_autoencoder(X, K, O)\n",
    "    \n",
    "    loss = tf.reduce_mean(tf.square(TY - Y)) + alpha * tf.reduce_sum(tf.sqrt(tf.reduce_sum(tf.square(weights), axis=1)), axis=0) + tf.losses.get_total_loss()\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    batch_size = 8\n",
    "    batch_per_epoch = train[0].shape[0] // batch_size\n",
    "    \n",
    "    costs = []\n",
    "    \n",
    "    session_config = tf.ConfigProto()\n",
    "    session_config.gpu_options.allow_growth = False\n",
    "    \n",
    "    with tf.Session(config = session_config) as sess:\n",
    "        sess.run(init)\n",
    "        for ep in range(epoch_num):\n",
    "            cost = 0\n",
    "            for batch_n in range(batch_per_epoch):\n",
    "                imgs, yimgs = next_batch(train[0], train[1], batch_size)\n",
    "                _, c, p = sess.run([train_op, loss, weights], feed_dict = {X: imgs, TY: yimgs})\n",
    "                cost += c / batch_per_epoch\n",
    "            costs.append(cost)\n",
    "            \n",
    "    return list(np.argmax(np.abs(p), axis=0)), costs\n",
    "\n",
    "def AEFS(train, test, K, debug = True):\n",
    "    x_train, x_val, y_train, y_val = train_test_split(train[0], train[1], test_size = 0.1)\n",
    "    print(\"y_train.shape\",y_train.shape)\n",
    "    bindices = []\n",
    "    bmse = 1e100\n",
    "    for alpha in [1e-3, 1e-1, 1e1, 1e3]:\n",
    "        print(\"alpha\",alpha)\n",
    "        indices, _ = aefs_subset_selector(train, K)\n",
    "        mse = mse_check((train[0][:, indices], train[1]), (x_val[:, indices], y_val))\n",
    "        if bmse > mse:\n",
    "            bmse = mse\n",
    "            bindices = indices\n",
    "    if debug:\n",
    "        print(bindices, bmse)\n",
    "    return train[0][:, bindices], test[0][:, bindices]\n",
    " \n",
    "#--------------------------------------------------------------------------------------------------------------------------------       \n",
    "def cal(p_data_arr,\\\n",
    "        p_label_arr_onehot,\\\n",
    "        p_key_feture_number,\\\n",
    "        p_seed):\n",
    "    \n",
    "    C_train_x,C_test_x,C_train_y,C_test_y= train_test_split(p_data_arr,p_label_arr_onehot,test_size=0.2,random_state=p_seed)\n",
    "\n",
    "    os.environ['PYTHONHASHSEED'] = str(p_seed)\n",
    "    np.random.seed(p_seed)\n",
    "    rn.seed(p_seed)\n",
    "    \n",
    "    train=(C_train_x,C_train_x)\n",
    "    test=(C_test_x,C_test_x)\n",
    "    \n",
    "    #--------------------------------------------------------------------------------------------------------------------------------\n",
    "    t_start = time.time()\n",
    "\n",
    "    C_train_selected_x, C_test_selected_x = AEFS((train[0], train[0]), (test[0], test[0]),  key_feture_number)\n",
    "\n",
    "    t_used=time.time() - t_start\n",
    "    \n",
    "    write_to_csv(np.array([t_used]),\"./log/AEFS_time.csv\")\n",
    "    \n",
    "    # Classification on original features\n",
    "    train_feature=C_train_x\n",
    "    train_label=C_train_y\n",
    "    test_feature=C_test_x\n",
    "    test_label=C_test_y\n",
    "    \n",
    "    orig_train_acc,orig_test_acc=F.ETree(train_feature,train_label,test_feature,test_label,0)\n",
    "    \n",
    "    # Classification on selected features\n",
    "    train_feature=C_train_selected_x\n",
    "    train_label=C_train_y\n",
    "    test_feature=C_test_selected_x\n",
    "    test_label=C_test_y\n",
    "\n",
    "    selec_train_acc,selec_test_acc=F.ETree(train_feature,train_label,test_feature,test_label,0)\n",
    "\n",
    "    # Linear reconstruction\n",
    "    train_feature_tuple=(C_train_selected_x,C_train_x)\n",
    "    test_feature_tuple=(C_test_selected_x,C_test_x)\n",
    "\n",
    "    reconstruction_loss=mse_check(train_feature_tuple, test_feature_tuple)\n",
    "    results=np.array([orig_train_acc,orig_test_acc,selec_train_acc,selec_test_acc,reconstruction_loss])\n",
    "    \n",
    "    write_to_csv(results.reshape(1,len(results)),\"./log/AEFS_results.csv\")\n",
    "    \n",
    "    return orig_train_acc,orig_test_acc,selec_train_acc,selec_test_acc,reconstruction_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_data_arr=data_arr\n",
    "p_label_arr_onehot=label_arr_onehot\n",
    "p_key_feture_number=key_feture_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train.shape (1036, 400)\n",
      "alpha 0.001\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-5-5f3f0c6cee40>:26: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fc7e7f104d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fc7e7f104d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fc7e7f104d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fc7e7f104d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "alpha 0.1\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fc7e71deb10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fc7e71deb10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fc7e71deb10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fc7e71deb10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "alpha 10.0\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fc7e716a2d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fc7e716a2d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fc7e716a2d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fc7e716a2d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "alpha 1000.0\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fc7e59f0e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fc7e59f0e50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fc7e59f0e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fc7e59f0e50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "[53, 396, 271, 24, 185, 353, 399, 358, 368, 79, 297, 362, 327, 95, 18, 120, 79, 365, 60, 279, 378, 177, 267, 206, 42, 93, 136, 82, 389, 396, 78, 302, 70, 181, 307, 235, 381, 97, 176, 328, 151, 174, 124, 203, 378, 314, 191, 88, 221, 343] 0.009661736\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 1.0\n",
      "Testing accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9965277777777778\n",
      "Testing accuracy： 0.9965277777777778\n",
      "y_train.shape (1036, 400)\n",
      "alpha 0.001\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fc7e7226290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fc7e7226290>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fc7e7226290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fc7e7226290>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    }
   ],
   "source": [
    "for p_seed in np.arange(0,50):\n",
    "    orig_train_acc,orig_test_acc,selec_train_acc,selec_test_acc,reconstruction_loss=cal(p_data_arr,\\\n",
    "                                                                                        p_label_arr_onehot,\\\n",
    "                                                                                        p_key_feture_number,\\\n",
    "                                                                                        p_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

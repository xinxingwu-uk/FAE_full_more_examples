{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#----------------------------Reproducible----------------------------------------------------------------------------------------\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "import os\n",
    "\n",
    "seed=0\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "np.random.seed(seed)\n",
    "rn.seed(seed)\n",
    "\n",
    "#----------------------------Reproducible----------------------------------------------------------------------------------------\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "import random\n",
    "import scipy.sparse as sparse\n",
    "import scipy.io\n",
    "import time\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skfeature.utility import construct_W\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from skfeature.utility.sparse_learning import feature_ranking\n",
    "import time\n",
    "from sklearn.impute import SimpleImputer \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from concrete_autoencoder import ConcreteAutoencoderFeatureSelector\n",
    "from keras.layers import Dense\n",
    "import pandas as pd\n",
    "from skimage import io\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.sparse as sparse\n",
    "from keras.datasets import mnist\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "#Import ourslef defined methods\n",
    "import sys\n",
    "sys.path.append(r\"../Defined\")\n",
    "import Functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data_used=10000\n",
    "(x_train_, y_train_), (x_test_, y_test_) = mnist.load_data()\n",
    "x_data=np.r_[x_train_,x_test_].reshape(70000, 28*28).astype('float32')\n",
    "y_data=np.r_[y_train_,y_test_]\n",
    "\n",
    "np.random.seed(seed)\n",
    "x_data_num,_=x_data.shape\n",
    "index=np.arange(x_data_num)\n",
    "np.random.shuffle(index)\n",
    "\n",
    "data_arr=x_data[index][0:num_data_used]\n",
    "label_arr_onehot=y_data[index][0:num_data_used]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_feture_number=50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "def write_to_csv(p_data,p_path):\n",
    "    dataframe = pd.DataFrame(p_data)\n",
    "    dataframe.to_csv(p_path, mode='a',header=False,index=False,sep=',')\n",
    "    del dataframe\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------       \n",
    "def mse_check(train, test):\n",
    "    LR = LinearRegression(n_jobs = -1)\n",
    "    LR.fit(train[0], train[1])\n",
    "    MSELR = ((LR.predict(test[0]) - test[1]) ** 2).mean()\n",
    "    return MSELR\n",
    " \n",
    "#--------------------------------------------------------------------------------------------------------------------------------       \n",
    "def cal(p_data_arr,\\\n",
    "        p_label_arr_onehot,\\\n",
    "        p_key_feture_number,\\\n",
    "        p_epochs_number,\\\n",
    "        p_seed):\n",
    "    \n",
    "    C_train_x,C_test_x,C_train_y,C_test_y= train_test_split(p_data_arr,p_label_arr_onehot,test_size=0.2,random_state=p_seed)\n",
    "\n",
    "    os.environ['PYTHONHASHSEED'] = str(p_seed)\n",
    "    np.random.seed(p_seed)\n",
    "    rn.seed(p_seed)\n",
    "    tf.compat.v1.set_random_seed(p_seed)\n",
    "    \n",
    "    #--------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    def decoder(x):\n",
    "        #x = Dense(key_feture_number)(x)\n",
    "        x = Dense(data_arr.shape[1])(x)\n",
    "        return x\n",
    "\n",
    "    t_start = time.time()\n",
    "    selector = ConcreteAutoencoderFeatureSelector(K = p_key_feture_number, output_function = decoder, num_epochs = p_epochs_number)\n",
    "    selector.fit(C_train_x, C_train_x, C_test_x, C_test_x)\n",
    "    t_used=time.time() - t_start\n",
    "    \n",
    "    write_to_csv(np.array([t_used]),\"./log/CAE_time.csv\")\n",
    "    \n",
    "    train_compressed_Data=p_data_arr[:, selector.get_support(indices=True)]\n",
    "    \n",
    "    # Classification on original features\n",
    "    train_feature=C_train_x\n",
    "    train_label=C_train_y\n",
    "    test_feature=C_test_x\n",
    "    test_label=C_test_y \n",
    "    orig_train_acc,orig_test_acc=F.ETree(train_feature,train_label,test_feature,test_label,0)\n",
    "        \n",
    "    # Classification on selected features\n",
    "    C_train_selected_x,C_test_selected_x,C_train_y,C_test_y= train_test_split(train_compressed_Data,p_label_arr_onehot,test_size=0.2,random_state=p_seed)\n",
    "    \n",
    "    train_feature=C_train_selected_x\n",
    "    train_label=C_train_y\n",
    "    test_feature=C_test_selected_x\n",
    "    test_label=C_test_y\n",
    "    selec_train_acc,selec_test_acc=F.ETree(train_feature,train_label,test_feature,test_label,0)\n",
    "    \n",
    "    # Linear reconstruction\n",
    "    train_feature_tuple=(C_train_selected_x,C_train_x)\n",
    "    test_feature_tuple=(C_test_selected_x,C_test_x)\n",
    "\n",
    "    reconstruction_loss=mse_check(train_feature_tuple, test_feature_tuple)\n",
    "    \n",
    "    results=np.array([orig_train_acc,orig_test_acc,selec_train_acc,selec_test_acc,reconstruction_loss])\n",
    "    \n",
    "    write_to_csv(results.reshape(1,len(results)),\"./log/CAE_results.csv\")\n",
    "    \n",
    "    return orig_train_acc,orig_test_acc,selec_train_acc,selec_test_acc,reconstruction_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_number=200\n",
    "\n",
    "p_data_arr=data_arr\n",
    "p_label_arr_onehot=label_arr_onehot\n",
    "p_key_feture_number=key_feture_number\n",
    "p_epochs_number=epochs_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1702: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "concrete_select (ConcreteSel (None, 50)                39201     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 784)               39984     \n",
      "=================================================================\n",
      "Total params: 79,185\n",
      "Trainable params: 79,184\n",
      "Non-trainable params: 1\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/200\n",
      "mean max of probabilities: 0.0014221268 - temperature 10.0\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 4471.6226 - val_loss: 4122.1522\n",
      "Epoch 2/200\n",
      "mean max of probabilities: 0.0017143216 - temperature 9.716152\n",
      "8000/8000 [==============================] - 14s 2ms/step - loss: 4184.0652 - val_loss: 4118.3877\n",
      "Epoch 3/200\n",
      "mean max of probabilities: 0.0020362886 - temperature 9.440363\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 4180.9205 - val_loss: 4116.3707\n",
      "Epoch 4/200\n",
      "mean max of probabilities: 0.0024600197 - temperature 9.172401\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 4176.2946 - val_loss: 4116.7228\n",
      "Epoch 5/200\n",
      "mean max of probabilities: 0.0030147128 - temperature 8.912045\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 4172.7413 - val_loss: 4110.7666\n",
      "Epoch 6/200\n",
      "mean max of probabilities: 0.003741507 - temperature 8.6590805\n",
      "8000/8000 [==============================] - 12s 2ms/step - loss: 4165.5694 - val_loss: 4102.0378\n",
      "Epoch 7/200\n",
      "mean max of probabilities: 0.0047485717 - temperature 8.413296\n",
      "8000/8000 [==============================] - 8s 1ms/step - loss: 4151.8320 - val_loss: 4075.1177\n",
      "Epoch 8/200\n",
      "mean max of probabilities: 0.006151568 - temperature 8.174487\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 4129.4668 - val_loss: 4046.8960\n",
      "Epoch 9/200\n",
      "mean max of probabilities: 0.008094782 - temperature 7.942457\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 4087.7691 - val_loss: 3994.3083\n",
      "Epoch 10/200\n",
      "mean max of probabilities: 0.0105204405 - temperature 7.7170134\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 4022.7142 - val_loss: 3925.0028\n",
      "Epoch 11/200\n",
      "mean max of probabilities: 0.013320715 - temperature 7.4979672\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 3930.0205 - val_loss: 3814.2736\n",
      "Epoch 12/200\n",
      "mean max of probabilities: 0.016242845 - temperature 7.2851405\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 3807.3154 - val_loss: 3687.9776\n",
      "Epoch 13/200\n",
      "mean max of probabilities: 0.01906611 - temperature 7.078353\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 3664.1646 - val_loss: 3538.5253\n",
      "Epoch 14/200\n",
      "mean max of probabilities: 0.02174151 - temperature 6.8774366\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 3516.4759 - val_loss: 3395.1323\n",
      "Epoch 15/200\n",
      "mean max of probabilities: 0.02417654 - temperature 6.6822195\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 3374.3008 - val_loss: 3262.2759\n",
      "Epoch 16/200\n",
      "mean max of probabilities: 0.026429806 - temperature 6.4925466\n",
      "8000/8000 [==============================] - 15s 2ms/step - loss: 3247.7594 - val_loss: 3145.1865\n",
      "Epoch 17/200\n",
      "mean max of probabilities: 0.02856273 - temperature 6.3082566\n",
      "8000/8000 [==============================] - 12s 2ms/step - loss: 3139.5995 - val_loss: 3047.3115\n",
      "Epoch 18/200\n",
      "mean max of probabilities: 0.030684846 - temperature 6.129198\n",
      "8000/8000 [==============================] - 12s 1ms/step - loss: 3045.8845 - val_loss: 2960.2552\n",
      "Epoch 19/200\n",
      "mean max of probabilities: 0.032722168 - temperature 5.955221\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 2969.0327 - val_loss: 2891.1012\n",
      "Epoch 20/200\n",
      "mean max of probabilities: 0.03479407 - temperature 5.786184\n",
      "8000/8000 [==============================] - 12s 2ms/step - loss: 2902.8197 - val_loss: 2836.2244\n",
      "Epoch 21/200\n",
      "mean max of probabilities: 0.03688483 - temperature 5.621946\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 2847.5682 - val_loss: 2780.0632\n",
      "Epoch 22/200\n",
      "mean max of probabilities: 0.03912163 - temperature 5.4623694\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 2796.2417 - val_loss: 2732.8721\n",
      "Epoch 23/200\n",
      "mean max of probabilities: 0.041898552 - temperature 5.307321\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 2746.8508 - val_loss: 2683.4212\n",
      "Epoch 24/200\n",
      "mean max of probabilities: 0.04496063 - temperature 5.1566744\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 2697.4579 - val_loss: 2632.0409\n",
      "Epoch 25/200\n",
      "mean max of probabilities: 0.048415508 - temperature 5.010304\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 2647.5908 - val_loss: 2590.1836\n",
      "Epoch 26/200\n",
      "mean max of probabilities: 0.053208057 - temperature 4.8680882\n",
      "8000/8000 [==============================] - 14s 2ms/step - loss: 2595.6426 - val_loss: 2529.2720\n",
      "Epoch 27/200\n",
      "mean max of probabilities: 0.058597907 - temperature 4.7299085\n",
      "8000/8000 [==============================] - 12s 2ms/step - loss: 2541.5537 - val_loss: 2475.2426\n",
      "Epoch 28/200\n",
      "mean max of probabilities: 0.064446285 - temperature 4.595652\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 2486.3909 - val_loss: 2419.1271\n",
      "Epoch 29/200\n",
      "mean max of probabilities: 0.07067504 - temperature 4.4652066\n",
      "8000/8000 [==============================] - 16s 2ms/step - loss: 2426.6188 - val_loss: 2358.7881\n",
      "Epoch 30/200\n",
      "mean max of probabilities: 0.07718299 - temperature 4.338463\n",
      "8000/8000 [==============================] - 16s 2ms/step - loss: 2365.3739 - val_loss: 2297.6474\n",
      "Epoch 31/200\n",
      "mean max of probabilities: 0.08363993 - temperature 4.2153172\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 2304.2682 - val_loss: 2238.5282\n",
      "Epoch 32/200\n",
      "mean max of probabilities: 0.09038312 - temperature 4.095666\n",
      "8000/8000 [==============================] - 16s 2ms/step - loss: 2244.6480 - val_loss: 2178.8240\n",
      "Epoch 33/200\n",
      "mean max of probabilities: 0.097604915 - temperature 3.979412\n",
      "8000/8000 [==============================] - 14s 2ms/step - loss: 2184.2757 - val_loss: 2121.3691\n",
      "Epoch 34/200\n",
      "mean max of probabilities: 0.10455759 - temperature 3.8664572\n",
      "8000/8000 [==============================] - 14s 2ms/step - loss: 2125.6024 - val_loss: 2062.0904\n",
      "Epoch 35/200\n",
      "mean max of probabilities: 0.11217295 - temperature 3.7567089\n",
      "8000/8000 [==============================] - 14s 2ms/step - loss: 2068.4341 - val_loss: 2007.1636\n",
      "Epoch 36/200\n",
      "mean max of probabilities: 0.11979582 - temperature 3.650076\n",
      "8000/8000 [==============================] - 14s 2ms/step - loss: 2013.9926 - val_loss: 1953.6985\n",
      "Epoch 37/200\n",
      "mean max of probabilities: 0.1273949 - temperature 3.5464702\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 1961.9813 - val_loss: 1904.3175\n",
      "Epoch 38/200\n",
      "mean max of probabilities: 0.13473508 - temperature 3.445804\n",
      "8000/8000 [==============================] - 12s 1ms/step - loss: 1909.1032 - val_loss: 1854.9052\n",
      "Epoch 39/200\n",
      "mean max of probabilities: 0.14129269 - temperature 3.3479955\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 1861.2441 - val_loss: 1805.8849\n",
      "Epoch 40/200\n",
      "mean max of probabilities: 0.1470912 - temperature 3.2529633\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 1813.8105 - val_loss: 1763.9119\n",
      "Epoch 41/200\n",
      "mean max of probabilities: 0.152355 - temperature 3.1606295\n",
      "8000/8000 [==============================] - 14s 2ms/step - loss: 1768.4546 - val_loss: 1716.7122\n",
      "Epoch 42/200\n",
      "mean max of probabilities: 0.15646297 - temperature 3.0709162\n",
      "8000/8000 [==============================] - 14s 2ms/step - loss: 1724.8275 - val_loss: 1676.7405\n",
      "Epoch 43/200\n",
      "mean max of probabilities: 0.16057462 - temperature 2.9837487\n",
      "8000/8000 [==============================] - 15s 2ms/step - loss: 1687.4303 - val_loss: 1642.0292\n",
      "Epoch 44/200\n",
      "mean max of probabilities: 0.16362792 - temperature 2.8990557\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 1648.7496 - val_loss: 1606.5311\n",
      "Epoch 45/200\n",
      "mean max of probabilities: 0.16695154 - temperature 2.8167667\n",
      "8000/8000 [==============================] - 16s 2ms/step - loss: 1620.2627 - val_loss: 1573.3292\n",
      "Epoch 46/200\n",
      "mean max of probabilities: 0.16955532 - temperature 2.7368128\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 1587.4392 - val_loss: 1551.6024\n",
      "Epoch 47/200\n",
      "mean max of probabilities: 0.17014238 - temperature 2.659129\n",
      "8000/8000 [==============================] - 12s 2ms/step - loss: 1565.6202 - val_loss: 1531.9986\n",
      "Epoch 48/200\n",
      "mean max of probabilities: 0.17209327 - temperature 2.5836504\n",
      "8000/8000 [==============================] - 14s 2ms/step - loss: 1545.9640 - val_loss: 1517.3297\n",
      "Epoch 49/200\n",
      "mean max of probabilities: 0.17406863 - temperature 2.5103142\n",
      "8000/8000 [==============================] - 12s 1ms/step - loss: 1529.8514 - val_loss: 1497.9972\n",
      "Epoch 50/200\n",
      "mean max of probabilities: 0.17438322 - temperature 2.43906\n",
      "8000/8000 [==============================] - 14s 2ms/step - loss: 1524.8087 - val_loss: 1486.0960\n",
      "Epoch 51/200\n",
      "mean max of probabilities: 0.175094 - temperature 2.369828\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 1510.3069 - val_loss: 1494.9114\n",
      "Epoch 52/200\n",
      "mean max of probabilities: 0.17637241 - temperature 2.3025618\n",
      "8000/8000 [==============================] - 15s 2ms/step - loss: 1513.2141 - val_loss: 1487.2639\n",
      "Epoch 53/200\n",
      "mean max of probabilities: 0.17719848 - temperature 2.2372043\n",
      "8000/8000 [==============================] - 12s 1ms/step - loss: 1513.5250 - val_loss: 1500.0003\n",
      "Epoch 54/200\n",
      "mean max of probabilities: 0.17755167 - temperature 2.173702\n",
      "8000/8000 [==============================] - 14s 2ms/step - loss: 1508.6188 - val_loss: 1462.5903\n",
      "Epoch 55/200\n",
      "mean max of probabilities: 0.17791755 - temperature 2.1120012\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 1513.9451 - val_loss: 1500.8500\n",
      "Epoch 56/200\n",
      "mean max of probabilities: 0.17850605 - temperature 2.0520527\n",
      "8000/8000 [==============================] - 15s 2ms/step - loss: 1515.2418 - val_loss: 1490.4999\n",
      "Epoch 57/200\n",
      "mean max of probabilities: 0.17889433 - temperature 1.993806\n",
      "8000/8000 [==============================] - 15s 2ms/step - loss: 1528.2386 - val_loss: 1515.8075\n",
      "Epoch 58/200\n",
      "mean max of probabilities: 0.17961489 - temperature 1.9372126\n",
      "8000/8000 [==============================] - 16s 2ms/step - loss: 1540.3140 - val_loss: 1527.8175\n",
      "Epoch 59/200\n",
      "mean max of probabilities: 0.18065028 - temperature 1.8822256\n",
      "8000/8000 [==============================] - 12s 2ms/step - loss: 1554.0014 - val_loss: 1539.6479\n",
      "Epoch 60/200\n",
      "mean max of probabilities: 0.18233138 - temperature 1.8287995\n",
      "8000/8000 [==============================] - 16s 2ms/step - loss: 1565.8370 - val_loss: 1528.7737\n",
      "Epoch 61/200\n",
      "mean max of probabilities: 0.18321548 - temperature 1.7768897\n",
      "8000/8000 [==============================] - 20s 2ms/step - loss: 1565.8773 - val_loss: 1563.3390\n",
      "Epoch 62/200\n",
      "mean max of probabilities: 0.18505533 - temperature 1.7264532\n",
      "8000/8000 [==============================] - 16s 2ms/step - loss: 1580.1696 - val_loss: 1576.1016\n",
      "Epoch 63/200\n",
      "mean max of probabilities: 0.18725881 - temperature 1.6774484\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 1594.1848 - val_loss: 1572.5684\n",
      "Epoch 64/200\n",
      "mean max of probabilities: 0.18978181 - temperature 1.6298345\n",
      "8000/8000 [==============================] - 15s 2ms/step - loss: 1608.3205 - val_loss: 1568.3079\n",
      "Epoch 65/200\n",
      "mean max of probabilities: 0.19317865 - temperature 1.583572\n",
      "8000/8000 [==============================] - 15s 2ms/step - loss: 1606.6990 - val_loss: 1596.3251\n",
      "Epoch 66/200\n",
      "mean max of probabilities: 0.19697453 - temperature 1.5386227\n",
      "8000/8000 [==============================] - 16s 2ms/step - loss: 1623.2768 - val_loss: 1570.7092\n",
      "Epoch 67/200\n",
      "mean max of probabilities: 0.20146629 - temperature 1.4949492\n",
      "8000/8000 [==============================] - 16s 2ms/step - loss: 1625.7473 - val_loss: 1620.8269\n",
      "Epoch 68/200\n",
      "mean max of probabilities: 0.20700485 - temperature 1.4525156\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 1642.1824 - val_loss: 1611.3378\n",
      "Epoch 69/200\n",
      "mean max of probabilities: 0.21308047 - temperature 1.4112862\n",
      "8000/8000 [==============================] - 14s 2ms/step - loss: 1642.9996 - val_loss: 1603.9992\n",
      "Epoch 70/200\n",
      "mean max of probabilities: 0.21987627 - temperature 1.3712273\n",
      "8000/8000 [==============================] - 15s 2ms/step - loss: 1648.8783 - val_loss: 1624.6225\n",
      "Epoch 71/200\n",
      "mean max of probabilities: 0.2279108 - temperature 1.3323054\n",
      "8000/8000 [==============================] - 14s 2ms/step - loss: 1648.4681 - val_loss: 1622.0384\n",
      "Epoch 72/200\n",
      "mean max of probabilities: 0.23729458 - temperature 1.2944883\n",
      "8000/8000 [==============================] - 12s 2ms/step - loss: 1655.3083 - val_loss: 1620.1504\n",
      "Epoch 73/200\n",
      "mean max of probabilities: 0.24699247 - temperature 1.2577448\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 1639.5249 - val_loss: 1635.0673\n",
      "Epoch 74/200\n",
      "mean max of probabilities: 0.25776678 - temperature 1.2220443\n",
      "8000/8000 [==============================] - 12s 2ms/step - loss: 1656.5801 - val_loss: 1633.7220\n",
      "Epoch 75/200\n",
      "mean max of probabilities: 0.26980212 - temperature 1.1873572\n",
      "8000/8000 [==============================] - 12s 1ms/step - loss: 1639.6439 - val_loss: 1611.0213\n",
      "Epoch 76/200\n",
      "mean max of probabilities: 0.28277898 - temperature 1.1536546\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 1644.6128 - val_loss: 1606.4493\n",
      "Epoch 77/200\n",
      "mean max of probabilities: 0.29672697 - temperature 1.1209084\n",
      "8000/8000 [==============================] - 12s 2ms/step - loss: 1629.3185 - val_loss: 1598.0498\n",
      "Epoch 78/200\n",
      "mean max of probabilities: 0.3109927 - temperature 1.089092\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 1616.7848 - val_loss: 1611.6968\n",
      "Epoch 79/200\n",
      "mean max of probabilities: 0.3269731 - temperature 1.0581783\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 1620.6608 - val_loss: 1580.8637\n",
      "Epoch 80/200\n",
      "mean max of probabilities: 0.34323844 - temperature 1.0281421\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 1611.8078 - val_loss: 1568.8138\n",
      "Epoch 81/200\n",
      "mean max of probabilities: 0.36089745 - temperature 0.9989582\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 1603.4803 - val_loss: 1561.2680\n",
      "Epoch 82/200\n",
      "mean max of probabilities: 0.37865293 - temperature 0.970603\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 1586.7717 - val_loss: 1531.7469\n",
      "Epoch 83/200\n",
      "mean max of probabilities: 0.39727482 - temperature 0.9430529\n",
      "7595/8000 [===========================>..] - ETA: 0s - loss: 1581.3285"
     ]
    }
   ],
   "source": [
    "for p_seed in np.arange(0,50):\n",
    "    orig_train_acc,orig_test_acc,selec_train_acc,selec_test_acc,reconstruction_loss=cal(p_data_arr,\\\n",
    "                                                                                        p_label_arr_onehot,\\\n",
    "                                                                                        p_key_feture_number,\\\n",
    "                                                                                        p_epochs_number,\\\n",
    "                                                                                        p_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

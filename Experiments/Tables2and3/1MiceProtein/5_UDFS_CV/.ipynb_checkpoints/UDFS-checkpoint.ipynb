{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "#----------------------------Reproducible----------------------------------------------------------------------------------------\n",
    "import numpy as np\n",
    "import random as rn\n",
    "import os\n",
    "\n",
    "seed=0\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "np.random.seed(seed)\n",
    "rn.seed(seed)\n",
    "\n",
    "#----------------------------Reproducible----------------------------------------------------------------------------------------\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "import random\n",
    "import scipy.sparse as sparse\n",
    "import scipy.io\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skfeature.utility import construct_W\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from skfeature.function.sparse_learning_based.UDFS import udfs\n",
    "from skfeature.utility import construct_W\n",
    "from skfeature.utility.sparse_learning import feature_ranking\n",
    "import time\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.impute import SimpleImputer \n",
    "import pandas as pd\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "#Import ourslef defined methods\n",
    "import sys\n",
    "sys.path.append(r\"../Defined\")\n",
    "import Functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame=pd.read_excel('../Dataset/Data_Cortex_Nuclear.xls',sheet_name='Hoja1')\n",
    "\n",
    "data_arr=(np.array(data_frame)[:,1:78]).copy()\n",
    "label_arr=(np.array(data_frame)[:,81]).copy()\n",
    "\n",
    "for index_i in np.arange(len(label_arr)):\n",
    "    if label_arr[index_i]=='c-CS-s':\n",
    "        label_arr[index_i]='0'\n",
    "    if label_arr[index_i]=='c-CS-m':\n",
    "        label_arr[index_i]='1'\n",
    "    if label_arr[index_i]=='c-SC-s':\n",
    "        label_arr[index_i]='2'\n",
    "    if label_arr[index_i]=='c-SC-m':\n",
    "        label_arr[index_i]='3'\n",
    "    if label_arr[index_i]=='t-CS-s':\n",
    "        label_arr[index_i]='4'\n",
    "    if label_arr[index_i]=='t-CS-m':\n",
    "        label_arr[index_i]='5'\n",
    "    if label_arr[index_i]=='t-SC-s':\n",
    "        label_arr[index_i]='6'\n",
    "    if label_arr[index_i]=='t-SC-m':\n",
    "        label_arr[index_i]='7'\n",
    "\n",
    "label_arr_onehot=label_arr#to_categorical(label_arr)\n",
    "\n",
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp_mean.fit(data_arr)\n",
    "data_arr=imp_mean.transform(data_arr)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled = scaler.fit_transform(data_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_feture_number=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 .Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "def write_to_csv(p_data,p_path):\n",
    "    dataframe = pd.DataFrame(p_data)\n",
    "    dataframe.to_csv(p_path, mode='a',header=False,index=False,sep=',')\n",
    "    del dataframe\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------       \n",
    "def mse_check(train, test):\n",
    "    LR = LinearRegression(n_jobs = -1)\n",
    "    LR.fit(train[0], train[1])\n",
    "    MSELR = ((LR.predict(test[0]) - test[1]) ** 2).mean()\n",
    "    return MSELR\n",
    "\n",
    "def udfs_used(train, test, K, debug = False):\n",
    "    x_train, x_val, y_train, y_val = train_test_split(train[0], train[1], test_size = 0.1)\n",
    "    bindices = []\n",
    "    bmse = 1e100\n",
    "    for gamma in [1e-3, 1e-1, 1e0, 1e1]:#le3\n",
    "        print(\"gamma\",gamma)\n",
    "        W = udfs(x_train,verbose=debug, gamma = gamma, max_iter = 100)\n",
    "        indices = feature_ranking(W)[: K]\n",
    "        mse = mse_check((train[0][:, indices], train[1]), (x_val[:, indices], y_val))\n",
    "        if bmse > mse:\n",
    "            bmse = mse\n",
    "            bindices = indices\n",
    "    if debug:\n",
    "        print(bindices, bmse)\n",
    "    return train[0][:, bindices], test[0][:, bindices]\n",
    " \n",
    "#--------------------------------------------------------------------------------------------------------------------------------       \n",
    "def cal(p_data_arr,\\\n",
    "        p_label_arr_onehot,\\\n",
    "        p_key_feture_number,\\\n",
    "        p_seed):\n",
    "    \n",
    "    C_train_x,C_test_x,C_train_y,C_test_y= train_test_split(p_data_arr,p_label_arr_onehot,test_size=0.2,random_state=p_seed)\n",
    "\n",
    "    os.environ['PYTHONHASHSEED'] = str(p_seed)\n",
    "    np.random.seed(p_seed)\n",
    "    rn.seed(p_seed)\n",
    "    \n",
    "    train_feature=C_train_x\n",
    "    train_label=C_train_y\n",
    "    test_feature=C_test_x\n",
    "    test_label=C_test_y\n",
    "    \n",
    "    #--------------------------------------------------------------------------------------------------------------------------------\n",
    "    train=(C_train_x,C_train_x)\n",
    "    test=(C_test_x,C_test_x)\n",
    "\n",
    "    t_start = time.time()\n",
    "\n",
    "    C_train_selected_x, C_test_selected_x = udfs_used(train, test, p_key_feture_number)\n",
    "    \n",
    "    t_used=time.time() - t_start\n",
    "    \n",
    "    write_to_csv(np.array([t_used]),\"./log/UDFS_time.csv\")\n",
    "\n",
    "    # Classification on original features\n",
    "    train_feature=C_train_x\n",
    "    train_label=C_train_y\n",
    "    test_feature=C_test_x\n",
    "    test_label=C_test_y\n",
    "    \n",
    "    orig_train_acc,orig_test_acc=F.ETree(train_feature,train_label,test_feature,test_label,0)\n",
    "    \n",
    "    # Classification on selected features\n",
    "    \n",
    "    train_feature=C_train_selected_x\n",
    "    train_label=C_train_y\n",
    "    test_feature=C_test_selected_x\n",
    "    test_label=C_test_y\n",
    "\n",
    "    selec_train_acc,selec_test_acc=F.ETree(train_feature,train_label,test_feature,test_label,0)\n",
    "\n",
    "    # Linear reconstruction\n",
    "    train_feature_tuple=(C_train_selected_x,C_train_x)\n",
    "    test_feature_tuple=(C_test_selected_x,C_test_x)\n",
    "\n",
    "    reconstruction_loss=mse_check(train_feature_tuple, test_feature_tuple)\n",
    "    results=np.array([orig_train_acc,orig_test_acc,selec_train_acc,selec_test_acc,reconstruction_loss])\n",
    "    \n",
    "    write_to_csv(results.reshape(1,len(results)),\"./log/UDFS_results.csv\")\n",
    "    \n",
    "    return orig_train_acc,orig_test_acc,selec_train_acc,selec_test_acc,reconstruction_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_data_arr=data_arr\n",
    "p_label_arr_onehot=label_arr_onehot\n",
    "p_key_feture_number=key_feture_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma 0.001\n",
      "gamma 0.1\n",
      "gamma 1.0\n",
      "gamma 10.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 1.0\n",
      "Testing accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9583333333333334\n",
      "Testing accuracy： 0.9583333333333334\n",
      "gamma 0.001\n",
      "gamma 0.1\n",
      "gamma 1.0\n",
      "gamma 10.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 1.0\n",
      "Testing accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9907407407407407\n",
      "Testing accuracy： 0.9907407407407407\n",
      "gamma 0.001\n",
      "gamma 0.1\n",
      "gamma 1.0\n",
      "gamma 10.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9953703703703703\n",
      "Testing accuracy： 0.9953703703703703\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9537037037037037\n",
      "Testing accuracy： 0.9537037037037037\n",
      "gamma 0.001\n",
      "gamma 0.1\n",
      "gamma 1.0\n",
      "gamma 10.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9907407407407407\n",
      "Testing accuracy： 0.9907407407407407\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.875\n",
      "Testing accuracy： 0.875\n",
      "gamma 0.001\n",
      "gamma 0.1\n",
      "gamma 1.0\n",
      "gamma 10.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9675925925925926\n",
      "Testing accuracy： 0.9675925925925926\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9768518518518519\n",
      "Testing accuracy： 0.9768518518518519\n",
      "gamma 0.001\n",
      "gamma 0.1\n",
      "gamma 1.0\n",
      "gamma 10.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9861111111111112\n",
      "Testing accuracy： 0.9861111111111112\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9861111111111112\n",
      "Testing accuracy： 0.9861111111111112\n",
      "gamma 0.001\n",
      "gamma 0.1\n",
      "gamma 1.0\n",
      "gamma 10.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9953703703703703\n",
      "Testing accuracy： 0.9953703703703703\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9629629629629629\n",
      "Testing accuracy： 0.9629629629629629\n",
      "gamma 0.001\n",
      "gamma 0.1\n",
      "gamma 1.0\n",
      "gamma 10.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9953703703703703\n",
      "Testing accuracy： 0.9953703703703703\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9675925925925926\n",
      "Testing accuracy： 0.9675925925925926\n",
      "gamma 0.001\n",
      "gamma 0.1\n",
      "gamma 1.0\n",
      "gamma 10.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 1.0\n",
      "Testing accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9768518518518519\n",
      "Testing accuracy： 0.9768518518518519\n",
      "gamma 0.001\n",
      "gamma 0.1\n",
      "gamma 1.0\n",
      "gamma 10.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 1.0\n",
      "Testing accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9814814814814815\n",
      "Testing accuracy： 0.9814814814814815\n",
      "gamma 0.001\n",
      "gamma 0.1\n",
      "gamma 1.0\n",
      "gamma 10.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9953703703703703\n",
      "Testing accuracy： 0.9953703703703703\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9768518518518519\n",
      "Testing accuracy： 0.9768518518518519\n",
      "gamma 0.001\n",
      "gamma 0.1\n",
      "gamma 1.0\n",
      "gamma 10.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9953703703703703\n",
      "Testing accuracy： 0.9953703703703703\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9861111111111112\n",
      "Testing accuracy： 0.9861111111111112\n",
      "gamma 0.001\n",
      "gamma 0.1\n",
      "gamma 1.0\n",
      "gamma 10.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 1.0\n",
      "Testing accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9675925925925926\n",
      "Testing accuracy： 0.9675925925925926\n",
      "gamma 0.001\n",
      "gamma 0.1\n",
      "gamma 1.0\n",
      "gamma 10.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9907407407407407\n",
      "Testing accuracy： 0.9907407407407407\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9583333333333334\n",
      "Testing accuracy： 0.9583333333333334\n",
      "gamma 0.001\n",
      "gamma 0.1\n",
      "gamma 1.0\n",
      "gamma 10.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 1.0\n",
      "Testing accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 1.0\n",
      "Testing accuracy： 1.0\n",
      "gamma 0.001\n",
      "gamma 0.1\n",
      "gamma 1.0\n",
      "gamma 10.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 1.0\n",
      "Testing accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9768518518518519\n",
      "Testing accuracy： 0.9768518518518519\n",
      "gamma 0.001\n",
      "gamma 0.1\n",
      "gamma 1.0\n",
      "gamma 10.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9953703703703703\n",
      "Testing accuracy： 0.9953703703703703\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9629629629629629\n",
      "Testing accuracy： 0.9629629629629629\n",
      "gamma 0.001\n",
      "gamma 0.1\n",
      "gamma 1.0\n",
      "gamma 10.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 1.0\n",
      "Testing accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9768518518518519\n",
      "Testing accuracy： 0.9768518518518519\n",
      "gamma 0.001\n",
      "gamma 0.1\n",
      "gamma 1.0\n",
      "gamma 10.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9861111111111112\n",
      "Testing accuracy： 0.9861111111111112\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9583333333333334\n",
      "Testing accuracy： 0.9583333333333334\n",
      "gamma 0.001\n",
      "gamma 0.1\n",
      "gamma 1.0\n",
      "gamma 10.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 1.0\n",
      "Testing accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9675925925925926\n",
      "Testing accuracy： 0.9675925925925926\n",
      "gamma 0.001\n",
      "gamma 0.1\n",
      "gamma 1.0\n",
      "gamma 10.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9861111111111112\n",
      "Testing accuracy： 0.9861111111111112\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9120370370370371\n",
      "Testing accuracy： 0.9120370370370371\n",
      "gamma 0.001\n",
      "gamma 0.1\n",
      "gamma 1.0\n",
      "gamma 10.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 1.0\n",
      "Testing accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9675925925925926\n",
      "Testing accuracy： 0.9675925925925926\n",
      "gamma 0.001\n",
      "gamma 0.1\n",
      "gamma 1.0\n",
      "gamma 10.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9953703703703703\n",
      "Testing accuracy： 0.9953703703703703\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9722222222222222\n",
      "Testing accuracy： 0.9722222222222222\n",
      "gamma 0.001\n",
      "gamma 0.1\n",
      "gamma 1.0\n",
      "gamma 10.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 1.0\n",
      "Testing accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9583333333333334\n",
      "Testing accuracy： 0.9583333333333334\n",
      "gamma 0.001\n",
      "gamma 0.1\n",
      "gamma 1.0\n",
      "gamma 10.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9907407407407407\n",
      "Testing accuracy： 0.9907407407407407\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9861111111111112\n",
      "Testing accuracy： 0.9861111111111112\n",
      "gamma 0.001\n",
      "gamma 0.1\n",
      "gamma 1.0\n",
      "gamma 10.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9953703703703703\n",
      "Testing accuracy： 0.9953703703703703\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9583333333333334\n",
      "Testing accuracy： 0.9583333333333334\n",
      "gamma 0.001\n",
      "gamma 0.1\n",
      "gamma 1.0\n",
      "gamma 10.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 1.0\n",
      "Testing accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9444444444444444\n",
      "Testing accuracy： 0.9444444444444444\n",
      "gamma 0.001\n",
      "gamma 0.1\n",
      "gamma 1.0\n",
      "gamma 10.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9814814814814815\n",
      "Testing accuracy： 0.9814814814814815\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9212962962962963\n",
      "Testing accuracy： 0.9212962962962963\n",
      "gamma 0.001\n",
      "gamma 0.1\n",
      "gamma 1.0\n",
      "gamma 10.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9953703703703703\n",
      "Testing accuracy： 0.9953703703703703\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9814814814814815\n",
      "Testing accuracy： 0.9814814814814815\n",
      "gamma 0.001\n",
      "gamma 0.1\n",
      "gamma 1.0\n",
      "gamma 10.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9907407407407407\n",
      "Testing accuracy： 0.9907407407407407\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9907407407407407\n",
      "Testing accuracy： 0.9907407407407407\n",
      "gamma 0.001\n",
      "gamma 0.1\n",
      "gamma 1.0\n",
      "gamma 10.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9814814814814815\n",
      "Testing accuracy： 0.9814814814814815\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9675925925925926\n",
      "Testing accuracy： 0.9675925925925926\n",
      "gamma 0.001\n",
      "gamma 0.1\n",
      "gamma 1.0\n",
      "gamma 10.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9953703703703703\n",
      "Testing accuracy： 0.9953703703703703\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9259259259259259\n",
      "Testing accuracy： 0.9259259259259259\n",
      "gamma 0.001\n",
      "gamma 0.1\n",
      "gamma 1.0\n",
      "gamma 10.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9953703703703703\n",
      "Testing accuracy： 0.9953703703703703\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9537037037037037\n",
      "Testing accuracy： 0.9537037037037037\n",
      "gamma 0.001\n",
      "gamma 0.1\n",
      "gamma 1.0\n",
      "gamma 10.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 1.0\n",
      "Testing accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9444444444444444\n",
      "Testing accuracy： 0.9444444444444444\n",
      "gamma 0.001\n",
      "gamma 0.1\n",
      "gamma 1.0\n",
      "gamma 10.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 1.0\n",
      "Testing accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9675925925925926\n",
      "Testing accuracy： 0.9675925925925926\n",
      "gamma 0.001\n",
      "gamma 0.1\n",
      "gamma 1.0\n",
      "gamma 10.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9907407407407407\n",
      "Testing accuracy： 0.9907407407407407\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9768518518518519\n",
      "Testing accuracy： 0.9768518518518519\n",
      "gamma 0.001\n",
      "gamma 0.1\n",
      "gamma 1.0\n",
      "gamma 10.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 1.0\n",
      "Testing accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9583333333333334\n",
      "Testing accuracy： 0.9583333333333334\n",
      "gamma 0.001\n",
      "gamma 0.1\n",
      "gamma 1.0\n",
      "gamma 10.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9861111111111112\n",
      "Testing accuracy： 0.9861111111111112\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9444444444444444\n",
      "Testing accuracy： 0.9444444444444444\n",
      "gamma 0.001\n",
      "gamma 0.1\n",
      "gamma 1.0\n",
      "gamma 10.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 1.0\n",
      "Testing accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9768518518518519\n",
      "Testing accuracy： 0.9768518518518519\n",
      "gamma 0.001\n",
      "gamma 0.1\n",
      "gamma 1.0\n",
      "gamma 10.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 1.0\n",
      "Testing accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9722222222222222\n",
      "Testing accuracy： 0.9722222222222222\n",
      "gamma 0.001\n",
      "gamma 0.1\n",
      "gamma 1.0\n",
      "gamma 10.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9861111111111112\n",
      "Testing accuracy： 0.9861111111111112\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9444444444444444\n",
      "Testing accuracy： 0.9444444444444444\n",
      "gamma 0.001\n",
      "gamma 0.1\n",
      "gamma 1.0\n",
      "gamma 10.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 1.0\n",
      "Testing accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9537037037037037\n",
      "Testing accuracy： 0.9537037037037037\n",
      "gamma 0.001\n",
      "gamma 0.1\n",
      "gamma 1.0\n",
      "gamma 10.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 1.0\n",
      "Testing accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9768518518518519\n",
      "Testing accuracy： 0.9768518518518519\n",
      "gamma 0.001\n",
      "gamma 0.1\n",
      "gamma 1.0\n",
      "gamma 10.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 1.0\n",
      "Testing accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9490740740740741\n",
      "Testing accuracy： 0.9490740740740741\n",
      "gamma 0.001\n",
      "gamma 0.1\n",
      "gamma 1.0\n",
      "gamma 10.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9814814814814815\n",
      "Testing accuracy： 0.9814814814814815\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9305555555555556\n",
      "Testing accuracy： 0.9305555555555556\n",
      "gamma 0.001\n",
      "gamma 0.1\n",
      "gamma 1.0\n",
      "gamma 10.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9861111111111112\n",
      "Testing accuracy： 0.9861111111111112\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9768518518518519\n",
      "Testing accuracy： 0.9768518518518519\n",
      "gamma 0.001\n",
      "gamma 0.1\n",
      "gamma 1.0\n",
      "gamma 10.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 1.0\n",
      "Testing accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9814814814814815\n",
      "Testing accuracy： 0.9814814814814815\n",
      "gamma 0.001\n",
      "gamma 0.1\n",
      "gamma 1.0\n",
      "gamma 10.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9953703703703703\n",
      "Testing accuracy： 0.9953703703703703\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9814814814814815\n",
      "Testing accuracy： 0.9814814814814815\n",
      "gamma 0.001\n",
      "gamma 0.1\n",
      "gamma 1.0\n",
      "gamma 10.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9953703703703703\n",
      "Testing accuracy： 0.9953703703703703\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9583333333333334\n",
      "Testing accuracy： 0.9583333333333334\n",
      "gamma 0.001\n",
      "gamma 0.1\n",
      "gamma 1.0\n",
      "gamma 10.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9953703703703703\n",
      "Testing accuracy： 0.9953703703703703\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.9907407407407407\n",
      "Testing accuracy： 0.9907407407407407\n"
     ]
    }
   ],
   "source": [
    "for p_seed in np.arange(0,50):\n",
    "    orig_train_acc,orig_test_acc,selec_train_acc,selec_test_acc,reconstruction_loss=cal(p_data_arr,\\\n",
    "                                                                                        p_label_arr_onehot,\\\n",
    "                                                                                        p_key_feture_number,\\\n",
    "                                                                                        p_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

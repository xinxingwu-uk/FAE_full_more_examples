{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#----------------------------Reproducible----------------------------------------------------------------------------------------\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "import os\n",
    "\n",
    "seed=0\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "np.random.seed(seed)\n",
    "rn.seed(seed)\n",
    "\n",
    "#----------------------------Reproducible----------------------------------------------------------------------------------------\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "import random\n",
    "import scipy.sparse as sparse\n",
    "import scipy.io\n",
    "import time\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skfeature.utility import construct_W\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from skfeature.utility.sparse_learning import feature_ranking\n",
    "import time\n",
    "from sklearn.impute import SimpleImputer \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from concrete_autoencoder import ConcreteAutoencoderFeatureSelector\n",
    "from keras.layers import Dense\n",
    "import pandas as pd\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "#Import defined methods\n",
    "import sys\n",
    "sys.path.append(r\"../Defined\")\n",
    "import Functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame=pd.read_excel('../Dataset/Data_Cortex_Nuclear.xls',sheet_name='Hoja1')\n",
    "\n",
    "data_arr=(np.array(data_frame)[:,1:78]).copy()\n",
    "label_arr=(np.array(data_frame)[:,81]).copy()\n",
    "\n",
    "for index_i in np.arange(len(label_arr)):\n",
    "    if label_arr[index_i]=='c-CS-s':\n",
    "        label_arr[index_i]='0'\n",
    "    if label_arr[index_i]=='c-CS-m':\n",
    "        label_arr[index_i]='1'\n",
    "    if label_arr[index_i]=='c-SC-s':\n",
    "        label_arr[index_i]='2'\n",
    "    if label_arr[index_i]=='c-SC-m':\n",
    "        label_arr[index_i]='3'\n",
    "    if label_arr[index_i]=='t-CS-s':\n",
    "        label_arr[index_i]='4'\n",
    "    if label_arr[index_i]=='t-CS-m':\n",
    "        label_arr[index_i]='5'\n",
    "    if label_arr[index_i]=='t-SC-s':\n",
    "        label_arr[index_i]='6'\n",
    "    if label_arr[index_i]=='t-SC-m':\n",
    "        label_arr[index_i]='7'\n",
    "\n",
    "label_arr_onehot=label_arr#to_categorical(label_arr)\n",
    "\n",
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp_mean.fit(data_arr)\n",
    "data_arr=imp_mean.transform(data_arr)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled = scaler.fit_transform(data_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_feture_number=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "def write_to_csv(p_data,p_path):\n",
    "    dataframe = pd.DataFrame(p_data)\n",
    "    dataframe.to_csv(p_path, mode='a',header=False,index=False,sep=',')\n",
    "    del dataframe\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------       \n",
    "def mse_check(train, test):\n",
    "    LR = LinearRegression(n_jobs = -1)\n",
    "    LR.fit(train[0], train[1])\n",
    "    MSELR = ((LR.predict(test[0]) - test[1]) ** 2).mean()\n",
    "    return MSELR\n",
    " \n",
    "#--------------------------------------------------------------------------------------------------------------------------------       \n",
    "def cal(p_data_arr,\\\n",
    "        p_label_arr_onehot,\\\n",
    "        p_key_feture_number,\\\n",
    "        p_epochs_number,\\\n",
    "        p_seed):\n",
    "    \n",
    "    C_train_x,C_test_x,C_train_y,C_test_y= train_test_split(p_data_arr,p_label_arr_onehot,test_size=0.2,random_state=p_seed)\n",
    "\n",
    "    os.environ['PYTHONHASHSEED'] = str(p_seed)\n",
    "    np.random.seed(p_seed)\n",
    "    rn.seed(p_seed)\n",
    "    tf.compat.v1.set_random_seed(p_seed)\n",
    "    \n",
    "    #--------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    def decoder(x):\n",
    "        #x = Dense(key_feture_number)(x)\n",
    "        x = Dense(data_arr.shape[1])(x)\n",
    "        return x\n",
    "\n",
    "    t_start = time.time()\n",
    "    selector = ConcreteAutoencoderFeatureSelector(K = p_key_feture_number, output_function = decoder, num_epochs = p_epochs_number)\n",
    "    selector.fit(C_train_x, C_train_x, C_test_x, C_test_x)\n",
    "    t_used=time.time() - t_start\n",
    "    \n",
    "    write_to_csv(np.array([t_used]),\"./log/CAE_time.csv\")\n",
    "    \n",
    "    train_compressed_Data=p_data_arr[:, selector.get_support(indices=True)]\n",
    "    \n",
    "    # Classification on original features\n",
    "    train_feature=C_train_x\n",
    "    train_label=C_train_y\n",
    "    test_feature=C_test_x\n",
    "    test_label=C_test_y \n",
    "    orig_train_acc,orig_test_acc=F.ETree(train_feature,train_label,test_feature,test_label,0)\n",
    "        \n",
    "    # Classification on selected features\n",
    "    C_train_selected_x,C_test_selected_x,C_train_y,C_test_y= train_test_split(train_compressed_Data,p_label_arr_onehot,test_size=0.2,random_state=p_seed)\n",
    "    \n",
    "    train_feature=C_train_selected_x\n",
    "    train_label=C_train_y\n",
    "    test_feature=C_test_selected_x\n",
    "    test_label=C_test_y\n",
    "    selec_train_acc,selec_test_acc=F.ETree(train_feature,train_label,test_feature,test_label,0)\n",
    "    \n",
    "    # Linear reconstruction\n",
    "    train_feature_tuple=(C_train_selected_x,C_train_x)\n",
    "    test_feature_tuple=(C_test_selected_x,C_test_x)\n",
    "\n",
    "    reconstruction_loss=mse_check(train_feature_tuple, test_feature_tuple)\n",
    "    \n",
    "    results=np.array([orig_train_acc,orig_test_acc,selec_train_acc,selec_test_acc,reconstruction_loss])\n",
    "    \n",
    "    write_to_csv(results.reshape(1,len(results)),\"./log/CAE_results.csv\")\n",
    "    \n",
    "    return orig_train_acc,orig_test_acc,selec_train_acc,selec_test_acc,reconstruction_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_number=200\n",
    "\n",
    "p_data_arr=data_arr\n",
    "p_label_arr_onehot=label_arr_onehot\n",
    "p_key_feture_number=key_feture_number\n",
    "p_epochs_number=epochs_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1702: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 77)                0         \n",
      "_________________________________________________________________\n",
      "concrete_select (ConcreteSel (None, 10)                771       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 77)                847       \n",
      "=================================================================\n",
      "Total params: 1,618\n",
      "Trainable params: 1,617\n",
      "Non-trainable params: 1\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 864 samples, validate on 216 samples\n",
      "Epoch 1/200\n",
      "mean max of probabilities: 0.017830983 - temperature 10.0\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.9796 - val_loss: 0.7756\n",
      "Epoch 2/200\n",
      "mean max of probabilities: 0.018159008 - temperature 9.714222\n",
      "864/864 [==============================] - 1s 580us/step - loss: 0.6240 - val_loss: 0.5105\n",
      "Epoch 3/200\n",
      "mean max of probabilities: 0.018717837 - temperature 9.436611\n",
      "864/864 [==============================] - 0s 374us/step - loss: 0.4195 - val_loss: 0.3492\n",
      "Epoch 4/200\n",
      "mean max of probabilities: 0.019799365 - temperature 9.166935\n",
      "864/864 [==============================] - 1s 592us/step - loss: 0.2938 - val_loss: 0.2504\n",
      "Epoch 5/200\n",
      "mean max of probabilities: 0.02113052 - temperature 8.904965\n",
      "864/864 [==============================] - 1s 604us/step - loss: 0.2124 - val_loss: 0.1854\n",
      "Epoch 6/200\n",
      "mean max of probabilities: 0.022551203 - temperature 8.650478\n",
      "864/864 [==============================] - 0s 366us/step - loss: 0.1598 - val_loss: 0.1418\n",
      "Epoch 7/200\n",
      "mean max of probabilities: 0.023901759 - temperature 8.403267\n",
      "864/864 [==============================] - 0s 519us/step - loss: 0.1239 - val_loss: 0.1107\n",
      "Epoch 8/200\n",
      "mean max of probabilities: 0.025147596 - temperature 8.163121\n",
      "864/864 [==============================] - 0s 460us/step - loss: 0.0993 - val_loss: 0.0904\n",
      "Epoch 9/200\n",
      "mean max of probabilities: 0.026278531 - temperature 7.9298377\n",
      "864/864 [==============================] - 0s 571us/step - loss: 0.0824 - val_loss: 0.0762\n",
      "Epoch 10/200\n",
      "mean max of probabilities: 0.027266135 - temperature 7.7032237\n",
      "864/864 [==============================] - 0s 474us/step - loss: 0.0708 - val_loss: 0.0663\n",
      "Epoch 11/200\n",
      "mean max of probabilities: 0.028167006 - temperature 7.483083\n",
      "864/864 [==============================] - 0s 536us/step - loss: 0.0631 - val_loss: 0.0601\n",
      "Epoch 12/200\n",
      "mean max of probabilities: 0.028978338 - temperature 7.269233\n",
      "864/864 [==============================] - 0s 345us/step - loss: 0.0577 - val_loss: 0.0560\n",
      "Epoch 13/200\n",
      "mean max of probabilities: 0.029704371 - temperature 7.061494\n",
      "864/864 [==============================] - 0s 421us/step - loss: 0.0542 - val_loss: 0.0532\n",
      "Epoch 14/200\n",
      "mean max of probabilities: 0.030331135 - temperature 6.8596926\n",
      "864/864 [==============================] - 0s 562us/step - loss: 0.0523 - val_loss: 0.0514\n",
      "Epoch 15/200\n",
      "mean max of probabilities: 0.03085633 - temperature 6.663658\n",
      "864/864 [==============================] - 0s 460us/step - loss: 0.0509 - val_loss: 0.0505\n",
      "Epoch 16/200\n",
      "mean max of probabilities: 0.0313007 - temperature 6.473224\n",
      "864/864 [==============================] - 0s 391us/step - loss: 0.0502 - val_loss: 0.0499\n",
      "Epoch 17/200\n",
      "mean max of probabilities: 0.031693924 - temperature 6.2882338\n",
      "864/864 [==============================] - 0s 521us/step - loss: 0.0497 - val_loss: 0.0498\n",
      "Epoch 18/200\n",
      "mean max of probabilities: 0.03212327 - temperature 6.108531\n",
      "864/864 [==============================] - 0s 494us/step - loss: 0.0495 - val_loss: 0.0495\n",
      "Epoch 19/200\n",
      "mean max of probabilities: 0.032456007 - temperature 5.933963\n",
      "864/864 [==============================] - 0s 442us/step - loss: 0.0494 - val_loss: 0.0494\n",
      "Epoch 20/200\n",
      "mean max of probabilities: 0.03275048 - temperature 5.764384\n",
      "864/864 [==============================] - 0s 397us/step - loss: 0.0492 - val_loss: 0.0494\n",
      "Epoch 21/200\n",
      "mean max of probabilities: 0.033033386 - temperature 5.5996504\n",
      "864/864 [==============================] - 0s 557us/step - loss: 0.0492 - val_loss: 0.0494\n",
      "Epoch 22/200\n",
      "mean max of probabilities: 0.033391565 - temperature 5.4396253\n",
      "864/864 [==============================] - 0s 349us/step - loss: 0.0492 - val_loss: 0.0494\n",
      "Epoch 23/200\n",
      "mean max of probabilities: 0.033804357 - temperature 5.2841735\n",
      "864/864 [==============================] - 1s 889us/step - loss: 0.0492 - val_loss: 0.0493\n",
      "Epoch 24/200\n",
      "mean max of probabilities: 0.03419988 - temperature 5.133164\n",
      "864/864 [==============================] - 0s 544us/step - loss: 0.0492 - val_loss: 0.0494\n",
      "Epoch 25/200\n",
      "mean max of probabilities: 0.034630038 - temperature 4.9864693\n",
      "864/864 [==============================] - 0s 501us/step - loss: 0.0493 - val_loss: 0.0494\n",
      "Epoch 26/200\n",
      "mean max of probabilities: 0.035351124 - temperature 4.8439674\n",
      "864/864 [==============================] - 1s 680us/step - loss: 0.0490 - val_loss: 0.0492\n",
      "Epoch 27/200\n",
      "mean max of probabilities: 0.036233272 - temperature 4.705537\n",
      "864/864 [==============================] - 1s 706us/step - loss: 0.0491 - val_loss: 0.0492\n",
      "Epoch 28/200\n",
      "mean max of probabilities: 0.037188 - temperature 4.571063\n",
      "864/864 [==============================] - 1s 799us/step - loss: 0.0492 - val_loss: 0.0492\n",
      "Epoch 29/200\n",
      "mean max of probabilities: 0.03831791 - temperature 4.440432\n",
      "864/864 [==============================] - 1s 738us/step - loss: 0.0490 - val_loss: 0.0487\n",
      "Epoch 30/200\n",
      "mean max of probabilities: 0.039436553 - temperature 4.3135343\n",
      "864/864 [==============================] - 1s 675us/step - loss: 0.0489 - val_loss: 0.0492\n",
      "Epoch 31/200\n",
      "mean max of probabilities: 0.04069808 - temperature 4.1902633\n",
      "864/864 [==============================] - 1s 583us/step - loss: 0.0491 - val_loss: 0.0493\n",
      "Epoch 32/200\n",
      "mean max of probabilities: 0.042086627 - temperature 4.070515\n",
      "864/864 [==============================] - 0s 405us/step - loss: 0.0488 - val_loss: 0.0491\n",
      "Epoch 33/200\n",
      "mean max of probabilities: 0.04376047 - temperature 3.9541893\n",
      "864/864 [==============================] - 0s 505us/step - loss: 0.0489 - val_loss: 0.0490\n",
      "Epoch 34/200\n",
      "mean max of probabilities: 0.045721997 - temperature 3.841188\n",
      "864/864 [==============================] - 1s 653us/step - loss: 0.0490 - val_loss: 0.0489\n",
      "Epoch 35/200\n",
      "mean max of probabilities: 0.04771789 - temperature 3.7314155\n",
      "864/864 [==============================] - 1s 581us/step - loss: 0.0487 - val_loss: 0.0489\n",
      "Epoch 36/200\n",
      "mean max of probabilities: 0.049906623 - temperature 3.62478\n",
      "864/864 [==============================] - 1s 708us/step - loss: 0.0489 - val_loss: 0.0492\n",
      "Epoch 37/200\n",
      "mean max of probabilities: 0.052389123 - temperature 3.5211914\n",
      "864/864 [==============================] - 0s 487us/step - loss: 0.0486 - val_loss: 0.0489\n",
      "Epoch 38/200\n",
      "mean max of probabilities: 0.054934144 - temperature 3.420564\n",
      "864/864 [==============================] - 1s 618us/step - loss: 0.0488 - val_loss: 0.0486\n",
      "Epoch 39/200\n",
      "mean max of probabilities: 0.057526935 - temperature 3.3228116\n",
      "864/864 [==============================] - 0s 527us/step - loss: 0.0486 - val_loss: 0.0488\n",
      "Epoch 40/200\n",
      "mean max of probabilities: 0.0601969 - temperature 3.227853\n",
      "864/864 [==============================] - 0s 505us/step - loss: 0.0490 - val_loss: 0.0487\n",
      "Epoch 41/200\n",
      "mean max of probabilities: 0.06318569 - temperature 3.1356087\n",
      "864/864 [==============================] - 0s 559us/step - loss: 0.0487 - val_loss: 0.0491\n",
      "Epoch 42/200\n",
      "mean max of probabilities: 0.066382505 - temperature 3.0459995\n",
      "864/864 [==============================] - 0s 494us/step - loss: 0.0489 - val_loss: 0.0487\n",
      "Epoch 43/200\n",
      "mean max of probabilities: 0.07003425 - temperature 2.9589517\n",
      "864/864 [==============================] - 1s 683us/step - loss: 0.0487 - val_loss: 0.0499\n",
      "Epoch 44/200\n",
      "mean max of probabilities: 0.073456906 - temperature 2.8743913\n",
      "864/864 [==============================] - 0s 551us/step - loss: 0.0484 - val_loss: 0.0494\n",
      "Epoch 45/200\n",
      "mean max of probabilities: 0.076713 - temperature 2.7922478\n",
      "864/864 [==============================] - 1s 681us/step - loss: 0.0490 - val_loss: 0.0498\n",
      "Epoch 46/200\n",
      "mean max of probabilities: 0.08058934 - temperature 2.712452\n",
      "864/864 [==============================] - 1s 738us/step - loss: 0.0488 - val_loss: 0.0492\n",
      "Epoch 47/200\n",
      "mean max of probabilities: 0.08445612 - temperature 2.6349366\n",
      "864/864 [==============================] - 0s 556us/step - loss: 0.0491 - val_loss: 0.0537\n",
      "Epoch 48/200\n",
      "mean max of probabilities: 0.088095166 - temperature 2.5596378\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0486 - val_loss: 0.0496\n",
      "Epoch 49/200\n",
      "mean max of probabilities: 0.09232938 - temperature 2.4864888\n",
      "864/864 [==============================] - 1s 969us/step - loss: 0.0486 - val_loss: 0.0487\n",
      "Epoch 50/200\n",
      "mean max of probabilities: 0.096464366 - temperature 2.4154308\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0492 - val_loss: 0.0508\n",
      "Epoch 51/200\n",
      "mean max of probabilities: 0.100617334 - temperature 2.3464034\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0489 - val_loss: 0.0487\n",
      "Epoch 52/200\n",
      "mean max of probabilities: 0.104659915 - temperature 2.2793484\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0490 - val_loss: 0.0508\n",
      "Epoch 53/200\n",
      "mean max of probabilities: 0.108752586 - temperature 2.2142096\n",
      "864/864 [==============================] - 1s 936us/step - loss: 0.0489 - val_loss: 0.0547\n",
      "Epoch 54/200\n",
      "mean max of probabilities: 0.11340909 - temperature 2.1509328\n",
      "864/864 [==============================] - 1s 993us/step - loss: 0.0497 - val_loss: 0.0510\n",
      "Epoch 55/200\n",
      "mean max of probabilities: 0.11711033 - temperature 2.0894635\n",
      "864/864 [==============================] - 1s 721us/step - loss: 0.0496 - val_loss: 0.0517\n",
      "Epoch 56/200\n",
      "mean max of probabilities: 0.12077384 - temperature 2.0297515\n",
      "864/864 [==============================] - 1s 734us/step - loss: 0.0502 - val_loss: 0.0501\n",
      "Epoch 57/200\n",
      "mean max of probabilities: 0.12510633 - temperature 1.9717458\n",
      "864/864 [==============================] - 1s 606us/step - loss: 0.0508 - val_loss: 0.0493\n",
      "Epoch 58/200\n",
      "mean max of probabilities: 0.12842686 - temperature 1.915398\n",
      "864/864 [==============================] - 1s 633us/step - loss: 0.0523 - val_loss: 0.0484\n",
      "Epoch 59/200\n",
      "mean max of probabilities: 0.13149169 - temperature 1.86066\n",
      "864/864 [==============================] - 0s 424us/step - loss: 0.0522 - val_loss: 0.0507\n",
      "Epoch 60/200\n",
      "mean max of probabilities: 0.13396645 - temperature 1.8074865\n",
      "864/864 [==============================] - 0s 458us/step - loss: 0.0534 - val_loss: 0.0491\n",
      "Epoch 61/200\n",
      "mean max of probabilities: 0.13724422 - temperature 1.7558324\n",
      "864/864 [==============================] - 1s 634us/step - loss: 0.0507 - val_loss: 0.0519\n",
      "Epoch 62/200\n",
      "mean max of probabilities: 0.14019473 - temperature 1.7056547\n",
      "864/864 [==============================] - 1s 843us/step - loss: 0.0493 - val_loss: 0.0492\n",
      "Epoch 63/200\n",
      "mean max of probabilities: 0.14293174 - temperature 1.6569109\n",
      "864/864 [==============================] - 1s 762us/step - loss: 0.0502 - val_loss: 0.0503\n",
      "Epoch 64/200\n",
      "mean max of probabilities: 0.14590354 - temperature 1.6095604\n",
      "864/864 [==============================] - 1s 838us/step - loss: 0.0514 - val_loss: 0.0536\n",
      "Epoch 65/200\n",
      "mean max of probabilities: 0.1482031 - temperature 1.5635628\n",
      "864/864 [==============================] - 1s 936us/step - loss: 0.0545 - val_loss: 0.0489\n",
      "Epoch 66/200\n",
      "mean max of probabilities: 0.15158895 - temperature 1.5188798\n",
      "864/864 [==============================] - 0s 482us/step - loss: 0.0498 - val_loss: 0.0627\n",
      "Epoch 67/200\n",
      "mean max of probabilities: 0.15362196 - temperature 1.4754735\n",
      "864/864 [==============================] - 1s 983us/step - loss: 0.0530 - val_loss: 0.0532\n",
      "Epoch 68/200\n",
      "mean max of probabilities: 0.15685044 - temperature 1.4333079\n",
      "864/864 [==============================] - 1s 860us/step - loss: 0.0563 - val_loss: 0.0498\n",
      "Epoch 69/200\n",
      "mean max of probabilities: 0.16032653 - temperature 1.3923471\n",
      "864/864 [==============================] - 1s 826us/step - loss: 0.0529 - val_loss: 0.0511\n",
      "Epoch 70/200\n",
      "mean max of probabilities: 0.16195486 - temperature 1.352557\n",
      "864/864 [==============================] - 1s 858us/step - loss: 0.0511 - val_loss: 0.0551\n",
      "Epoch 71/200\n",
      "mean max of probabilities: 0.1641868 - temperature 1.313903\n",
      "864/864 [==============================] - 1s 691us/step - loss: 0.0547 - val_loss: 0.0512\n",
      "Epoch 72/200\n",
      "mean max of probabilities: 0.16746204 - temperature 1.2763531\n",
      "864/864 [==============================] - 1s 855us/step - loss: 0.0528 - val_loss: 0.0531\n",
      "Epoch 73/200\n",
      "mean max of probabilities: 0.17025901 - temperature 1.2398779\n",
      "864/864 [==============================] - 1s 700us/step - loss: 0.0574 - val_loss: 0.0496\n",
      "Epoch 74/200\n",
      "mean max of probabilities: 0.17359407 - temperature 1.204445\n",
      "864/864 [==============================] - 1s 669us/step - loss: 0.0619 - val_loss: 0.0576\n",
      "Epoch 75/200\n",
      "mean max of probabilities: 0.17576589 - temperature 1.1700248\n",
      "864/864 [==============================] - 1s 662us/step - loss: 0.0546 - val_loss: 0.0556\n",
      "Epoch 76/200\n",
      "mean max of probabilities: 0.17728686 - temperature 1.136588\n",
      "864/864 [==============================] - 1s 622us/step - loss: 0.0550 - val_loss: 0.0510\n",
      "Epoch 77/200\n",
      "mean max of probabilities: 0.1784939 - temperature 1.1041069\n",
      "864/864 [==============================] - 1s 759us/step - loss: 0.0563 - val_loss: 0.0548\n",
      "Epoch 78/200\n",
      "mean max of probabilities: 0.17974512 - temperature 1.0725542\n",
      "864/864 [==============================] - 1s 845us/step - loss: 0.0606 - val_loss: 0.0581\n",
      "Epoch 79/200\n",
      "mean max of probabilities: 0.18096045 - temperature 1.0419029\n",
      "864/864 [==============================] - 1s 955us/step - loss: 0.0599 - val_loss: 0.0599\n",
      "Epoch 80/200\n",
      "mean max of probabilities: 0.18337727 - temperature 1.0121278\n",
      "864/864 [==============================] - 1s 687us/step - loss: 0.0586 - val_loss: 0.0575\n",
      "Epoch 81/200\n",
      "mean max of probabilities: 0.18433018 - temperature 0.9832033\n",
      "864/864 [==============================] - 0s 504us/step - loss: 0.0555 - val_loss: 0.0535\n",
      "Epoch 82/200\n",
      "mean max of probabilities: 0.18450694 - temperature 0.9551056\n",
      "864/864 [==============================] - 1s 731us/step - loss: 0.0573 - val_loss: 0.0655\n",
      "Epoch 83/200\n",
      "mean max of probabilities: 0.1866651 - temperature 0.92781085\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0601 - val_loss: 0.0579\n",
      "Epoch 84/200\n",
      "mean max of probabilities: 0.18837538 - temperature 0.901296\n",
      "864/864 [==============================] - 1s 857us/step - loss: 0.0588 - val_loss: 0.0574\n",
      "Epoch 85/200\n",
      "mean max of probabilities: 0.19104478 - temperature 0.87553895\n",
      "864/864 [==============================] - 1s 723us/step - loss: 0.0597 - val_loss: 0.0588\n",
      "Epoch 86/200\n",
      "mean max of probabilities: 0.1930867 - temperature 0.8505179\n",
      "864/864 [==============================] - 1s 680us/step - loss: 0.0574 - val_loss: 0.0573\n",
      "Epoch 87/200\n",
      "mean max of probabilities: 0.19379678 - temperature 0.826212\n",
      "864/864 [==============================] - 1s 844us/step - loss: 0.0629 - val_loss: 0.0632\n",
      "Epoch 88/200\n",
      "mean max of probabilities: 0.19593845 - temperature 0.80260086\n",
      "864/864 [==============================] - 1s 977us/step - loss: 0.0609 - val_loss: 0.0566\n",
      "Epoch 89/200\n",
      "mean max of probabilities: 0.19759762 - temperature 0.7796643\n",
      "864/864 [==============================] - 1s 733us/step - loss: 0.0571 - val_loss: 0.0695\n",
      "Epoch 90/200\n",
      "mean max of probabilities: 0.19863273 - temperature 0.75738305\n",
      "864/864 [==============================] - 1s 684us/step - loss: 0.0618 - val_loss: 0.0573\n",
      "Epoch 91/200\n",
      "mean max of probabilities: 0.19961247 - temperature 0.73573875\n",
      "864/864 [==============================] - 1s 610us/step - loss: 0.0564 - val_loss: 0.0661\n",
      "Epoch 92/200\n",
      "mean max of probabilities: 0.20124738 - temperature 0.714713\n",
      "864/864 [==============================] - 1s 763us/step - loss: 0.0678 - val_loss: 0.0527\n",
      "Epoch 93/200\n",
      "mean max of probabilities: 0.2031753 - temperature 0.694288\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0647 - val_loss: 0.0600\n",
      "Epoch 94/200\n",
      "mean max of probabilities: 0.20501022 - temperature 0.6744468\n",
      "864/864 [==============================] - 1s 797us/step - loss: 0.0660 - val_loss: 0.0694\n",
      "Epoch 95/200\n",
      "mean max of probabilities: 0.20641737 - temperature 0.6551726\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0675 - val_loss: 0.0693\n",
      "Epoch 96/200\n",
      "mean max of probabilities: 0.20780969 - temperature 0.63644916\n",
      "864/864 [==============================] - 1s 834us/step - loss: 0.0656 - val_loss: 0.0786\n",
      "Epoch 97/200\n",
      "mean max of probabilities: 0.20905904 - temperature 0.6182609\n",
      "864/864 [==============================] - 1s 990us/step - loss: 0.0584 - val_loss: 0.0549\n",
      "Epoch 98/200\n",
      "mean max of probabilities: 0.21039157 - temperature 0.60059243\n",
      "864/864 [==============================] - 0s 462us/step - loss: 0.0728 - val_loss: 0.0733\n",
      "Epoch 99/200\n",
      "mean max of probabilities: 0.2116425 - temperature 0.58342886\n",
      "864/864 [==============================] - 1s 942us/step - loss: 0.0684 - val_loss: 0.1154\n",
      "Epoch 100/200\n",
      "mean max of probabilities: 0.21372354 - temperature 0.56675583\n",
      "864/864 [==============================] - 1s 647us/step - loss: 0.0644 - val_loss: 0.0646\n",
      "Epoch 101/200\n",
      "mean max of probabilities: 0.21457526 - temperature 0.5505593\n",
      "864/864 [==============================] - 1s 832us/step - loss: 0.0713 - val_loss: 0.0697\n",
      "Epoch 102/200\n",
      "mean max of probabilities: 0.2156394 - temperature 0.5348254\n",
      "864/864 [==============================] - 1s 667us/step - loss: 0.0695 - val_loss: 0.0809\n",
      "Epoch 103/200\n",
      "mean max of probabilities: 0.21713312 - temperature 0.51954126\n",
      "864/864 [==============================] - 1s 787us/step - loss: 0.0711 - val_loss: 0.0622\n",
      "Epoch 104/200\n",
      "mean max of probabilities: 0.21920268 - temperature 0.504694\n",
      "864/864 [==============================] - 1s 682us/step - loss: 0.0667 - val_loss: 0.0629\n",
      "Epoch 105/200\n",
      "mean max of probabilities: 0.2199312 - temperature 0.49027085\n",
      "864/864 [==============================] - 1s 652us/step - loss: 0.0680 - val_loss: 0.0844\n",
      "Epoch 106/200\n",
      "mean max of probabilities: 0.22113793 - temperature 0.47626004\n",
      "864/864 [==============================] - 1s 750us/step - loss: 0.0669 - val_loss: 0.0638\n",
      "Epoch 107/200\n",
      "mean max of probabilities: 0.22198972 - temperature 0.46264952\n",
      "864/864 [==============================] - 1s 943us/step - loss: 0.0716 - val_loss: 0.0629\n",
      "Epoch 108/200\n",
      "mean max of probabilities: 0.22353716 - temperature 0.44942802\n",
      "864/864 [==============================] - 1s 895us/step - loss: 0.0678 - val_loss: 0.0728\n",
      "Epoch 109/200\n",
      "mean max of probabilities: 0.22446814 - temperature 0.43658432\n",
      "864/864 [==============================] - 1s 875us/step - loss: 0.0740 - val_loss: 0.0747\n",
      "Epoch 110/200\n",
      "mean max of probabilities: 0.22518201 - temperature 0.42410767\n",
      "864/864 [==============================] - 1s 888us/step - loss: 0.0673 - val_loss: 0.0651\n",
      "Epoch 111/200\n",
      "mean max of probabilities: 0.22571369 - temperature 0.41198763\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0778 - val_loss: 0.0633\n",
      "Epoch 112/200\n",
      "mean max of probabilities: 0.22799495 - temperature 0.40021387\n",
      "864/864 [==============================] - 1s 674us/step - loss: 0.0616 - val_loss: 0.0642\n",
      "Epoch 113/200\n",
      "mean max of probabilities: 0.22856018 - temperature 0.3887767\n",
      "864/864 [==============================] - 0s 497us/step - loss: 0.0673 - val_loss: 0.0796\n",
      "Epoch 114/200\n",
      "mean max of probabilities: 0.22903995 - temperature 0.37766638\n",
      "864/864 [==============================] - 1s 786us/step - loss: 0.0626 - val_loss: 0.0644\n",
      "Epoch 115/200\n",
      "mean max of probabilities: 0.22984345 - temperature 0.36687356\n",
      "864/864 [==============================] - 0s 480us/step - loss: 0.0736 - val_loss: 0.0697\n",
      "Epoch 116/200\n",
      "mean max of probabilities: 0.23100236 - temperature 0.35638916\n",
      "864/864 [==============================] - 1s 668us/step - loss: 0.0721 - val_loss: 0.0544\n",
      "Epoch 117/200\n",
      "mean max of probabilities: 0.23191354 - temperature 0.34620434\n",
      "864/864 [==============================] - 1s 687us/step - loss: 0.0730 - val_loss: 0.0686\n",
      "Epoch 118/200\n",
      "mean max of probabilities: 0.233075 - temperature 0.33631054\n",
      "864/864 [==============================] - 1s 822us/step - loss: 0.0653 - val_loss: 0.0663\n",
      "Epoch 119/200\n",
      "mean max of probabilities: 0.23395853 - temperature 0.3266997\n",
      "864/864 [==============================] - 1s 859us/step - loss: 0.0671 - val_loss: 0.0839\n",
      "Epoch 120/200\n",
      "mean max of probabilities: 0.23420703 - temperature 0.31736347\n",
      "864/864 [==============================] - 1s 730us/step - loss: 0.0675 - val_loss: 0.0659\n",
      "Epoch 121/200\n",
      "mean max of probabilities: 0.23538224 - temperature 0.3082939\n",
      "864/864 [==============================] - 1s 974us/step - loss: 0.0792 - val_loss: 0.0623\n",
      "Epoch 122/200\n",
      "mean max of probabilities: 0.23589964 - temperature 0.29948357\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0643 - val_loss: 0.0784\n",
      "Epoch 123/200\n",
      "mean max of probabilities: 0.2362804 - temperature 0.29092497\n",
      "864/864 [==============================] - 1s 986us/step - loss: 0.0667 - val_loss: 0.0631\n",
      "Epoch 124/200\n",
      "mean max of probabilities: 0.23613541 - temperature 0.28261095\n",
      "864/864 [==============================] - 1s 898us/step - loss: 0.0684 - val_loss: 0.0793\n",
      "Epoch 125/200\n",
      "mean max of probabilities: 0.23684625 - temperature 0.27453458\n",
      "864/864 [==============================] - 1s 854us/step - loss: 0.0721 - val_loss: 0.0717\n",
      "Epoch 126/200\n",
      "mean max of probabilities: 0.23806448 - temperature 0.26668897\n",
      "864/864 [==============================] - 0s 532us/step - loss: 0.0688 - val_loss: 0.0612\n",
      "Epoch 127/200\n",
      "mean max of probabilities: 0.23890254 - temperature 0.25906765\n",
      "864/864 [==============================] - 1s 678us/step - loss: 0.0762 - val_loss: 0.0717\n",
      "Epoch 128/200\n",
      "mean max of probabilities: 0.23929639 - temperature 0.25166407\n",
      "864/864 [==============================] - 1s 698us/step - loss: 0.0754 - val_loss: 0.0592\n",
      "Epoch 129/200\n",
      "mean max of probabilities: 0.23986144 - temperature 0.244472\n",
      "864/864 [==============================] - 0s 498us/step - loss: 0.0702 - val_loss: 0.0635\n",
      "Epoch 130/200\n",
      "mean max of probabilities: 0.2412472 - temperature 0.23748554\n",
      "864/864 [==============================] - 1s 770us/step - loss: 0.0716 - val_loss: 0.0747\n",
      "Epoch 131/200\n",
      "mean max of probabilities: 0.2426225 - temperature 0.23069873\n",
      "864/864 [==============================] - 1s 719us/step - loss: 0.0705 - val_loss: 0.0912\n",
      "Epoch 132/200\n",
      "mean max of probabilities: 0.24357812 - temperature 0.22410586\n",
      "864/864 [==============================] - 0s 493us/step - loss: 0.0705 - val_loss: 0.0832\n",
      "Epoch 133/200\n",
      "mean max of probabilities: 0.24371156 - temperature 0.21770142\n",
      "864/864 [==============================] - 1s 701us/step - loss: 0.0673 - val_loss: 0.0725\n",
      "Epoch 134/200\n",
      "mean max of probabilities: 0.24426381 - temperature 0.21148\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0713 - val_loss: 0.0649\n",
      "Epoch 135/200\n",
      "mean max of probabilities: 0.24466848 - temperature 0.20543638\n",
      "864/864 [==============================] - 1s 618us/step - loss: 0.0618 - val_loss: 0.0859\n",
      "Epoch 136/200\n",
      "mean max of probabilities: 0.24463339 - temperature 0.19956544\n",
      "864/864 [==============================] - 0s 542us/step - loss: 0.0676 - val_loss: 0.0575\n",
      "Epoch 137/200\n",
      "mean max of probabilities: 0.24553898 - temperature 0.19386232\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0675 - val_loss: 0.0689\n",
      "Epoch 138/200\n",
      "mean max of probabilities: 0.24670522 - temperature 0.18832213\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0737 - val_loss: 0.0740\n",
      "Epoch 139/200\n",
      "mean max of probabilities: 0.24698167 - temperature 0.18294032\n",
      "864/864 [==============================] - 1s 876us/step - loss: 0.0747 - val_loss: 0.0650\n",
      "Epoch 140/200\n",
      "mean max of probabilities: 0.24779363 - temperature 0.17771229\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0672 - val_loss: 0.0684\n",
      "Epoch 141/200\n",
      "mean max of probabilities: 0.24809444 - temperature 0.17263365\n",
      "864/864 [==============================] - 0s 554us/step - loss: 0.0679 - val_loss: 0.0778\n",
      "Epoch 142/200\n",
      "mean max of probabilities: 0.24975368 - temperature 0.16770016\n",
      "864/864 [==============================] - 1s 829us/step - loss: 0.0720 - val_loss: 0.0682\n",
      "Epoch 143/200\n",
      "mean max of probabilities: 0.24960776 - temperature 0.1629078\n",
      "864/864 [==============================] - 1s 959us/step - loss: 0.0645 - val_loss: 0.0686\n",
      "Epoch 144/200\n",
      "mean max of probabilities: 0.24944611 - temperature 0.1582522\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0697 - val_loss: 0.0776\n",
      "Epoch 145/200\n",
      "mean max of probabilities: 0.2503609 - temperature 0.1537297\n",
      "864/864 [==============================] - 1s 905us/step - loss: 0.0698 - val_loss: 0.0667\n",
      "Epoch 146/200\n",
      "mean max of probabilities: 0.25138697 - temperature 0.14933646\n",
      "864/864 [==============================] - 1s 730us/step - loss: 0.0700 - val_loss: 0.0637\n",
      "Epoch 147/200\n",
      "mean max of probabilities: 0.25203827 - temperature 0.14506873\n",
      "864/864 [==============================] - 1s 778us/step - loss: 0.0793 - val_loss: 0.0671\n",
      "Epoch 148/200\n",
      "mean max of probabilities: 0.25298777 - temperature 0.14092301\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0639 - val_loss: 0.0712\n",
      "Epoch 149/200\n",
      "mean max of probabilities: 0.2535015 - temperature 0.13689573\n",
      "864/864 [==============================] - 1s 583us/step - loss: 0.0700 - val_loss: 0.0752\n",
      "Epoch 150/200\n",
      "mean max of probabilities: 0.2538136 - temperature 0.13298355\n",
      "864/864 [==============================] - 1s 697us/step - loss: 0.0641 - val_loss: 0.0602\n",
      "Epoch 151/200\n",
      "mean max of probabilities: 0.25437146 - temperature 0.12918319\n",
      "864/864 [==============================] - 1s 903us/step - loss: 0.0671 - val_loss: 0.0574\n",
      "Epoch 152/200\n",
      "mean max of probabilities: 0.25407678 - temperature 0.12549141\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0622 - val_loss: 0.0689\n",
      "Epoch 153/200\n",
      "mean max of probabilities: 0.25443786 - temperature 0.12190509\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0666 - val_loss: 0.0670\n",
      "Epoch 154/200\n",
      "mean max of probabilities: 0.254665 - temperature 0.11842132\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0655 - val_loss: 0.0721\n",
      "Epoch 155/200\n",
      "mean max of probabilities: 0.25559282 - temperature 0.1150371\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 0.0663 - val_loss: 0.0720\n",
      "Epoch 156/200\n",
      "mean max of probabilities: 0.2562661 - temperature 0.11174959\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0655 - val_loss: 0.0652\n",
      "Epoch 157/200\n",
      "mean max of probabilities: 0.25654978 - temperature 0.10855604\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0706 - val_loss: 0.0565\n",
      "Epoch 158/200\n",
      "mean max of probabilities: 0.25784984 - temperature 0.10545374\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0608 - val_loss: 0.0593\n",
      "Epoch 159/200\n",
      "mean max of probabilities: 0.2583712 - temperature 0.10244011\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 0.0700 - val_loss: 0.0647\n",
      "Epoch 160/200\n",
      "mean max of probabilities: 0.2589112 - temperature 0.1\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 0.0696 - val_loss: 0.0652\n",
      "Epoch 161/200\n",
      "mean max of probabilities: 0.26037344 - temperature 0.1\n",
      "864/864 [==============================] - 1s 762us/step - loss: 0.0659 - val_loss: 0.0779\n",
      "Epoch 162/200\n",
      "mean max of probabilities: 0.26049823 - temperature 0.1\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0727 - val_loss: 0.0634\n",
      "Epoch 163/200\n",
      "mean max of probabilities: 0.26118746 - temperature 0.1\n",
      "864/864 [==============================] - 0s 513us/step - loss: 0.0692 - val_loss: 0.0655\n",
      "Epoch 164/200\n",
      "mean max of probabilities: 0.26120293 - temperature 0.1\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0669 - val_loss: 0.0901\n",
      "Epoch 165/200\n",
      "mean max of probabilities: 0.2616833 - temperature 0.1\n",
      "864/864 [==============================] - 1s 679us/step - loss: 0.0673 - val_loss: 0.0872\n",
      "Epoch 166/200\n",
      "mean max of probabilities: 0.26208687 - temperature 0.1\n",
      "864/864 [==============================] - 1s 934us/step - loss: 0.0647 - val_loss: 0.0660\n",
      "Epoch 167/200\n",
      "mean max of probabilities: 0.26221448 - temperature 0.1\n",
      "864/864 [==============================] - 1s 745us/step - loss: 0.0656 - val_loss: 0.0721\n",
      "Epoch 168/200\n",
      "mean max of probabilities: 0.26251033 - temperature 0.1\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0660 - val_loss: 0.0693\n",
      "Epoch 169/200\n",
      "mean max of probabilities: 0.2636567 - temperature 0.1\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0670 - val_loss: 0.0736\n",
      "Epoch 170/200\n",
      "mean max of probabilities: 0.264059 - temperature 0.1\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0626 - val_loss: 0.0614\n",
      "Epoch 171/200\n",
      "mean max of probabilities: 0.26440644 - temperature 0.1\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0684 - val_loss: 0.0645\n",
      "Epoch 172/200\n",
      "mean max of probabilities: 0.26530537 - temperature 0.1\n",
      "864/864 [==============================] - 1s 888us/step - loss: 0.0633 - val_loss: 0.0671\n",
      "Epoch 173/200\n",
      "mean max of probabilities: 0.2657662 - temperature 0.1\n",
      "864/864 [==============================] - 1s 616us/step - loss: 0.0652 - val_loss: 0.0658\n",
      "Epoch 174/200\n",
      "mean max of probabilities: 0.26576704 - temperature 0.1\n",
      "864/864 [==============================] - 1s 887us/step - loss: 0.0601 - val_loss: 0.0611\n",
      "Epoch 175/200\n",
      "mean max of probabilities: 0.26570147 - temperature 0.1\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0605 - val_loss: 0.0556\n",
      "Epoch 176/200\n",
      "mean max of probabilities: 0.265789 - temperature 0.1\n",
      "864/864 [==============================] - 1s 974us/step - loss: 0.0642 - val_loss: 0.0630\n",
      "Epoch 177/200\n",
      "mean max of probabilities: 0.26641816 - temperature 0.1\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0618 - val_loss: 0.0656\n",
      "Epoch 178/200\n",
      "mean max of probabilities: 0.2666615 - temperature 0.1\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 0.0620 - val_loss: 0.0679\n",
      "Epoch 179/200\n",
      "mean max of probabilities: 0.26682526 - temperature 0.1\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0610 - val_loss: 0.0636\n",
      "Epoch 180/200\n",
      "mean max of probabilities: 0.2674901 - temperature 0.1\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 0.0661 - val_loss: 0.0775\n",
      "Epoch 181/200\n",
      "mean max of probabilities: 0.26794243 - temperature 0.1\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0636 - val_loss: 0.0612\n",
      "Epoch 182/200\n",
      "mean max of probabilities: 0.26864082 - temperature 0.1\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0642 - val_loss: 0.0650\n",
      "Epoch 183/200\n",
      "mean max of probabilities: 0.26970872 - temperature 0.1\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0568 - val_loss: 0.0722\n",
      "Epoch 184/200\n",
      "mean max of probabilities: 0.2703783 - temperature 0.1\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0711 - val_loss: 0.0541\n",
      "Epoch 185/200\n",
      "mean max of probabilities: 0.27070847 - temperature 0.1\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0630 - val_loss: 0.0666\n",
      "Epoch 186/200\n",
      "mean max of probabilities: 0.2711894 - temperature 0.1\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0637 - val_loss: 0.0570\n",
      "Epoch 187/200\n",
      "mean max of probabilities: 0.27207893 - temperature 0.1\n",
      "864/864 [==============================] - 1s 987us/step - loss: 0.0627 - val_loss: 0.0570\n",
      "Epoch 188/200\n",
      "mean max of probabilities: 0.27243835 - temperature 0.1\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0756 - val_loss: 0.0652\n",
      "Epoch 189/200\n",
      "mean max of probabilities: 0.27290088 - temperature 0.1\n",
      "864/864 [==============================] - 1s 958us/step - loss: 0.0676 - val_loss: 0.0620\n",
      "Epoch 190/200\n",
      "mean max of probabilities: 0.2729608 - temperature 0.1\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0662 - val_loss: 0.0593\n",
      "Epoch 191/200\n",
      "mean max of probabilities: 0.2732713 - temperature 0.1\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0603 - val_loss: 0.0662\n",
      "Epoch 192/200\n",
      "mean max of probabilities: 0.27405852 - temperature 0.1\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 0.0654 - val_loss: 0.0612\n",
      "Epoch 193/200\n",
      "mean max of probabilities: 0.2742706 - temperature 0.1\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0629 - val_loss: 0.0639\n",
      "Epoch 194/200\n",
      "mean max of probabilities: 0.27492738 - temperature 0.1\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 0.0609 - val_loss: 0.0603\n",
      "Epoch 195/200\n",
      "mean max of probabilities: 0.2749149 - temperature 0.1\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0596 - val_loss: 0.0667\n",
      "Epoch 196/200\n",
      "mean max of probabilities: 0.27561033 - temperature 0.1\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0629 - val_loss: 0.0584\n",
      "Epoch 197/200\n",
      "mean max of probabilities: 0.27657056 - temperature 0.1\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 0.0637 - val_loss: 0.0685\n",
      "Epoch 198/200\n",
      "mean max of probabilities: 0.27671972 - temperature 0.1\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 0.0633 - val_loss: 0.0665\n",
      "Epoch 199/200\n",
      "mean max of probabilities: 0.27705827 - temperature 0.1\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 0.0642 - val_loss: 0.0641\n",
      "Epoch 200/200\n",
      "mean max of probabilities: 0.27774733 - temperature 0.1\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 0.0583 - val_loss: 0.0670\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 1.0\n",
      "Testing accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Training accuracy： 1.0\n",
      "Testing accuracy： 0.6064814814814815\n",
      "Testing accuracy： 0.6064814814814815\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 77)                0         \n",
      "_________________________________________________________________\n",
      "concrete_select (ConcreteSel (None, 10)                771       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 77)                847       \n",
      "=================================================================\n",
      "Total params: 1,618\n",
      "Trainable params: 1,617\n",
      "Non-trainable params: 1\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 864 samples, validate on 216 samples\n",
      "Epoch 1/200\n",
      "mean max of probabilities: 0.017775513 - temperature 10.0\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 0.9481 - val_loss: 0.7232\n",
      "Epoch 2/200\n",
      "mean max of probabilities: 0.01799089 - temperature 9.714222\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.6037 - val_loss: 0.4777\n",
      "Epoch 3/200\n",
      "mean max of probabilities: 0.018873611 - temperature 9.436611\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.4082 - val_loss: 0.3308\n",
      "Epoch 4/200\n",
      "mean max of probabilities: 0.020045664 - temperature 9.166935\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 0.2873 - val_loss: 0.2375\n",
      "Epoch 5/200\n",
      "mean max of probabilities: 0.021605767 - temperature 8.904965\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 0.2092 - val_loss: 0.1764\n",
      "Epoch 6/200\n",
      "mean max of probabilities: 0.02311784 - temperature 8.650478\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.1579 - val_loss: 0.1353\n",
      "Epoch 7/200\n",
      "mean max of probabilities: 0.02452896 - temperature 8.403267\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 0.1228 - val_loss: 0.1080\n",
      "Epoch 8/200\n",
      "mean max of probabilities: 0.025834775 - temperature 8.163121\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0988 - val_loss: 0.0890\n",
      "Epoch 9/200\n",
      "mean max of probabilities: 0.02704835 - temperature 7.9298377\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 0.0820 - val_loss: 0.0758\n",
      "Epoch 10/200\n",
      "mean max of probabilities: 0.028137898 - temperature 7.7032237\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0709 - val_loss: 0.0668\n",
      "Epoch 11/200\n",
      "mean max of probabilities: 0.029103506 - temperature 7.483083\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0632 - val_loss: 0.0607\n",
      "Epoch 12/200\n",
      "mean max of probabilities: 0.029935211 - temperature 7.269233\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0579 - val_loss: 0.0571\n",
      "Epoch 13/200\n",
      "mean max of probabilities: 0.030609291 - temperature 7.061494\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0546 - val_loss: 0.0543\n",
      "Epoch 14/200\n",
      "mean max of probabilities: 0.031138647 - temperature 6.8596926\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 0.0524 - val_loss: 0.0529\n",
      "Epoch 15/200\n",
      "mean max of probabilities: 0.03162325 - temperature 6.663658\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0511 - val_loss: 0.0518\n",
      "Epoch 16/200\n",
      "mean max of probabilities: 0.03206729 - temperature 6.473224\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0502 - val_loss: 0.0511\n",
      "Epoch 17/200\n",
      "mean max of probabilities: 0.032360934 - temperature 6.2882338\n",
      "864/864 [==============================] - 1s 997us/step - loss: 0.0498 - val_loss: 0.0508\n",
      "Epoch 18/200\n",
      "mean max of probabilities: 0.032648146 - temperature 6.108531\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0495 - val_loss: 0.0506\n",
      "Epoch 19/200\n",
      "mean max of probabilities: 0.03288818 - temperature 5.933963\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0493 - val_loss: 0.0506\n",
      "Epoch 20/200\n",
      "mean max of probabilities: 0.033160377 - temperature 5.764384\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0493 - val_loss: 0.0503\n",
      "Epoch 21/200\n",
      "mean max of probabilities: 0.033477772 - temperature 5.5996504\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0491 - val_loss: 0.0505\n",
      "Epoch 22/200\n",
      "mean max of probabilities: 0.033903085 - temperature 5.4396253\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0492 - val_loss: 0.0504\n",
      "Epoch 23/200\n",
      "mean max of probabilities: 0.034525383 - temperature 5.2841735\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 0.0491 - val_loss: 0.0504\n",
      "Epoch 24/200\n",
      "mean max of probabilities: 0.035341877 - temperature 5.133164\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 0.0492 - val_loss: 0.0504\n",
      "Epoch 25/200\n",
      "mean max of probabilities: 0.036239646 - temperature 4.9864693\n",
      "864/864 [==============================] - 1s 956us/step - loss: 0.0491 - val_loss: 0.0504\n",
      "Epoch 26/200\n",
      "mean max of probabilities: 0.037211407 - temperature 4.8439674\n",
      "864/864 [==============================] - 0s 398us/step - loss: 0.0491 - val_loss: 0.0503\n",
      "Epoch 27/200\n",
      "mean max of probabilities: 0.038205635 - temperature 4.705537\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0489 - val_loss: 0.0502\n",
      "Epoch 28/200\n",
      "mean max of probabilities: 0.03940215 - temperature 4.571063\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 0.0490 - val_loss: 0.0501\n",
      "Epoch 29/200\n",
      "mean max of probabilities: 0.040831365 - temperature 4.440432\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0490 - val_loss: 0.0502\n",
      "Epoch 30/200\n",
      "mean max of probabilities: 0.042539556 - temperature 4.3135343\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0490 - val_loss: 0.0501\n",
      "Epoch 31/200\n",
      "mean max of probabilities: 0.04437723 - temperature 4.1902633\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0490 - val_loss: 0.0505\n",
      "Epoch 32/200\n",
      "mean max of probabilities: 0.046278518 - temperature 4.070515\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0489 - val_loss: 0.0503\n",
      "Epoch 33/200\n",
      "mean max of probabilities: 0.048382156 - temperature 3.9541893\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0488 - val_loss: 0.0501\n",
      "Epoch 34/200\n",
      "mean max of probabilities: 0.05049994 - temperature 3.841188\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0487 - val_loss: 0.0502\n",
      "Epoch 35/200\n",
      "mean max of probabilities: 0.052867018 - temperature 3.7314155\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0488 - val_loss: 0.0501\n",
      "Epoch 36/200\n",
      "mean max of probabilities: 0.055410672 - temperature 3.62478\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0489 - val_loss: 0.0499\n",
      "Epoch 37/200\n",
      "mean max of probabilities: 0.05811118 - temperature 3.5211914\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0488 - val_loss: 0.0498\n",
      "Epoch 38/200\n",
      "mean max of probabilities: 0.061003603 - temperature 3.420564\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0490 - val_loss: 0.0506\n",
      "Epoch 39/200\n",
      "mean max of probabilities: 0.063968636 - temperature 3.3228116\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0491 - val_loss: 0.0498\n",
      "Epoch 40/200\n",
      "mean max of probabilities: 0.06697099 - temperature 3.227853\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0493 - val_loss: 0.0503\n",
      "Epoch 41/200\n",
      "mean max of probabilities: 0.07001085 - temperature 3.1356087\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0488 - val_loss: 0.0496\n",
      "Epoch 42/200\n",
      "mean max of probabilities: 0.07286284 - temperature 3.0459995\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 0.0491 - val_loss: 0.0501\n",
      "Epoch 43/200\n",
      "mean max of probabilities: 0.076070294 - temperature 2.9589517\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 0.0489 - val_loss: 0.0501\n",
      "Epoch 44/200\n",
      "mean max of probabilities: 0.07936015 - temperature 2.8743913\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0491 - val_loss: 0.0497\n",
      "Epoch 45/200\n",
      "mean max of probabilities: 0.08280505 - temperature 2.7922478\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0489 - val_loss: 0.0501\n",
      "Epoch 46/200\n",
      "mean max of probabilities: 0.08656789 - temperature 2.712452\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0491 - val_loss: 0.0498\n",
      "Epoch 47/200\n",
      "mean max of probabilities: 0.090178624 - temperature 2.6349366\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0493 - val_loss: 0.0514\n",
      "Epoch 48/200\n",
      "mean max of probabilities: 0.094401374 - temperature 2.5596378\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0500 - val_loss: 0.0500\n",
      "Epoch 49/200\n",
      "mean max of probabilities: 0.098526336 - temperature 2.4864888\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0491 - val_loss: 0.0508\n",
      "Epoch 50/200\n",
      "mean max of probabilities: 0.102005996 - temperature 2.4154308\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0491 - val_loss: 0.0534\n",
      "Epoch 51/200\n",
      "mean max of probabilities: 0.10590923 - temperature 2.3464034\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0494 - val_loss: 0.0499\n",
      "Epoch 52/200\n",
      "mean max of probabilities: 0.11074237 - temperature 2.2793484\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0498 - val_loss: 0.0515\n",
      "Epoch 53/200\n",
      "mean max of probabilities: 0.11465001 - temperature 2.2142096\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 0.0507 - val_loss: 0.0505\n",
      "Epoch 54/200\n",
      "mean max of probabilities: 0.11870207 - temperature 2.1509328\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0500 - val_loss: 0.0516\n",
      "Epoch 55/200\n",
      "mean max of probabilities: 0.12208408 - temperature 2.0894635\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 0.0499 - val_loss: 0.0527\n",
      "Epoch 56/200\n",
      "mean max of probabilities: 0.1255645 - temperature 2.0297515\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0509 - val_loss: 0.0513\n",
      "Epoch 57/200\n",
      "mean max of probabilities: 0.12942094 - temperature 1.9717458\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 0.0507 - val_loss: 0.0516\n",
      "Epoch 58/200\n",
      "mean max of probabilities: 0.13282713 - temperature 1.915398\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0509 - val_loss: 0.0514\n",
      "Epoch 59/200\n",
      "mean max of probabilities: 0.1357603 - temperature 1.86066\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 0.0525 - val_loss: 0.0550\n",
      "Epoch 60/200\n",
      "mean max of probabilities: 0.13954845 - temperature 1.8074865\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0504 - val_loss: 0.0536\n",
      "Epoch 61/200\n",
      "mean max of probabilities: 0.14259896 - temperature 1.7558324\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0513 - val_loss: 0.0584\n",
      "Epoch 62/200\n",
      "mean max of probabilities: 0.14508623 - temperature 1.7056547\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0532 - val_loss: 0.0517\n",
      "Epoch 63/200\n",
      "mean max of probabilities: 0.14804396 - temperature 1.6569109\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0521 - val_loss: 0.0615\n",
      "Epoch 64/200\n",
      "mean max of probabilities: 0.15060733 - temperature 1.6095604\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 0.0603 - val_loss: 0.0513\n",
      "Epoch 65/200\n",
      "mean max of probabilities: 0.15398999 - temperature 1.5635628\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0541 - val_loss: 0.0547\n",
      "Epoch 66/200\n",
      "mean max of probabilities: 0.1566985 - temperature 1.5188798\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0600 - val_loss: 0.0578\n",
      "Epoch 67/200\n",
      "mean max of probabilities: 0.15937956 - temperature 1.4754735\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0560 - val_loss: 0.0563\n",
      "Epoch 68/200\n",
      "mean max of probabilities: 0.16150708 - temperature 1.4333079\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0561 - val_loss: 0.0638\n",
      "Epoch 69/200\n",
      "mean max of probabilities: 0.16288999 - temperature 1.3923471\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0588 - val_loss: 0.0614\n",
      "Epoch 70/200\n",
      "mean max of probabilities: 0.16528268 - temperature 1.352557\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0539 - val_loss: 0.0530\n",
      "Epoch 71/200\n",
      "mean max of probabilities: 0.16742526 - temperature 1.313903\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 0.0563 - val_loss: 0.0557\n",
      "Epoch 72/200\n",
      "mean max of probabilities: 0.16892803 - temperature 1.2763531\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 0.0543 - val_loss: 0.0632\n",
      "Epoch 73/200\n",
      "mean max of probabilities: 0.17106263 - temperature 1.2398779\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0560 - val_loss: 0.0575\n",
      "Epoch 74/200\n",
      "mean max of probabilities: 0.17334773 - temperature 1.204445\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 0.0549 - val_loss: 0.0571\n",
      "Epoch 75/200\n",
      "mean max of probabilities: 0.1751986 - temperature 1.1700248\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0553 - val_loss: 0.0591\n",
      "Epoch 76/200\n",
      "mean max of probabilities: 0.17650513 - temperature 1.136588\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0592 - val_loss: 0.0523\n",
      "Epoch 77/200\n",
      "mean max of probabilities: 0.17750832 - temperature 1.1041069\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 0.0574 - val_loss: 0.0564\n",
      "Epoch 78/200\n",
      "mean max of probabilities: 0.17905295 - temperature 1.0725542\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 0.0593 - val_loss: 0.0711\n",
      "Epoch 79/200\n",
      "mean max of probabilities: 0.18088692 - temperature 1.0419029\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0522 - val_loss: 0.0548\n",
      "Epoch 80/200\n",
      "mean max of probabilities: 0.18203679 - temperature 1.0121278\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0575 - val_loss: 0.0600\n",
      "Epoch 81/200\n",
      "mean max of probabilities: 0.18423292 - temperature 0.9832033\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0623 - val_loss: 0.0586\n",
      "Epoch 82/200\n",
      "mean max of probabilities: 0.1858562 - temperature 0.9551056\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0609 - val_loss: 0.0605\n",
      "Epoch 83/200\n",
      "mean max of probabilities: 0.18744294 - temperature 0.92781085\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0604 - val_loss: 0.0769\n",
      "Epoch 84/200\n",
      "mean max of probabilities: 0.18855627 - temperature 0.901296\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 0.0610 - val_loss: 0.0696\n",
      "Epoch 85/200\n",
      "mean max of probabilities: 0.18974736 - temperature 0.87553895\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0628 - val_loss: 0.0669\n",
      "Epoch 86/200\n",
      "mean max of probabilities: 0.19115655 - temperature 0.8505179\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0662 - val_loss: 0.0625\n",
      "Epoch 87/200\n",
      "mean max of probabilities: 0.19282553 - temperature 0.826212\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 0.0644 - val_loss: 0.0700\n",
      "Epoch 88/200\n",
      "mean max of probabilities: 0.19335307 - temperature 0.80260086\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0674 - val_loss: 0.0660\n",
      "Epoch 89/200\n",
      "mean max of probabilities: 0.19497733 - temperature 0.7796643\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0667 - val_loss: 0.0636\n",
      "Epoch 90/200\n",
      "mean max of probabilities: 0.19596195 - temperature 0.75738305\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0650 - val_loss: 0.0659\n",
      "Epoch 91/200\n",
      "mean max of probabilities: 0.19699785 - temperature 0.73573875\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0591 - val_loss: 0.0669\n",
      "Epoch 92/200\n",
      "mean max of probabilities: 0.19848144 - temperature 0.714713\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 0.0685 - val_loss: 0.0793\n",
      "Epoch 93/200\n",
      "mean max of probabilities: 0.19885755 - temperature 0.694288\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 0.0686 - val_loss: 0.0636\n",
      "Epoch 94/200\n",
      "mean max of probabilities: 0.19946472 - temperature 0.6744468\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0659 - val_loss: 0.0567\n",
      "Epoch 95/200\n",
      "mean max of probabilities: 0.20011643 - temperature 0.6551726\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0660 - val_loss: 0.0626\n",
      "Epoch 96/200\n",
      "mean max of probabilities: 0.2002459 - temperature 0.63644916\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0673 - val_loss: 0.0644\n",
      "Epoch 97/200\n",
      "mean max of probabilities: 0.20148996 - temperature 0.6182609\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0630 - val_loss: 0.0691\n",
      "Epoch 98/200\n",
      "mean max of probabilities: 0.20231883 - temperature 0.60059243\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0671 - val_loss: 0.0749\n",
      "Epoch 99/200\n",
      "mean max of probabilities: 0.20388082 - temperature 0.58342886\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0613 - val_loss: 0.0625\n",
      "Epoch 100/200\n",
      "mean max of probabilities: 0.20476484 - temperature 0.56675583\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0712 - val_loss: 0.0595\n",
      "Epoch 101/200\n",
      "mean max of probabilities: 0.20603421 - temperature 0.5505593\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0655 - val_loss: 0.0605\n",
      "Epoch 102/200\n",
      "mean max of probabilities: 0.20645848 - temperature 0.5348254\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0692 - val_loss: 0.0799\n",
      "Epoch 103/200\n",
      "mean max of probabilities: 0.20735829 - temperature 0.51954126\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0629 - val_loss: 0.0622\n",
      "Epoch 104/200\n",
      "mean max of probabilities: 0.20745012 - temperature 0.504694\n",
      "864/864 [==============================] - 2s 3ms/step - loss: 0.0699 - val_loss: 0.0723\n",
      "Epoch 105/200\n",
      "mean max of probabilities: 0.20896634 - temperature 0.49027085\n",
      "864/864 [==============================] - 3s 3ms/step - loss: 0.0662 - val_loss: 0.0754\n",
      "Epoch 106/200\n",
      "mean max of probabilities: 0.21023412 - temperature 0.47626004\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0738 - val_loss: 0.0666\n"
     ]
    }
   ],
   "source": [
    "for p_seed in np.arange(0,50):\n",
    "    orig_train_acc,orig_test_acc,selec_train_acc,selec_test_acc,reconstruction_loss=cal(p_data_arr,\\\n",
    "                                                                                        p_label_arr_onehot,\\\n",
    "                                                                                        p_key_feture_number,\\\n",
    "                                                                                        p_epochs_number,\\\n",
    "                                                                                        p_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

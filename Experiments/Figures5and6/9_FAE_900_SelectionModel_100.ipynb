{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/ubuntu_env_1/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ubuntu/ubuntu_env_1/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ubuntu/ubuntu_env_1/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ubuntu/ubuntu_env_1/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ubuntu/ubuntu_env_1/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ubuntu/ubuntu_env_1/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/ubuntu/ubuntu_env_1/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ubuntu/ubuntu_env_1/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ubuntu/ubuntu_env_1/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ubuntu/ubuntu_env_1/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ubuntu/ubuntu_env_1/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ubuntu/ubuntu_env_1/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#----------------------------Reproducible----------------------------------------------------------------------------------------\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "import os\n",
    "\n",
    "seed=0\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "np.random.seed(seed)\n",
    "rn.seed(seed)\n",
    "#session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "session_conf =tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "#tf.set_random_seed(seed)\n",
    "tf.compat.v1.set_random_seed(seed)\n",
    "#sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "\n",
    "K.set_session(sess)\n",
    "#----------------------------Reproducible----------------------------------------------------------------------------------------\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Flatten, Activation, Dropout, Layer\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import to_categorical\n",
    "from keras import optimizers,initializers,constraints,regularizers\n",
    "from keras import backend as K\n",
    "from keras.callbacks import LambdaCallback,ModelCheckpoint\n",
    "from keras.utils import plot_model\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import h5py\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer \n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib as mpl\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "#Import ourslef defined methods\n",
    "import sys\n",
    "sys.path.append(r\"./Defined\")\n",
    "import Functions as F\n",
    "\n",
    "# The following code should be added before the keras model\n",
    "#np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of xy_test: (11101, 10463)\n"
     ]
    }
   ],
   "source": [
    "xy_test = np.load('bgedv2_XY_te_float32.npy')\n",
    "print('Shape of xy_test: ' + str(xy_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_feture_number=900"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "class Feature_Select_Layer(Layer):\n",
    "    \n",
    "    def __init__(self, output_dim, l1_lambda, **kwargs):\n",
    "        super(Feature_Select_Layer, self).__init__(**kwargs)\n",
    "        self.output_dim = output_dim\n",
    "        self.l1_lambda=l1_lambda\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(name='kernel',  \n",
    "                                      shape=(input_shape[1],),\n",
    "                                      initializer=initializers.RandomUniform(minval=0.999999, maxval=0.9999999, seed=seed),\n",
    "                                      trainable=True,\n",
    "                                      regularizer=regularizers.l1(self.l1_lambda),\n",
    "                                      constraint=constraints.NonNeg())\n",
    "        super(Feature_Select_Layer, self).build(input_shape)\n",
    "    \n",
    "    def call(self, x, selection=False,k=key_feture_number):\n",
    "        kernel=self.kernel        \n",
    "        if selection:\n",
    "            kernel_=K.transpose(kernel)\n",
    "            kth_largest = tf.math.top_k(kernel_, k=k)[0][-1]\n",
    "            kernel = tf.where(condition=K.less(kernel,kth_largest),x=K.zeros_like(kernel),y=kernel)        \n",
    "        return K.dot(x, tf.linalg.tensor_diag(kernel))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_dim)\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "def Autoencoder(p_data_feature=xy_test.shape[1],\\\n",
    "                p_encoding_dim=key_feture_number,\\\n",
    "                p_learning_rate= 1E-3):\n",
    "    input_img = Input(shape=(p_data_feature,), name='input_img')\n",
    "\n",
    "    encoded = Dense(p_encoding_dim, activation='linear',kernel_initializer=initializers.glorot_uniform(seed))(input_img)\n",
    "    bottleneck=encoded\n",
    "    decoded = Dense(p_data_feature, activation='linear',kernel_initializer=initializers.glorot_uniform(seed))(encoded)\n",
    "\n",
    "    latent_encoder = Model(input_img, bottleneck)\n",
    "    autoencoder = Model(input_img, decoded)\n",
    "    \n",
    "    autoencoder.compile(loss='mean_squared_error', optimizer=optimizers.Adam(lr=p_learning_rate))\n",
    "    \n",
    "    print('Autoencoder Structure-------------------------------------')\n",
    "    autoencoder.summary()\n",
    "    #print('Latent Encoder Structure-------------------------------------')\n",
    "    #latent_encoder.summary()\n",
    "    return autoencoder,latent_encoder\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "def Identity_Autoencoder(p_data_feature=xy_test.shape[1],\\\n",
    "                         p_encoding_dim=key_feture_number,\\\n",
    "                         p_learning_rate= 1E-3,\\\n",
    "                         p_l1_lambda=0.1):\n",
    "    \n",
    "    input_img = Input(shape=(p_data_feature,), name='autoencoder_input')\n",
    "\n",
    "    feature_selection = Feature_Select_Layer(output_dim=p_data_feature,\\\n",
    "                                             l1_lambda=p_l1_lambda,\\\n",
    "                                             input_shape=(p_data_feature,),\\\n",
    "                                             name='feature_selection')\n",
    "\n",
    "    feature_selection_score=feature_selection(input_img)\n",
    "\n",
    "    encoded = Dense(p_encoding_dim,\\\n",
    "                    activation='linear',\\\n",
    "                    kernel_initializer=initializers.glorot_uniform(seed),\\\n",
    "                    name='autoencoder_hidden_layer')\n",
    "    \n",
    "    encoded_score=encoded(feature_selection_score)\n",
    "    \n",
    "    bottleneck_score=encoded_score\n",
    "    \n",
    "    decoded = Dense(p_data_feature,\\\n",
    "                    activation='linear',\\\n",
    "                    kernel_initializer=initializers.glorot_uniform(seed),\\\n",
    "                    name='autoencoder_output')\n",
    "    \n",
    "    decoded_score =decoded(bottleneck_score)\n",
    "\n",
    "    latent_encoder_score = Model(input_img, bottleneck_score)\n",
    "    autoencoder = Model(input_img, decoded_score)\n",
    "    \n",
    "    autoencoder.compile(loss='mean_squared_error',\\\n",
    "                        optimizer=optimizers.Adam(lr=p_learning_rate))\n",
    "    \n",
    "    print('Autoencoder Structure-------------------------------------')\n",
    "    autoencoder.summary()\n",
    "    return autoencoder,latent_encoder_score\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "def Fractal_Autoencoder(p_data_feature=xy_test.shape[1],\\\n",
    "                        p_feture_number=key_feture_number,\\\n",
    "                        p_encoding_dim=key_feture_number,\\\n",
    "                        p_learning_rate=1E-3,\\\n",
    "                        p_l1_lambda=0.1,\\\n",
    "                        p_loss_weight_1=1,\\\n",
    "                        p_loss_weight_2=2):\n",
    "    \n",
    "    input_img = Input(shape=(p_data_feature,), name='autoencoder_input')\n",
    "\n",
    "    feature_selection = Feature_Select_Layer(output_dim=p_data_feature,\\\n",
    "                                             l1_lambda=p_l1_lambda,\\\n",
    "                                             input_shape=(p_data_feature,),\\\n",
    "                                             name='feature_selection')\n",
    "\n",
    "    feature_selection_score=feature_selection(input_img)\n",
    "    feature_selection_choose=feature_selection(input_img,selection=True,k=p_feture_number)\n",
    "\n",
    "    encoded = Dense(p_encoding_dim,\\\n",
    "                    activation='linear',\\\n",
    "                    kernel_initializer=initializers.glorot_uniform(seed),\\\n",
    "                    name='autoencoder_hidden_layer')\n",
    "    \n",
    "    encoded_score=encoded(feature_selection_score)\n",
    "    encoded_choose=encoded(feature_selection_choose)\n",
    "    \n",
    "    bottleneck_score=encoded_score\n",
    "    bottleneck_choose=encoded_choose\n",
    "    \n",
    "    decoded = Dense(p_data_feature,\\\n",
    "                    activation='linear',\\\n",
    "                    kernel_initializer=initializers.glorot_uniform(seed),\\\n",
    "                    name='autoencoder_output')\n",
    "    \n",
    "    decoded_score =decoded(bottleneck_score)\n",
    "    decoded_choose =decoded(bottleneck_choose)\n",
    "\n",
    "    latent_encoder_score = Model(input_img, bottleneck_score)\n",
    "    latent_encoder_choose = Model(input_img, bottleneck_choose)\n",
    "    feature_selection_output=Model(input_img,feature_selection_choose)\n",
    "    autoencoder = Model(input_img, [decoded_score,decoded_choose])\n",
    "    \n",
    "    autoencoder.compile(loss=['mean_squared_error','mean_squared_error'],\\\n",
    "                        loss_weights=[p_loss_weight_1, p_loss_weight_2],\\\n",
    "                        optimizer=optimizers.Adam(lr=p_learning_rate))\n",
    "    \n",
    "    print('Autoencoder Structure-------------------------------------')\n",
    "    autoencoder.summary()\n",
    "    return autoencoder,feature_selection_output,latent_encoder_score,latent_encoder_choose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Structure and paramter testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_number=1000\n",
    "batch_size_value=256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 3.1.1 Fractal Autoencoder\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/ubuntu_env_1/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/ubuntu_env_1/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-4-e4d43e0c9952>:25: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/ubuntu/ubuntu_env_1/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/ubuntu_env_1/lib/python3.6/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Autoencoder Structure-------------------------------------\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "autoencoder_input (InputLayer)  (None, 10463)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "feature_selection (Feature_Sele (None, 10463)        10463       autoencoder_input[0][0]          \n",
      "                                                                 autoencoder_input[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "autoencoder_hidden_layer (Dense (None, 900)          9417600     feature_selection[0][0]          \n",
      "                                                                 feature_selection[1][0]          \n",
      "__________________________________________________________________________________________________\n",
      "autoencoder_output (Dense)      (None, 10463)        9427163     autoencoder_hidden_layer[0][0]   \n",
      "                                                                 autoencoder_hidden_layer[1][0]   \n",
      "==================================================================================================\n",
      "Total params: 18,855,226\n",
      "Trainable params: 18,855,226\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "F_AE,\\\n",
    "feature_selection_output,\\\n",
    "latent_encoder_score_F_AE,\\\n",
    "latent_encoder_choose_F_AE=Fractal_Autoencoder(p_data_feature=xy_test.shape[1],\\\n",
    "                                               p_feture_number=key_feture_number,\\\n",
    "                                               p_encoding_dim=key_feture_number,\\\n",
    "                                               p_learning_rate= 1E-3,\\\n",
    "                                               p_l1_lambda=0.1,\\\n",
    "                                               p_loss_weight_1=1,\\\n",
    "                                               p_loss_weight_2=2)\n",
    "\n",
    "#file_name=\"./log/F_AE_\"+str(key_feture_number)+\"_\"+key_feture_number+\".png\"\n",
    "#plot_model(F_AE, to_file=file_name,show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "File_name='./log_weights/F_AE_'+str(key_feture_number)+'_weights.0100.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/ubuntu_env_1/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/ubuntu_env_1/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "F_AE.load_weights(File_name, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for one-to-one map layer 0.27557877064688113\n",
      "MSE for feature selection layer 0.27909406655517754\n"
     ]
    }
   ],
   "source": [
    "p_data=F_AE.predict(xy_test)\n",
    "numbers=xy_test.shape[0]*xy_test.shape[1]\n",
    "\n",
    "print(\"MSE for one-to-one map layer\",np.sum(np.power(np.array(p_data)[0]-xy_test,2))/numbers)\n",
    "print(\"MSE for feature selection layer\",np.sum(np.power(np.array(p_data)[1]-xy_test,2))/numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 3.1.2 SingeGene Feature selection layer output testing\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection_output.load_weights(File_name, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "392\n"
     ]
    }
   ],
   "source": [
    "FS_layer_output=feature_selection_output.predict(xy_test)\n",
    "print(np.sum(FS_layer_output[0]>0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 3.1.3 Key features count\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2496\n",
      "900\n"
     ]
    }
   ],
   "source": [
    "key_features=F.top_k_keepWeights_1(F_AE.get_layer(index=1).get_weights()[0],key_feture_number)\n",
    "print(np.sum(F_AE.get_layer(index=1).get_weights()[0]>0))\n",
    "print(np.sum(key_features>0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.Comapre genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_genes_index=np.where(key_features>0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "LM_ID = 'map_lm.txt'\n",
    "TG_ID = 'map_tg_merge.txt'\n",
    "\n",
    "LM_ID_infile = open(LM_ID)\n",
    "LM_ID_infile_list=[]\n",
    "for line in LM_ID_infile:\n",
    "    LM_ID_infile_list.append(line.split('\\t')[0])\n",
    "    \n",
    "TG_ID_infile = open(TG_ID)\n",
    "TG_ID_infile_list=[]\n",
    "for line in TG_ID_infile:\n",
    "    TG_ID_infile_list.append(line.split('\\t')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "LM_ID_arr=np.array(LM_ID_infile_list)\n",
    "TG_ID_arr=np.array(TG_ID_infile_list)\n",
    "selected_genes=TG_ID_arr[selected_genes_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133\n"
     ]
    }
   ],
   "source": [
    "inters_genes = np.intersect1d(selected_genes, LM_ID_arr)\n",
    "print(len(inters_genes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.Comapre genes in figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_genes_array_withFAESelection=np.zeros(10463)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "900"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in selected_genes_index:\n",
    "    whole_genes_array_withFAESelection[i]=1\n",
    "\n",
    "np.sum(whole_genes_array_withFAESelection==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "943"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole_genes_array_withLandmarkgenes=np.zeros(10463)\n",
    "whole_genes_array_withLandmarkgenes[9520:]=1\n",
    "np.sum(whole_genes_array_withLandmarkgenes==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (30,2))\n",
    "plt.grid(False)\n",
    "whole_genes_array_withFAESelection_=np.tile(whole_genes_array_withFAESelection,(1000,1))\n",
    "plt.yticks([]) \n",
    "plt.xticks(fontsize=24) \n",
    "colors = ['black', 'red']\n",
    "cmap = mpl.colors.ListedColormap(colors)\n",
    "plt.imshow(whole_genes_array_withFAESelection_, interpolation='nearest', cmap=cmap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (30,2))\n",
    "plt.grid(False)\n",
    "whole_genes_array_withLandmarkgenes_=np.tile(whole_genes_array_withLandmarkgenes,(1000,1))\n",
    "plt.yticks([]) \n",
    "plt.xticks(fontsize=24) \n",
    "colors = ['black', 'yellow']\n",
    "cmap = mpl.colors.ListedColormap(colors)\n",
    "plt.imshow(whole_genes_array_withLandmarkgenes_, interpolation='nearest', cmap=cmap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

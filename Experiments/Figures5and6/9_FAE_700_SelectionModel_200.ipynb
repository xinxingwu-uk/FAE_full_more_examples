{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#----------------------------Reproducible----------------------------------------------------------------------------------------\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "import os\n",
    "\n",
    "seed=0\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "np.random.seed(seed)\n",
    "rn.seed(seed)\n",
    "#session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "session_conf =tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "#tf.set_random_seed(seed)\n",
    "tf.compat.v1.set_random_seed(seed)\n",
    "#sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "\n",
    "K.set_session(sess)\n",
    "#----------------------------Reproducible----------------------------------------------------------------------------------------\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Flatten, Activation, Dropout, Layer\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import to_categorical\n",
    "from keras import optimizers,initializers,constraints,regularizers\n",
    "from keras import backend as K\n",
    "from keras.callbacks import LambdaCallback,ModelCheckpoint\n",
    "from keras.utils import plot_model\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import h5py\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer \n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib as mpl\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "#Import ourslef defined methods\n",
    "import sys\n",
    "sys.path.append(r\"./Defined\")\n",
    "import Functions as F\n",
    "\n",
    "# The following code should be added before the keras model\n",
    "#np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of xy_test: (11101, 10463)\n"
     ]
    }
   ],
   "source": [
    "xy_test = np.load('bgedv2_XY_te_float32.npy')\n",
    "print('Shape of xy_test: ' + str(xy_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_feture_number=700"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "class Feature_Select_Layer(Layer):\n",
    "    \n",
    "    def __init__(self, output_dim, l1_lambda, **kwargs):\n",
    "        super(Feature_Select_Layer, self).__init__(**kwargs)\n",
    "        self.output_dim = output_dim\n",
    "        self.l1_lambda=l1_lambda\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(name='kernel',  \n",
    "                                      shape=(input_shape[1],),\n",
    "                                      initializer=initializers.RandomUniform(minval=0.999999, maxval=0.9999999, seed=seed),\n",
    "                                      trainable=True,\n",
    "                                      regularizer=regularizers.l1(self.l1_lambda),\n",
    "                                      constraint=constraints.NonNeg())\n",
    "        super(Feature_Select_Layer, self).build(input_shape)\n",
    "    \n",
    "    def call(self, x, selection=False,k=key_feture_number):\n",
    "        kernel=self.kernel        \n",
    "        if selection:\n",
    "            kernel_=K.transpose(kernel)\n",
    "            kth_largest = tf.math.top_k(kernel_, k=k)[0][-1]\n",
    "            kernel = tf.where(condition=K.less(kernel,kth_largest),x=K.zeros_like(kernel),y=kernel)        \n",
    "        return K.dot(x, tf.linalg.tensor_diag(kernel))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_dim)\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "def Autoencoder(p_data_feature=xy_test.shape[1],\\\n",
    "                p_encoding_dim=key_feture_number,\\\n",
    "                p_learning_rate= 1E-3):\n",
    "    input_img = Input(shape=(p_data_feature,), name='input_img')\n",
    "\n",
    "    encoded = Dense(p_encoding_dim, activation='linear',kernel_initializer=initializers.glorot_uniform(seed))(input_img)\n",
    "    bottleneck=encoded\n",
    "    decoded = Dense(p_data_feature, activation='linear',kernel_initializer=initializers.glorot_uniform(seed))(encoded)\n",
    "\n",
    "    latent_encoder = Model(input_img, bottleneck)\n",
    "    autoencoder = Model(input_img, decoded)\n",
    "    \n",
    "    autoencoder.compile(loss='mean_squared_error', optimizer=optimizers.Adam(lr=p_learning_rate))\n",
    "    \n",
    "    print('Autoencoder Structure-------------------------------------')\n",
    "    autoencoder.summary()\n",
    "    #print('Latent Encoder Structure-------------------------------------')\n",
    "    #latent_encoder.summary()\n",
    "    return autoencoder,latent_encoder\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "def Identity_Autoencoder(p_data_feature=xy_test.shape[1],\\\n",
    "                         p_encoding_dim=key_feture_number,\\\n",
    "                         p_learning_rate= 1E-3,\\\n",
    "                         p_l1_lambda=0.1):\n",
    "    \n",
    "    input_img = Input(shape=(p_data_feature,), name='autoencoder_input')\n",
    "\n",
    "    feature_selection = Feature_Select_Layer(output_dim=p_data_feature,\\\n",
    "                                             l1_lambda=p_l1_lambda,\\\n",
    "                                             input_shape=(p_data_feature,),\\\n",
    "                                             name='feature_selection')\n",
    "\n",
    "    feature_selection_score=feature_selection(input_img)\n",
    "\n",
    "    encoded = Dense(p_encoding_dim,\\\n",
    "                    activation='linear',\\\n",
    "                    kernel_initializer=initializers.glorot_uniform(seed),\\\n",
    "                    name='autoencoder_hidden_layer')\n",
    "    \n",
    "    encoded_score=encoded(feature_selection_score)\n",
    "    \n",
    "    bottleneck_score=encoded_score\n",
    "    \n",
    "    decoded = Dense(p_data_feature,\\\n",
    "                    activation='linear',\\\n",
    "                    kernel_initializer=initializers.glorot_uniform(seed),\\\n",
    "                    name='autoencoder_output')\n",
    "    \n",
    "    decoded_score =decoded(bottleneck_score)\n",
    "\n",
    "    latent_encoder_score = Model(input_img, bottleneck_score)\n",
    "    autoencoder = Model(input_img, decoded_score)\n",
    "    \n",
    "    autoencoder.compile(loss='mean_squared_error',\\\n",
    "                        optimizer=optimizers.Adam(lr=p_learning_rate))\n",
    "    \n",
    "    print('Autoencoder Structure-------------------------------------')\n",
    "    autoencoder.summary()\n",
    "    return autoencoder,latent_encoder_score\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "def Fractal_Autoencoder(p_data_feature=xy_test.shape[1],\\\n",
    "                        p_feture_number=key_feture_number,\\\n",
    "                        p_encoding_dim=key_feture_number,\\\n",
    "                        p_learning_rate=1E-3,\\\n",
    "                        p_l1_lambda=0.1,\\\n",
    "                        p_loss_weight_1=1,\\\n",
    "                        p_loss_weight_2=2):\n",
    "    \n",
    "    input_img = Input(shape=(p_data_feature,), name='autoencoder_input')\n",
    "\n",
    "    feature_selection = Feature_Select_Layer(output_dim=p_data_feature,\\\n",
    "                                             l1_lambda=p_l1_lambda,\\\n",
    "                                             input_shape=(p_data_feature,),\\\n",
    "                                             name='feature_selection')\n",
    "\n",
    "    feature_selection_score=feature_selection(input_img)\n",
    "    feature_selection_choose=feature_selection(input_img,selection=True,k=p_feture_number)\n",
    "\n",
    "    encoded = Dense(p_encoding_dim,\\\n",
    "                    activation='linear',\\\n",
    "                    kernel_initializer=initializers.glorot_uniform(seed),\\\n",
    "                    name='autoencoder_hidden_layer')\n",
    "    \n",
    "    encoded_score=encoded(feature_selection_score)\n",
    "    encoded_choose=encoded(feature_selection_choose)\n",
    "    \n",
    "    bottleneck_score=encoded_score\n",
    "    bottleneck_choose=encoded_choose\n",
    "    \n",
    "    decoded = Dense(p_data_feature,\\\n",
    "                    activation='linear',\\\n",
    "                    kernel_initializer=initializers.glorot_uniform(seed),\\\n",
    "                    name='autoencoder_output')\n",
    "    \n",
    "    decoded_score =decoded(bottleneck_score)\n",
    "    decoded_choose =decoded(bottleneck_choose)\n",
    "\n",
    "    latent_encoder_score = Model(input_img, bottleneck_score)\n",
    "    latent_encoder_choose = Model(input_img, bottleneck_choose)\n",
    "    feature_selection_output=Model(input_img,feature_selection_choose)\n",
    "    autoencoder = Model(input_img, [decoded_score,decoded_choose])\n",
    "    \n",
    "    autoencoder.compile(loss=['mean_squared_error','mean_squared_error'],\\\n",
    "                        loss_weights=[p_loss_weight_1, p_loss_weight_2],\\\n",
    "                        optimizer=optimizers.Adam(lr=p_learning_rate))\n",
    "    \n",
    "    print('Autoencoder Structure-------------------------------------')\n",
    "    autoencoder.summary()\n",
    "    return autoencoder,feature_selection_output,latent_encoder_score,latent_encoder_choose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Structure and paramter testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_number=1000\n",
    "batch_size_value=256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 3.1.1 Fractal Autoencoder\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-4-e4d43e0c9952>:25: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Autoencoder Structure-------------------------------------\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "autoencoder_input (InputLayer)  (None, 10463)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "feature_selection (Feature_Sele (None, 10463)        10463       autoencoder_input[0][0]          \n",
      "                                                                 autoencoder_input[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "autoencoder_hidden_layer (Dense (None, 700)          7324800     feature_selection[0][0]          \n",
      "                                                                 feature_selection[1][0]          \n",
      "__________________________________________________________________________________________________\n",
      "autoencoder_output (Dense)      (None, 10463)        7334563     autoencoder_hidden_layer[0][0]   \n",
      "                                                                 autoencoder_hidden_layer[1][0]   \n",
      "==================================================================================================\n",
      "Total params: 14,669,826\n",
      "Trainable params: 14,669,826\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "F_AE,\\\n",
    "feature_selection_output,\\\n",
    "latent_encoder_score_F_AE,\\\n",
    "latent_encoder_choose_F_AE=Fractal_Autoencoder(p_data_feature=xy_test.shape[1],\\\n",
    "                                               p_feture_number=key_feture_number,\\\n",
    "                                               p_encoding_dim=key_feture_number,\\\n",
    "                                               p_learning_rate= 1E-3,\\\n",
    "                                               p_l1_lambda=0.1,\\\n",
    "                                               p_loss_weight_1=1,\\\n",
    "                                               p_loss_weight_2=2)\n",
    "\n",
    "#file_name=\"./log/F_AE_\"+str(key_feture_number)+\"_\"+key_feture_number+\".png\"\n",
    "#plot_model(F_AE, to_file=file_name,show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "File_name='./log_weights/F_AE_'+str(key_feture_number)+'_weights.0200.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "F_AE.load_weights(File_name, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for one-to-one map layer 0.27009566088727216\n",
      "MSE for feature selection layer 0.2882793171569336\n"
     ]
    }
   ],
   "source": [
    "p_data=F_AE.predict(xy_test)\n",
    "numbers=xy_test.shape[0]*xy_test.shape[1]\n",
    "\n",
    "print(\"MSE for one-to-one map layer\",np.sum(np.power(np.array(p_data)[0]-xy_test,2))/numbers)\n",
    "print(\"MSE for feature selection layer\",np.sum(np.power(np.array(p_data)[1]-xy_test,2))/numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 3.1.2 SingeGene Feature selection layer output testing\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection_output.load_weights(File_name, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313\n"
     ]
    }
   ],
   "source": [
    "FS_layer_output=feature_selection_output.predict(xy_test)\n",
    "print(np.sum(FS_layer_output[0]>0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 3.1.3 Key features count\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3890\n",
      "700\n"
     ]
    }
   ],
   "source": [
    "key_features=F.top_k_keepWeights_1(F_AE.get_layer(index=1).get_weights()[0],key_feture_number)\n",
    "print(np.sum(F_AE.get_layer(index=1).get_weights()[0]>0))\n",
    "print(np.sum(key_features>0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.Comapre genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_genes_index=np.where(key_features>0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "LM_ID = 'map_lm.txt'\n",
    "TG_ID = 'map_tg_merge.txt'\n",
    "\n",
    "LM_ID_infile = open(LM_ID)\n",
    "LM_ID_infile_list=[]\n",
    "for line in LM_ID_infile:\n",
    "    LM_ID_infile_list.append(line.split('\\t')[0])\n",
    "    \n",
    "TG_ID_infile = open(TG_ID)\n",
    "TG_ID_infile_list=[]\n",
    "for line in TG_ID_infile:\n",
    "    TG_ID_infile_list.append(line.split('\\t')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "LM_ID_arr=np.array(LM_ID_infile_list)\n",
    "TG_ID_arr=np.array(TG_ID_infile_list)\n",
    "selected_genes=TG_ID_arr[selected_genes_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n"
     ]
    }
   ],
   "source": [
    "inters_genes = np.intersect1d(selected_genes, LM_ID_arr)\n",
    "print(len(inters_genes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.Comapre genes in figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_genes_array_withFAESelection=np.zeros(10463)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "700"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in selected_genes_index:\n",
    "    whole_genes_array_withFAESelection[i]=1\n",
    "\n",
    "np.sum(whole_genes_array_withFAESelection==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "943"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole_genes_array_withLandmarkgenes=np.zeros(10463)\n",
    "whole_genes_array_withLandmarkgenes[9520:]=1\n",
    "np.sum(whole_genes_array_withLandmarkgenes==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (30,2))\n",
    "plt.grid(False)\n",
    "whole_genes_array_withFAESelection_=np.tile(whole_genes_array_withFAESelection,(1000,1))\n",
    "plt.yticks([]) \n",
    "plt.xticks(fontsize=24) \n",
    "colors = ['black', 'white']\n",
    "cmap = mpl.colors.ListedColormap(colors)\n",
    "plt.imshow(whole_genes_array_withFAESelection_, interpolation='nearest', cmap=cmap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (30,2))\n",
    "plt.grid(False)\n",
    "whole_genes_array_withLandmarkgenes_=np.tile(whole_genes_array_withLandmarkgenes,(1000,1))\n",
    "plt.yticks([]) \n",
    "plt.xticks(fontsize=24) \n",
    "colors = ['black', 'yellow']\n",
    "cmap = mpl.colors.ListedColormap(colors)\n",
    "plt.imshow(whole_genes_array_withLandmarkgenes_, interpolation='nearest', cmap=cmap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
